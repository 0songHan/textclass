
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html">
      
      
      <link rel="icon" href="img/logo.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.1.21">
    
    
      
        <title>4.4 模型剪枝 - 头条投满分项目V4.0</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.eebd395e.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="." title="头条投满分项目V4.0" class="md-header__button md-logo" aria-label="头条投满分项目V4.0" data-md-component="logo">
      
  <img src="img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            头条投满分项目V4.0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              4.4 模型剪枝
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="头条投满分项目V4.0" class="md-nav__button md-logo" aria-label="头条投满分项目V4.0" data-md-component="logo">
      
  <img src="img/logo.png" alt="logo">

    </a>
    头条投满分项目V4.0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF.html" class="md-nav__link">
        1、项目背景
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          2、数据集
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          2、数据集
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="02-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        2.1 数据集介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html" class="md-nav__link">
        2.2 数据分析与处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          3、模型训练与测试
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          3、模型训练与测试
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html" class="md-nav__link">
        3.1 随机森林-baseline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="05-fasttext%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        3.2 fastext的应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="06-bert%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        3.3 Bert模型使用
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          4、模型压缩
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          4、模型压缩
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html" class="md-nav__link">
        4.1 模型量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html" class="md-nav__link">
        4.2 知识蒸馏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html" class="md-nav__link">
        4.3 知识蒸馏的实践
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          4.4 模型剪枝
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html" class="md-nav__link md-nav__link--active">
        4.4 模型剪枝
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1.什么是模型的剪枝
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2pruning-model" class="md-nav__link">
    2.对特定网络模块的剪枝(Pruning Model).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-pruning-multiple-parameters" class="md-nav__link">
    3. 多参数模块的剪枝(Pruning multiple parameters).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-global-pruning" class="md-nav__link">
    4. 全局剪枝(GLobal pruning).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5custom-pruning" class="md-nav__link">
    5.用户自定义剪枝(Custom pruning).
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1.什么是模型的剪枝
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2pruning-model" class="md-nav__link">
    2.对特定网络模块的剪枝(Pruning Model).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-pruning-multiple-parameters" class="md-nav__link">
    3. 多参数模块的剪枝(Pruning multiple parameters).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-global-pruning" class="md-nav__link">
    4. 全局剪枝(GLobal pruning).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5custom-pruning" class="md-nav__link">
    5.用户自定义剪枝(Custom pruning).
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="_1">模型剪枝的概念和理论<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>学习目标</p>
<ul>
<li>理解什么是模型剪枝.</li>
<li>掌握模型剪枝的基本操作.</li>
</ul>
<hr />
<p><img alt="" src="img/2_1.png" /></p>
<hr />
<h2 id="1">1.什么是模型的剪枝<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<ul>
<li>基于深度神经网络的大型预训练模型拥有庞大的参数量, 才能达到SOTA的效果. 但是我们参考生物的神经网络, 发现却是依靠大量稀疏的连接来完成复杂的意识活动. </li>
</ul>
<hr />
<ul>
<li>仿照生物的稀疏神经网络, 将大型网络中的稠密连接变成稀疏的连接, 并同样达到SOTA的效果, 就是模型剪枝的原动力.</li>
</ul>
<p><img alt="" src="img/2_2.png" /></p>
<hr />
<ul>
<li>Pytorch中对模型剪枝的支持在torch.nn.utils.prune模块中, 分以下几种剪枝方式:<ul>
<li>对特定网络模块的剪枝(Pruning Model).</li>
<li>多参数模块的剪枝(Pruning multiple parameters).</li>
<li>全局剪枝(GLobal pruning).</li>
<li>用户自定义剪枝(Custom pruning).</li>
</ul>
</li>
</ul>
<hr />
<blockquote>
<ul>
<li>注意: 保证Pytorch的版本在1.4.0以上, 支持剪枝操作.</li>
</ul>
</blockquote>
<hr />
<h2 id="2pruning-model">2.对特定网络模块的剪枝(Pruning Model).<a class="headerlink" href="#2pruning-model" title="Permanent link">&para;</a></h2>
<ul>
<li>首先导入工具包:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.utils.prune</span> <span class="k">as</span> <span class="nn">prune</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</code></pre></div>
<hr />
<ul>
<li>创建一个网络, 我们以经典的LeNet来示例:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 1: 图像的输入通道(1是黑白图像), 6: 输出通道, 3x3: 卷积核的尺寸</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>  <span class="c1"># 5x5 是经历卷积操作后的图片尺寸</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>调用:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">module</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>[(&#39;weight&#39;, Parameter containing:
tensor([[[[ 0.0853, -0.0203, -0.0784],
          [ 0.3327, -0.0904, -0.0374],
          [-0.0037, -0.2629, -0.2536]]],


        [[[ 0.1313,  0.0249,  0.2735],
          [ 0.0630,  0.0625, -0.0468],
          [ 0.3328,  0.3249, -0.2640]]],


        [[[ 0.1931, -0.2246,  0.0102],
          [ 0.3319,  0.1740, -0.0799],
          [-0.0195, -0.1295, -0.0964]]],


        [[[ 0.3005,  0.2704,  0.3162],
          [-0.2560,  0.0295,  0.2605],
          [-0.1056, -0.0730,  0.0436]]],


        [[[-0.3205,  0.1927, -0.0761],
          [ 0.0142, -0.0562, -0.3087],
          [ 0.1202,  0.1119, -0.1336]]],


        [[[ 0.0568,  0.1142,  0.3079],
          [ 0.2000, -0.1661, -0.2935],
          [-0.1652, -0.2606, -0.0559]]]], device=&#39;cuda:0&#39;, requires_grad=True)), (&#39;bias&#39;, Parameter containing:
tensor([ 0.1085, -0.1044,  0.1366,  0.3240, -0.1522,  0.1630], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</code></pre></div>
<hr />
<ul>
<li>再打印一个特殊的属性张量</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果</li>
</ul>
<div class="highlight"><pre><span></span><code># 这里面打印出一个空列表, 至于这个空列表代表什么含义? 剪枝操作后同学们就明白了!
[]
</code></pre></div>
<hr />
<ul>
<li>直接调用prune函数对模型进行剪枝操作:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 第一个参数: module, 代表要进行剪枝的特定模块, 之前我们已经制定了module=model.conv1,</span>
<span class="c1">#             说明这里要对第一个卷积层执行剪枝.</span>
<span class="c1"># 第二个参数: name, 指定要对选中的模块中的哪些参数执行剪枝.</span>
<span class="c1">#             这里设定为name=&quot;weight&quot;, 意味着对连接网络中的weight剪枝, 而不对bias剪枝.</span>
<span class="c1"># 第三个参数: amount, 指定要对模型中多大比例的参数执行剪枝.</span>
<span class="c1">#             amount是一个介于0.0-1.0的float数值, 或者一个正整数指定剪裁掉多少条连接边.</span>

<span class="n">prune</span><span class="o">.</span><span class="n">random_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>调用:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>[(&#39;bias&#39;, Parameter containing:
tensor([ 0.1861,  0.2483, -0.3235,  0.0667,  0.0790,  0.1807], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;weight_orig&#39;, Parameter containing:
tensor([[[[-0.1544, -0.3045,  0.1339],
          [ 0.2605, -0.1201,  0.3060],
          [-0.2502, -0.0023, -0.0362]]],


        [[[ 0.3147, -0.1034, -0.1772],
          [-0.2250, -0.1071,  0.2489],
          [ 0.2741, -0.1926, -0.2046]]],


        [[[-0.1022, -0.2210, -0.1349],
          [-0.2938,  0.0679,  0.2485],
          [ 0.1108, -0.0564, -0.3328]]],


        [[[-0.0464,  0.0138,  0.0283],
          [-0.3205,  0.0184,  0.0521],
          [ 0.2219, -0.2403, -0.2881]]],


        [[[ 0.3320, -0.0684, -0.1715],
          [-0.0381,  0.1819,  0.1796],
          [-0.3321, -0.2684, -0.0477]]],


        [[[-0.1638, -0.0969,  0.0077],
          [ 0.0906,  0.2051,  0.2174],
          [-0.2174,  0.1875, -0.2978]]]], device=&#39;cuda:0&#39;, requires_grad=True))]
[(&#39;weight_mask&#39;, tensor([[[[1., 0., 1.],
          [1., 0., 1.],
          [1., 0., 1.]]],


        [[[0., 0., 0.],
          [0., 1., 1.],
          [0., 0., 1.]]],


        [[[1., 1., 1.],
          [0., 1., 1.],
          [1., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 1., 1.],
          [1., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 1.],
          [1., 1., 0.]]],


        [[[1., 0., 1.],
          [0., 0., 1.],
          [1., 1., 0.]]]], device=&#39;cuda:0&#39;))]
</code></pre></div>
<hr />
<blockquote>
<ul>
<li>结论: 模型经历剪枝操作后, 原始的权重矩阵weight参数不见了, 变成了weight_orig. 并且刚刚打印为空列表的module.named_buffers(), 此时拥有了一个weight_mask参数.</li>
</ul>
</blockquote>
<hr />
<ul>
<li>这时打印module.weight属性值, 看看有什么启发?</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>tensor([[[[-0.1544, -0.0000,  0.1339],
          [ 0.2605, -0.0000,  0.3060],
          [-0.2502, -0.0000, -0.0362]]],


        [[[ 0.0000, -0.0000, -0.0000],
          [-0.0000, -0.1071,  0.2489],
          [ 0.0000, -0.0000, -0.2046]]],


        [[[-0.1022, -0.2210, -0.1349],
          [-0.0000,  0.0679,  0.2485],
          [ 0.1108, -0.0564, -0.3328]]],


        [[[-0.0464,  0.0138,  0.0283],
          [-0.3205,  0.0184,  0.0521],
          [ 0.2219, -0.2403, -0.2881]]],


        [[[ 0.3320, -0.0684, -0.1715],
          [-0.0381,  0.0000,  0.1796],
          [-0.3321, -0.2684, -0.0000]]],


        [[[-0.1638, -0.0000,  0.0077],
          [ 0.0000,  0.0000,  0.2174],
          [-0.2174,  0.1875, -0.0000]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
</code></pre></div>
<hr />
<blockquote>
<ul>
<li>结论: 经过剪枝操作后的模型, 原始的参数存放在了weight_orig中, 对应的剪枝矩阵存放在weight_mask中, 而将weight_mask视作掩码张量, 再和weight_orig相乘的结果就存放在了weight中.</li>
</ul>
</blockquote>
<hr />
<blockquote>
<ul>
<li>注意: 剪枝操作后的weight已经不再是module的参数(parameter), 而只是module的一个属性(attribute).</li>
</ul>
</blockquote>
<hr />
<p>我们可以对模型的任意子结构进行剪枝操作, 除了在weight上面剪枝, 还可以对bias进行剪枝.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 第一个参数: module, 代表剪枝的对象, 此处代表LeNet中的conv1</span>
<span class="c1"># 第二个参数: name, 代表剪枝对象中的具体参数, 此处代表偏置量</span>
<span class="c1"># 第三个参数: amount, 代表剪枝的数量, 可以设置为0.0-1.0之间表示比例, 也可以用正整数表示剪枝的参数绝对数量</span>
<span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 再次打印模型参数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果</li>
</ul>
<div class="highlight"><pre><span></span><code>[(&#39;weight_orig&#39;, Parameter containing:
tensor([[[[-0.0159, -0.3175, -0.0816],
          [ 0.3144, -0.1534, -0.0924],
          [-0.2885, -0.1054, -0.1872]]],


        [[[ 0.0835, -0.1258, -0.2760],
          [-0.3174,  0.0669, -0.1867],
          [-0.0381,  0.1156,  0.0078]]],


        [[[ 0.1416, -0.2907, -0.0249],
          [ 0.1018,  0.1757, -0.0326],
          [ 0.2736, -0.1980, -0.1162]]],


        [[[-0.1835,  0.1600,  0.3178],
          [ 0.0579, -0.0647, -0.1039],
          [-0.0160, -0.0715,  0.2746]]],


        [[[-0.2314, -0.1759, -0.1820],
          [-0.0594,  0.2355, -0.2087],
          [ 0.0216,  0.0066, -0.0624]]],


        [[[-0.2772,  0.1479, -0.0983],
          [-0.3307, -0.2360, -0.0596],
          [ 0.2785,  0.0648,  0.2869]]]], device=&#39;cuda:0&#39;, requires_grad=True)), (&#39;bias_orig&#39;, Parameter containing:
tensor([-0.1924, -0.1420, -0.0235,  0.0325,  0.0188,  0.0120], device=&#39;cuda:0&#39;,
       requires_grad=True))]
**************************************************
[(&#39;weight_mask&#39;, tensor([[[[0., 0., 0.],
          [1., 1., 1.],
          [1., 0., 1.]]],


        [[[1., 0., 1.],
          [1., 0., 1.],
          [1., 0., 1.]]],


        [[[1., 1., 0.],
          [1., 1., 1.],
          [1., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 0.],
          [0., 1., 0.]]],


        [[[1., 1., 1.],
          [1., 1., 1.],
          [0., 1., 1.]]],


        [[[1., 1., 1.],
          [0., 0., 1.],
          [1., 1., 0.]]]], device=&#39;cuda:0&#39;)), (&#39;bias_mask&#39;, tensor([1., 1., 0., 1., 0., 0.], device=&#39;cuda:0&#39;))]
**************************************************
tensor([-0.1924, -0.1420, -0.0000,  0.0325,  0.0000,  0.0000], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
**************************************************
</code></pre></div>
<hr />
<blockquote>
<ul>
<li>结论: 在module的不同参数集合上应用不同的剪枝策略, 我们发现模型参数中不仅仅有了weight_orig, 也有了bias_orig. 在起到掩码张量作用的named_buffers中, 也同时出现了weight_mask和bias_mask. </li>
</ul>
</blockquote>
<hr />
<ul>
<li>序列化一个剪枝模型(Serializing a pruned model):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 对于一个模型来说, 不管是它原始的参数, 拥有的属性值, 还是剪枝的mask buffers参数</span>
<span class="c1"># 全部都存储在模型的状态字典中, 即state_dict()中.</span>
<span class="c1"># 将模型初始的状态字典打印出来</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 对模型进行剪枝操作, 分别在weight和bias上剪枝</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span>
<span class="n">prune</span><span class="o">.</span><span class="n">random_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 再将剪枝后的模型的状态字典打印出来</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>odict_keys([&#39;conv1.weight&#39;, &#39;conv1.bias&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;, &#39;fc1.weight&#39;, &#39;fc1.bias&#39;, &#39;fc2.weight&#39;, &#39;fc2.bias&#39;, &#39;fc3.weight&#39;, &#39;fc3.bias&#39;])
**************************************************
odict_keys([&#39;conv1.weight_orig&#39;, &#39;conv1.bias_orig&#39;, &#39;conv1.weight_mask&#39;, &#39;conv1.bias_mask&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;, &#39;fc1.weight&#39;, &#39;fc1.bias&#39;, &#39;fc2.weight&#39;, &#39;fc2.bias&#39;, &#39;fc3.weight&#39;, &#39;fc3.bias&#39;])
</code></pre></div>
<hr />
<ul>
<li>关键一步: 对模型执行剪枝remove操作.<ul>
<li>通过module中的参数weight_orig和weight_mask进行剪枝, 本质上属于置零遮掩, 让权重连接失效.</li>
<li>这个remove是无法undo的, 也就是说一旦执行就是对模型参数的永久改变.</li>
</ul>
</li>
</ul>
<hr />
<ul>
<li>执行remove操作的演示代码:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 打印剪枝后的模型参数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 打印剪枝后的模型mask buffers参数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 打印剪枝后的模型weight属性值</span>
<span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 执行剪枝永久化操作remove</span>
<span class="n">prune</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># remove后再次打印模型参数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># remove后再次打印模型mask buffers参数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>[(&#39;weight_orig&#39;, Parameter containing:
tensor([[[[ 0.1668,  0.0369, -0.2930],
          [-0.2630, -0.1777, -0.1096],
          [ 0.0481, -0.0898,  0.1920]]],


        [[[ 0.0729,  0.1445, -0.0471],
          [ 0.1525,  0.2986,  0.2602],
          [-0.0929, -0.2725, -0.0069]]],


        [[[-0.2006, -0.2577,  0.2754],
          [ 0.0999,  0.2106, -0.0046],
          [-0.2813, -0.2794, -0.0580]]],


        [[[-0.2944, -0.2214, -0.0795],
          [-0.0773,  0.2931, -0.2249],
          [-0.0796, -0.2343, -0.0457]]],


        [[[-0.1965,  0.2550,  0.2606],
          [ 0.0213, -0.2839,  0.2037],
          [-0.2068, -0.0507, -0.3097]]],


        [[[ 0.0030,  0.2340, -0.1122],
          [-0.0302, -0.0261,  0.1168],
          [ 0.0927,  0.1553,  0.1167]]]], device=&#39;cuda:0&#39;, requires_grad=True)), (&#39;bias_orig&#39;, Parameter containing:
tensor([ 0.1147,  0.2439, -0.1753, -0.2578, -0.0994,  0.0588], device=&#39;cuda:0&#39;,
       requires_grad=True))]
**************************************************
[(&#39;weight_mask&#39;, tensor([[[[0., 0., 0.],
          [1., 1., 1.],
          [0., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 1.],
          [1., 1., 1.]]],


        [[[1., 1., 0.],
          [1., 1., 1.],
          [1., 0., 1.]]],


        [[[0., 1., 1.],
          [1., 1., 1.],
          [1., 1., 0.]]],


        [[[1., 0., 1.],
          [0., 1., 0.],
          [0., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 0.],
          [0., 1., 1.]]]], device=&#39;cuda:0&#39;)), (&#39;bias_mask&#39;, tensor([0., 1., 1., 1., 0., 0.], device=&#39;cuda:0&#39;))]
**************************************************
tensor([[[[ 0.0000,  0.0000, -0.0000],
          [-0.2630, -0.1777, -0.1096],
          [ 0.0000, -0.0898,  0.1920]]],


        [[[ 0.0729,  0.1445, -0.0471],
          [ 0.1525,  0.0000,  0.2602],
          [-0.0929, -0.2725, -0.0069]]],


        [[[-0.2006, -0.2577,  0.0000],
          [ 0.0999,  0.2106, -0.0046],
          [-0.2813, -0.0000, -0.0580]]],


        [[[-0.0000, -0.2214, -0.0795],
          [-0.0773,  0.2931, -0.2249],
          [-0.0796, -0.2343, -0.0000]]],


        [[[-0.1965,  0.0000,  0.2606],
          [ 0.0000, -0.2839,  0.0000],
          [-0.0000, -0.0507, -0.3097]]],


        [[[ 0.0030,  0.2340, -0.1122],
          [-0.0302, -0.0000,  0.0000],
          [ 0.0000,  0.1553,  0.1167]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
**************************************************
OrderedDict([(0, &lt;torch.nn.utils.prune.RandomUnstructured object at 0x7f65b879e7f0&gt;), (1, &lt;torch.nn.utils.prune.L1Unstructured object at 0x7f655c5ebfd0&gt;)])
[(&#39;bias_orig&#39;, Parameter containing:
tensor([ 0.1147,  0.2439, -0.1753, -0.2578, -0.0994,  0.0588], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;weight&#39;, Parameter containing:
tensor([[[[ 0.0000,  0.0000, -0.0000],
          [-0.2630, -0.1777, -0.1096],
          [ 0.0000, -0.0898,  0.1920]]],


        [[[ 0.0729,  0.1445, -0.0471],
          [ 0.1525,  0.0000,  0.2602],
          [-0.0929, -0.2725, -0.0069]]],


        [[[-0.2006, -0.2577,  0.0000],
          [ 0.0999,  0.2106, -0.0046],
          [-0.2813, -0.0000, -0.0580]]],


        [[[-0.0000, -0.2214, -0.0795],
          [-0.0773,  0.2931, -0.2249],
          [-0.0796, -0.2343, -0.0000]]],


        [[[-0.1965,  0.0000,  0.2606],
          [ 0.0000, -0.2839,  0.0000],
          [-0.0000, -0.0507, -0.3097]]],


        [[[ 0.0030,  0.2340, -0.1122],
          [-0.0302, -0.0000,  0.0000],
          [ 0.0000,  0.1553,  0.1167]]]], device=&#39;cuda:0&#39;, requires_grad=True))]
**************************************************
[(&#39;bias_mask&#39;, tensor([0., 1., 1., 1., 0., 0.], device=&#39;cuda:0&#39;))]
</code></pre></div>
<hr />
<p>结论: 对模型的weight执行remove操作后, 模型参数集合中只剩下bias_orig了, weight_orig消失, 变成了weight, 说明针对weight的剪枝已经永久化生效. 对于named_buffers张量打印可以看出, 只剩下bias_mask了, 因为针对weight做掩码的weight_mask已经生效完毕, 不再需要保留了. </p>
<hr />
<hr />
<hr />
<h2 id="3-pruning-multiple-parameters">3. 多参数模块的剪枝(Pruning multiple parameters).<a class="headerlink" href="#3-pruning-multiple-parameters" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># 打印初始模型的所有状态字典</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 打印初始模型的mask buffers张量字典名称</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">())</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 对于模型进行分模块参数的剪枝</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
    <span class="c1"># 对模型中所有的卷积层执行l1_unstructured剪枝操作, 选取20%的参数剪枝</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1"># 对模型中所有全连接层执行ln_structured剪枝操作, 选取40%的参数剪枝</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">prune</span><span class="o">.</span><span class="n">ln_structured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># 打印多参数模块剪枝后的mask buffers张量字典名称</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">())</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 打印多参数模块剪枝后模型的所有状态字典名称</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>odict_keys([&#39;conv1.weight&#39;, &#39;conv1.bias&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;, &#39;fc1.weight&#39;, &#39;fc1.bias&#39;, &#39;fc2.weight&#39;, &#39;fc2.bias&#39;, &#39;fc3.weight&#39;, &#39;fc3.bias&#39;])
**************************************************
dict_keys([])
**************************************************
dict_keys([&#39;conv1.weight_mask&#39;, &#39;conv2.weight_mask&#39;, &#39;fc1.weight_mask&#39;, &#39;fc2.weight_mask&#39;, &#39;fc3.weight_mask&#39;])
**************************************************
odict_keys([&#39;conv1.bias&#39;, &#39;conv1.weight_orig&#39;, &#39;conv1.weight_mask&#39;, &#39;conv2.bias&#39;, &#39;conv2.weight_orig&#39;, &#39;conv2.weight_mask&#39;, &#39;fc1.bias&#39;, &#39;fc1.weight_orig&#39;, &#39;fc1.weight_mask&#39;, &#39;fc2.bias&#39;, &#39;fc2.weight_orig&#39;, &#39;fc2.weight_mask&#39;, &#39;fc3.bias&#39;, &#39;fc3.weight_orig&#39;, &#39;fc3.weight_mask&#39;])
</code></pre></div>
<hr />
<blockquote>
<ul>
<li>结论: 对比初始化模型的状态字典和剪枝后的状态字典, 可以看到所有的weight参数都没有了, 变成了weight_orig和weight_mask的组合. 初始化的模型named_buffers是空列表, 剪枝后拥有了所有参与剪枝的参数层的weight_mask张量.</li>
</ul>
</blockquote>
<hr />
<hr />
<hr />
<h2 id="4-global-pruning">4. 全局剪枝(GLobal pruning).<a class="headerlink" href="#4-global-pruning" title="Permanent link">&para;</a></h2>
<p>第一种, 第二种剪枝策略本质上属于局部剪枝(local pruning), 需要程序员按照自己的定义one by one的进行操作. 最主要的问题就是模型剪枝效果的好坏很大程度上取决于程序员的剪枝经验, 而且就算经验丰富的程序员也很难肯定的说某种剪枝策略一定更优.</p>
<hr />
<p>更普遍也更通用的剪枝策略是采用全局剪枝(global pruning), 比如在整体网络的视角下剪枝掉20%的权重参数, 而不是在每一层上都剪枝掉20%的权重参数. 采用全局剪枝后, 不同的层被剪掉的百分比不同.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># 首先打印初始化模型的状态字典</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># 构建参数集合, 决定哪些层, 哪些参数集合参与剪枝</span>
<span class="n">parameters_to_prune</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">))</span>

<span class="c1"># 调用prune中的全局剪枝函数global_unstructured执行剪枝操作, 此处针对整体模型中的20%参数量进行剪枝</span>
<span class="n">prune</span><span class="o">.</span><span class="n">global_unstructured</span><span class="p">(</span><span class="n">parameters_to_prune</span><span class="p">,</span> <span class="n">pruning_method</span><span class="o">=</span><span class="n">prune</span><span class="o">.</span><span class="n">L1Unstructured</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># 最后打印剪枝后的模型的状态字典</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>odict_keys([&#39;conv1.weight&#39;, &#39;conv1.bias&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;, &#39;fc1.weight&#39;, &#39;fc1.bias&#39;, &#39;fc2.weight&#39;, &#39;fc2.bias&#39;, &#39;fc3.weight&#39;, &#39;fc3.bias&#39;])
**************************************************
odict_keys([&#39;conv1.bias&#39;, &#39;conv1.weight_orig&#39;, &#39;conv1.weight_mask&#39;, &#39;conv2.bias&#39;, &#39;conv2.weight_orig&#39;, &#39;conv2.weight_mask&#39;, &#39;fc1.bias&#39;, &#39;fc1.weight_orig&#39;, &#39;fc1.weight_mask&#39;, &#39;fc2.bias&#39;, &#39;fc2.weight_orig&#39;, &#39;fc2.weight_mask&#39;, &#39;fc3.bias&#39;, &#39;fc3.weight_orig&#39;, &#39;fc3.weight_mask&#39;])
</code></pre></div>
<hr />
<ul>
<li>针对模型剪枝后, 不同的层会有不同比例的权重参数被剪掉, 利用代码打印出来看看:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">parameters_to_prune</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
            <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">))</span>

<span class="n">prune</span><span class="o">.</span><span class="n">global_unstructured</span><span class="p">(</span><span class="n">parameters_to_prune</span><span class="p">,</span> <span class="n">pruning_method</span><span class="o">=</span><span class="n">prune</span><span class="o">.</span><span class="n">L1Unstructured</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in conv1.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in conv2.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc1.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc2.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc3.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Global sparsity: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
               <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
               <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
               <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
               <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
         <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
               <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
               <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
               <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
               <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">))</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>Sparsity in conv1.weight: 1.85%
Sparsity in conv2.weight: 7.87%
Sparsity in fc1.weight: 21.99%
Sparsity in fc2.weight: 12.56%
Sparsity in fc3.weight: 9.17%
Global sparsity: 20.00%
</code></pre></div>
<hr />
<blockquote>
<ul>
<li>结论: 当采用全局剪枝策略的时候(假定20%比例参数参与剪枝), 仅保证模型总体参数量的20%被剪枝掉, 具体到每一层的情况则由模型的具体参数分布情况来定.</li>
</ul>
</blockquote>
<hr />
<hr />
<hr />
<h2 id="5custom-pruning">5.用户自定义剪枝(Custom pruning).<a class="headerlink" href="#5custom-pruning" title="Permanent link">&para;</a></h2>
<ul>
<li>所谓用户自定义剪枝, 就是程序员自己定义通过什么样的规则进行剪枝, 而不是依赖Pytorch定义好的比如l1_unstructured, ln_structured等等预设好的剪枝规则来进行剪枝.</li>
</ul>
<hr />
<ul>
<li>剪枝模型通过继承class BasePruningMethod()来执行剪枝, 内部有若干方法: <strong>call</strong>, apply_mask, apply, prune, remove等等. 一般来说, 用户只需要实现__init__, 和compute_mask两个函数即可完成自定义的剪枝规则设定.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 自定义剪枝方法的类, 一定要继承prune.BasePruningMethod</span>
<span class="k">class</span> <span class="nc">myself_pruning_method</span><span class="p">(</span><span class="n">prune</span><span class="o">.</span><span class="n">BasePruningMethod</span><span class="p">):</span>
    <span class="n">PRUNING_TYPE</span> <span class="o">=</span> <span class="s2">&quot;unstructured&quot;</span>

    <span class="c1"># 内部实现compute_mask函数, 完成程序员自己定义的剪枝规则, 本质上就是如何去mask掉权重参数</span>
    <span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">default_mask</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">default_mask</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># 此处定义的规则是每隔一个参数就遮掩掉一个, 最终参与剪枝的参数量的50%被mask掉</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">mask</span>

<span class="c1"># 自定义剪枝方法的函数, 内部直接调用剪枝类的方法apply</span>
<span class="k">def</span> <span class="nf">myself_unstructured_pruning</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">myself_pruning_method</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span>
</code></pre></div>
<hr />
<ul>
<li>调用:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 实例化模型类</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1"># 调用自定义剪枝方法的函数, 对model中的第三个全连接层fc3中的偏置bias执行自定义剪枝</span>
<span class="n">myself_unstructured_pruning</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span>

<span class="c1"># 剪枝成功的最大标志, 就是拥有了bias_mask参数</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">bias_mask</span><span class="p">)</span>

<span class="c1"># 打印一下自定义剪枝的耗时</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="n">duration</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;ms&#39;</span><span class="p">)</span>
</code></pre></div>
<hr />
<ul>
<li>输出结果:</li>
</ul>
<div class="highlight"><pre><span></span><code>tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.], device=&#39;cuda:0&#39;)
1.7154216766357422 ms
</code></pre></div>
<hr />
<p>结论: 打印出来的bias_mask张量, 完全是按照预定义的方式每隔一位遮掩掉一位, 0和1交替出现, 后续执行remove操作的时候, 原始的bias_orig中的权重就会同样的被每隔一位剪枝掉一位. 在GPU机器上执行自定义剪枝速度特别快, 仅需1.7ms.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="assets/javascripts/bundle.220ee61c.min.js"></script>
      
        
          <script src="js/extra.js"></script>
        
      
        
          <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        
      
    
  </body>
</html>