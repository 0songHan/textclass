{"config":{"lang":["ja"],"separator":"[\\s\\-\uff0c\u3002]+","pipeline":["stemmer"]},"docs":[{"location":"index.html","title":"Home","text":"<p>\u6b22\u8fce\u5b66\u4e60\u5934\u6761\u6295\u6ee1\u5206\u9879\u76ee</p>"},{"location":"01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF.html","title":"1\u3001\u9879\u76ee\u80cc\u666f","text":""},{"location":"01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF.html#_1","title":"\u6295\u6ee1\u5206\u9879\u76ee\u80cc\u666f\u4ecb\u7ecd","text":"<p>\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u7406\u89e3\u6295\u6ee1\u5206\u9879\u76ee\u7684\u5f00\u53d1\u80cc\u666f.</li> </ul>"},{"location":"01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF.html#1","title":"1\u3001\u9879\u76ee\u80cc\u666f","text":"<ul> <li>\u5bf9\u4e8e\u5b57\u8282\u8df3\u52a8\u8fd9\u5bb6\u516c\u53f8\u6765\u8bf4, \u867d\u7136\u4ea7\u54c1\u7ebf\u4f17\u591a\u4f46\u662f\u6296\u97f3, \u4eca\u65e5\u5934\u6761\u662f\u6700\u5927\u7684\u4e24\u4e2a\u738b\u724c. \u5206\u522b\u4ee3\u8868\u4e86\u57fa\u4e8e\u77ed\u89c6\u9891\u7684\u63a8\u8350, \u548c\u57fa\u4e8e\u77ed\u6587\u672c\u7684\u63a8\u8350. \u80cc\u540e\u878d\u5408\u4e86\u4f17\u591aCV, NLP, \u63a8\u8350\u7cfb\u7edf, \u5927\u6570\u636e\u7b49\u77e5\u8bc6, \u53ef\u4ee5\u8bf4\u662f\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u96c6\u5927\u6210\u8005.</li> </ul> <ul> <li>\u9488\u5bf9\u4e8e\u4eca\u65e5\u5934\u6761\u6765\u8bf4, \u7528\u6237\u5728\u4f17\u591a\u65b0\u95fb, \u8d44\u8baf\u4e2d, \u4e00\u5b9a\u6709\u66f4\u611f\u5174\u8da3\u7684\u7c7b\u522b. \u6bd4\u5982\u7537\u751f\u7684\u5386\u53f2, \u519b\u4e8b, \u8db3\u7403\u7b49, \u5973\u751f\u7684\u8d22\u7ecf, \u516b\u5366, \u7f8e\u5986\u7b49. \u5982\u679c\u80fd\u5c06\u7528\u6237\u66f4\u611f\u5174\u8da3\u7684\u7c7b\u522b\u65b0\u95fb\u4e3b\u52a8\u7b5b\u9009\u51fa\u6765, \u5e76\u8fdb\u884c\u63a8\u8350\u9605\u8bfb, \u90a3\u4e48\u70b9\u51fb\u91cf, \u8ba2\u9605\u91cf, \u4ed8\u8d39\u91cf\u90fd\u4f1a\u6709\u660e\u663e\u589e\u957f.</li> </ul> <ul> <li>\u57fa\u4e8e\u4e0a\u8ff0\u539f\u56e0, \u5b57\u8282\u5185\u90e8\u4eca\u65e5\u5934\u6761\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d, \u5c31\u9700\u8981\u5185\u5d4c\u4e00\u4e2a\u5b50\u4efb\u52a1: \u5c06\u77ed\u6587\u672c\u81ea\u52a8\u8fdb\u884c\u591a\u5206\u7c7b, \u7136\u540e\u50cf\u5feb\u9012\u4e00\u6837\u7684\"\u6295\u9012\"\u5230\u5bf9\u5e94\u7684\"\u9891\u9053\"\u4e2d, \u56e0\u6b64\"\u6295\u6ee1\u5206\"\u5e94\u8fd0\u800c\u751f.</li> </ul>"},{"location":"01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF.html#2","title":"2\u3001\u5c0f\u8282\u603b\u7ed3","text":"<ul> <li>\u672c\u5c0f\u8282\u4ecb\u7ecd\u4e86\u6295\u6ee1\u5206\u9879\u76ee\u7684\u80cc\u666f, \u662f\u5c5e\u4e8e\u6574\u4e2a\u4eca\u65e5\u5934\u6761\u9879\u76ee\u4e2d\u7684\u4e00\u4e2a\u529f\u80fd\u5b50\u96c6, \u5b8c\u6210\u65b0\u95fb, \u54a8\u8be2\u7b49\u77ed\u6587\u672c\u7684\u591a\u5206\u7c7b, \u5c06\u5404\u4e2a\u5b50\u7c7b\u7684\u8d44\u6599\u63a8\u9001\u5230\u5bf9\u5e94\u7684\u63a8\u8350\u6d41\u4e2d.</li> </ul>"},{"location":"02-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.html","title":"\u6570\u636e\u96c6\u4ecb\u7ecd","text":"<p>\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u719f\u6089\u76f8\u5173\u6570\u636e\u7684\u683c\u5f0f\u548c\u6837\u4f8b.</li> </ul>"},{"location":"02-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.html#1","title":"1.\u9879\u76ee\u6570\u636e\u6982\u89c8","text":"<ul> <li>\u9879\u76ee\u4e2d\u7684\u6570\u636e\u6765\u6e90\u57fa\u672c\u5206\u4e3a3\u5927\u79cd\u7c7b:<ul> <li>\u7b2c\u4e00\u7c7b: \u516c\u53f8\u5185\u90e8\u6570\u636e\u90e8\u95e8\u63d0\u4f9b.<ul> <li>\u60c5\u51b51: \u6570\u636e\u5e73\u53f0\u6709\u9884\u5904\u7406, \u63d0\u4f9b\u7684\u662f\"\u6210\u54c1\u6570\u636e\".</li> <li>\u60c5\u51b52: \u6570\u636e\u5e73\u53f0\u6ca1\u6709\u9884\u5904\u7406, \u53ea\u544a\u8bc9\u5f00\u53d1\u4eba\u5458\"\u6570\u636e\u8def\u5f84\".</li> <li>\u60c5\u51b53: \u539f\u59cb\u6570\u636e\u5c31\u6ca1\u6709, \u9700\u8981\u5f00\u53d1\u4eba\u5458\u6c9f\u901a\u4e0d\u540c\u90e8\u5206, \u83b7\u53d6\"\u4e1a\u52a1\u6570\u636e\".</li> </ul> </li> <li>\u7b2c\u4e8c\u7c7b: \u7532\u65b9\u63d0\u9700\u6c42, \u5e76\u63d0\u4f9b\u6570\u636e.<ul> <li>\u60c5\u51b51: \u7532\u65b9\u6709\u9884\u5904\u7406\u6570\u636e, \u63d0\u4f9b\u7684\u57fa\u672c\u662f\"\u534a\u6210\u54c1\u6570\u636e\".</li> <li>\u60c5\u51b52: \u7532\u65b9\u53ea\u8d1f\u8d23\"\u57cb\u70b9\", \u540e\u7eed\u6570\u636e\u9700\u8981\u5f00\u53d1\u4eba\u5458\u5904\u7406.</li> <li>\u60c5\u51b53: \u7532\u65b9\u6570\u636e\"\u532e\u4e4f\", \u751a\u81f3\u6570\u636e\"\u7f3a\u5931\".</li> </ul> </li> <li>\u7b2c\u4e09\u7c7b: \u9700\u6c42\u753b\u5927\u997c\u9636\u6bb5, \u6ca1\u6709\u6570\u636e, \u6ca1\u6709GPU, \u53ea\u6709\"\u84dd\u56fe\"\u548c\"\u5c55\u671b\".</li> </ul> </li> </ul> <ul> <li>\u672c\u9879\u76ee\u4e2d\u7684\u6570\u636e\u5df2\u7ecf\u7531\u5b57\u8282\u9884\u5904\u7406\u5e76\u5b8c\u6210\u4e86\u6807\u6ce8\u4fe1\u606f. \u5c5e\u4e8e\u7b2c\u4e00\u7c7b\u4e2d\u7684\u60c5\u51b51.<ul> <li>\u6570\u636e\u8def\u5f84: 02-data/data/</li> </ul> </li> </ul> <ul> <li>data\u6587\u4ef6\u5939\u5185\u5bb9\u5c55\u793a:</li> </ul> <ul> <li>\u8bad\u7ec3\u96c6\u6570\u636e: </li> </ul> <pre><code>02-data/data/train.txt\n</code></pre> <p>\u5171180000\u6761.</p> <pre><code>\u4e2d\u534e\u5973\u5b50\u5b66\u9662\uff1a\u672c\u79d1\u5c42\u6b21\u4ec51\u4e13\u4e1a\u62db\u7537\u751f     3\n\u4e24\u5929\u4ef7\u7f51\u7ad9\u80cc\u540e\u91cd\u91cd\u8ff7\u96fe\uff1a\u505a\u4e2a\u7f51\u7ad9\u7a76\u7adf\u8981\u591a\u5c11\u94b1    4\n\u4e1c5\u73af\u6d77\u68e0\u516c\u793e230-290\u5e732\u5c45\u51c6\u73b0\u623f98\u6298\u4f18\u60e0 1\n\u5361\u4f69\u7f57\uff1a\u544a\u8bc9\u4f60\u5fb7\u56fd\u811a\u751f\u731b\u7684\u539f\u56e0 \u4e0d\u5e0c\u671b\u82f1\u5fb7\u6218\u8e22\u70b9\u7403       7\n82\u5c81\u8001\u592a\u4e3a\u5b66\u751f\u505a\u996d\u626b\u573044\u5e74\u83b7\u6388\u6e2f\u5927\u8363\u8a89\u9662\u58eb      5\n\u8bb0\u8005\u56de\u8bbf\u5730\u9707\u4e2d\u53ef\u4e50\u7537\u5b69\uff1a\u5c06\u53d7\u9080\u8d74\u7f8e\u56fd\u53c2\u89c2        5\n\u51af\u5fb7\u4f26\u5f90\u82e5\ufffd\u9694\u7a7a\u4f20\u60c5 \u9ed8\u8ba4\u5176\u662f\u5973\u53cb        9\n\u4f20\u90ed\u6676\u6676\u6b32\u843d\u6237\u9999\u6e2f\u6218\u4f26\u6566\u5965\u8fd0 \u88c5\u4fee\u522b\u5885\u5f53\u5a5a\u623f     1\n\u300a\u8d64\u58c1OL\u300b\u653b\u57ce\u6218\u8bf8\u4faf\u6218\u785d\u70df\u53c8\u8d77  8\n\u201c\u624b\u673a\u94b1\u5305\u201d\u4eae\u76f8\u79d1\u535a\u4f1a    4\n\u4e0a\u6d772010\u4e0a\u534a\u5e74\u56db\u516d\u7ea7\u8003\u8bd5\u62a5\u540d4\u67088\u65e5\u524d\u5b8c\u6210        3\n\u674e\u6c38\u6ce2\u79f0\u674e\u5b97\u4f1f\u96be\u963b\u6797\u4e39\u53d6\u80dc \u900f\u9732\u8c22\u674f\u82b3\u6709\u671b\u51fa\u6218   7\n3\u5c81\u5973\u7ae5\u4e0b\u4f53\u7ea2\u80bf \u81ea\u79f0\u88ab\u5e7c\u513f\u56ed\u8001\u5e08\u7528\u5c3a\u5b50\u6345\u4f24      5\n\u91d1\u8bc1\u987e\u95ee\uff1a\u8fc7\u5c71\u8f66\u884c\u60c5\u610f\u5473\u7740\u4ec0\u4e48  2\n\u8c01\u6599\u5730\u738b\u5982\u6b64\u865a  1\n\u300a\u5149\u73af5\u300bLogo\u6cc4\u9732 Kinect\u7248\u51e0\u65e0\u60ac\u5ff5      8\n\u6d77\u6dc0\u533a\u9886\u79c0\u65b0\u7845\u8c37\u5bbd\u666f\u5927\u5b85\u9884\u8ba110\u6708\u5e95\u5f00\u76d8  1\n\u67f4\u5fd7\u5764\uff1a\u571f\u5730\u4f9b\u5e94\u91cf\u4e0d\u65ad\u4ece\u7d27 \u5730\u4ef7\u96be\u73b007\u6c34\u5e73(\u56fe)   1\n\u4f0a\u8fbe\u4f20\u8bf4EDDA Online     8\n\u4e09\u8054\u4e66\u5e97\u5efa\u8d77\u4e66\u9999\u5df7      4\n\u5b87\u822a\u5458\u5c3f\u6db2\u5835\u585e\u56fd\u9645\u7a7a\u95f4\u7ad9\u6c34\u5faa\u73af\u7cfb\u7edf      4\n\u7814\u7a76\u53d1\u73b0\u5f00\u8f66\u6280\u672f\u5dee\u6216\u4e0e\u57fa\u56e0\u76f8\u5173  6\n\u7687\u9a6c\u8f93\u7403\u66ff\u8865\u5e2d\u95f9\u4e11\u95fb \u961f\u526f\u5973\u7403\u8ff7\u516c\u7136\u8c03\u60c5(\u89c6\u9891)   7\n\u5317\u4eac\u5efa\u5de5\u4e0e\u5e02\u653f\u5e9c\u518d\u5ea6\u5408\u4f5c\u63a8\u51fa\u90ed\u5e84\u5b50\u9650\u4ef7\u623f        1\n\u7ec4\u56fe\uff1a\u674e\u6b23\u6c5d\u7d20\u989c\u51fa\u955c\u62cd\u4f4e\u78b3\u73af\u4fdd\u5927\u7247      9\n</code></pre> <p>train.txt\u4e2d\u5305\u542b180000\u884c\u6837\u672c, \u6bcf\u884c\u5305\u62ec\u4e24\u5217, \u7b2c\u4e00\u5217\u4e3a\u5f85\u5206\u7c7b\u7684\u4e2d\u6587\u6587\u672c, \u7b2c\u4e8c\u5217\u662f\u6570\u5b57\u5316\u6807\u7b7e, \u4e2d\u95f4\u7528\\t\u4f5c\u4e3a\u5206\u9694\u7b26.</p> <ul> <li>\u6d4b\u8bd5\u96c6\u6570\u636e: </li> </ul> <pre><code>02-data/data/test.txt\n</code></pre> <p>\u517110000\u6761.</p> <pre><code>\u8bcd\u6c47\u9605\u8bfb\u662f\u5173\u952e 08\u5e74\u8003\u7814\u6691\u671f\u82f1\u8bed\u590d\u4e60\u5168\u6307\u5357       3\n\u4e2d\u56fd\u4eba\u6c11\u516c\u5b89\u5927\u5b662012\u5e74\u7855\u58eb\u7814\u7a76\u751f\u76ee\u5f55\u53ca\u4e66\u76ee      3\n\u65e5\u672c\u5730\u9707\uff1a\u91d1\u5409\u5217\u5173\u6ce8\u5728\u65e5\u5b66\u5b50\u7cfb\u5217\u62a5\u9053    3\n\u540d\u5e08\u8f85\u5bfc\uff1a2012\u8003\u7814\u82f1\u8bed\u865a\u62df\u8bed\u6c14\u4e09\u79cd\u7528\u6cd5  3\n\u81ea\u8003\u7ecf\u9a8c\u8c08\uff1a\u81ea\u8003\u751f\u6bd5\u4e1a\u8bba\u6587\u9009\u9898\u6280\u5de7      3\n\u672c\u79d1\u672a\u5f55\u53d6\u8fd8\u6709\u8fd9\u4e9b\u8def\u53ef\u4ee5\u8d70      3\n2009\u5e74\u6210\u4eba\u9ad8\u8003\u62db\u751f\u7edf\u4e00\u8003\u8bd5\u65f6\u95f4\u8868        3\n\u53bb\u65b0\u897f\u5170\u4f53\u9a8c\u820c\u5c16\u4e0a\u7684\u9955\u992e\u4e4b\u65c5(\u7ec4\u56fe)      3\n\u56db\u7ea7\u9605\u8bfb\u4e0e\u8003\u7814\u9605\u8bfb\u6bd4\u8f83\u5206\u6790\u4e0e\u5e94\u8bd5\u7b56\u7565    3\n\u5907\u80032012\u9ad8\u8003\u4f5c\u6587\u5fc5\u8bfb\u7f8e\u658750\u7bc7(\u4e00)        3\n\u540d\u5e08\u8be6\u89e3\u8003\u7814\u590d\u8bd5\u82f1\u8bed\u542c\u529b\u5907\u8003\u7b56\u7565        3\n\u70ed\u8bae\uff1a\u827a\u8003\u5408\u683c\u8bc1\u662f\u9ad8\u8003\u5347\u5b66\u738b\u724c\u5417(\u7ec4\u56fe)  3\n\u7814\u7a76\u751f\u529e\u66ff\u8003\u7f51\u7ad9\u7eed\uff1a\u5e55\u540e\u8001\u677f\u5e74\u8d5a\u8fd1\u767e\u4e07(\u56fe)      3\n2011\u5e74\u9ad8\u8003\u6587\u79d1\u7efc\u5408\u8bd5\u9898(\u91cd\u5e86\u5377)  3\n56\u6240\u9ad8\u6821\u9884\u4f302009\u5e74\u6e56\u5317\u5f55\u53d6\u5206\u6570\u7ebf\u51fa\u7089    3\n\u516c\u5171\u82f1\u8bed(PETS)\u5199\u4f5c\u4e2d\u5e38\u89c1\u7684\u903b\u8f91\u8bcd\u6c47\u6c47\u603b  3\n\u65f6\u8bc4\uff1a\u9ad8\u8003\u5e94\u6210\u4e3a\u6559\u80b2\u516c\u5e73\u7684\u201c\u52a9\u63a8\u5668\u201d      3\n\u4e5d\u6210\u5916\u56fd\u4eba\u613f\u7ee7\u7eed\u5728\u65e5\u751f\u6d3b \u516d\u6210\u7559\u5b66\u751f\u672a\u8fd4\u6821       3\n\u6559\u80b2\u90e8\u56de\u5e94\u201c\u53d6\u6d88\u9ad8\u8003\u6237\u7c4d\u9650\u5236\u201d    3\n2008\u5e74\u7518\u8083\u7701\u9ad8\u62db\u4e0d\u540c\u4e8e\u5f80\u5e74\u60ac\u5ff5\u53e0\u51fa(\u56fe)  3\n\u9001\u8003\u961f\u4f0d\u6210\u6d77 \u9ad8\u8003\u573a\u5916\u90a3\u4e9b\u714e\u71ac\u7684\u5fc3       3\n09\u5e74\u5c0f\u8bed\u79cd\u62a5\u8003\u5b8c\u5168\u6307\u5357\uff1a\u4ecd\u987b\u4ee5\u9ad8\u8003\u4e3a\u91cd(\u56fe)      3\n\u56db\u516d\u7ea7\u8003\u524d\u9605\u8bfb\u51b2\u523a\uff1a\u5982\u4f55\u53d1\u6325\u6b63\u5e38\u6c34\u5e73    3\n\u5317\u4eac\u5e02\u6d77\u6dc0\u533a09\u5e74\u9ad8\u8003\u7b2c\u4e8c\u6b21\u6a21\u62df\u8003\u8bd5\u9898    3\n\u502a\u9707\uff1a\u6211\u56fd\u9996\u4f4d\u53c2\u52a0GRE\u8003\u8bd5\u7684\u76f2\u4eba\u5927\u5b66\u751f   3\n</code></pre> <p>test.txt\u4e2d\u5305\u542b10000\u884c\u6837\u672c, \u6bcf\u884c\u5305\u62ec\u4e24\u5217, \u7b2c\u4e00\u5217\u4e3a\u5f85\u5206\u7c7b\u7684\u4e2d\u6587\u6587\u672c, \u7b2c\u4e8c\u5217\u662f\u6570\u5b57\u5316\u6807\u7b7e, \u4e2d \u95f4\u7528\\t\u4f5c\u4e3a\u5206\u9694\u7b26.</p> <ul> <li>\u9a8c\u8bc1\u96c6\u6570\u636e: </li> </ul> <pre><code>02-data/data/dev.txt\n</code></pre> <p>\u517110000\u6761.</p> <pre><code>\u4f53\u9a8c2D\u5dc5\u5cf0 \u501a\u5929\u5c60\u9f99\u8bb0\u5341\u5927\u521b\u65b0\u6982\u89c8       8\n60\u5e74\u94c1\u6811\u5f00\u82b1\u5f62\u72b6\u4f3c\u7389\u7c73\u82af(\u7ec4\u56fe)  5\n\u540c\u6b65A\u80a1\u9996\u79c0\uff1a\u6e2f\u80a1\u7f29\u91cf\u56de\u8c03       2\n\u4e2d\u9752\u5b9dsg\u73b0\u573a\u6293\u62cd \u5154\u5b50\u821e\u70ed\u8fa3\u8868\u6f14 8\n\u950c\u4ef7\u96be\u7eed\u53bb\u5e74\u8f89\u714c        0\n2\u5c81\u7537\u7ae5\u722c\u7a97\u53f0\u4e0d\u614e7\u697c\u5760\u4e0b\u83b7\u6551(\u56fe)        5\n\u5e03\u62c9\u7279\uff1a\u653e\u7403\u5458\u4e00\u6761\u751f\u8def\u5427 FIFA\u80fd\u6d88\u5316\u4ff1\u4e50\u90e8\u7684\u653b\u51fb 7\n\u91d1\u79d1\u897f\u5e9c \u540d\u5885\u5929\u6210       1\n\u72b6\u5143\u5fc3\u7ecf\uff1a\u8003\u524d\u4e00\u5468\u91cd\u70b9\u662f\u56de\u987e\u548c\u6574\u7406      3\n\u53d1\u6539\u59d4\u6cbb\u7406\u6d89\u4f01\u6536\u8d39\u6bcf\u5e74\u4e3a\u4f01\u4e1a\u51cf\u8d1f\u8d85\u767e\u4ebf  6\n\u4e00\u5e74\u7f51\u4e8b\u626b\u836110\u5e74\u7eb7\u6270\u5f00\u5fc3\u7f51\u674e\u9b3c\u4e4b\u4e89\u548c\u5e73\u843d\u5e55      4\n2010\u82f1\u56fd\u65b0\u653f\u5e9c\u201c\u4e09\u628a\u706b\u201d\u6216\u5f71\u54cd\u7559\u5b66\u4e1a      3\n\u4fc4\u8fbe\u5409\u65af\u5766\u5171\u548c\u56fd\u4e00\u540d\u533a\u957f\u88ab\u67aa\u6740  6\n\u671d\u9c9c\u8981\u6c42\u65e5\u672c\u5bf9\u8fc7\u53bb\u7f6a\u884c\u9053\u6b49\u548c\u8d54\u507f        6\n\u300a\u53e3\u888b\u5996\u602a \u9ed1\u767d\u300b\u65e5\u672c\u9996\u5468\u8d29\u552e255\u4e07      8\n\u56fe\u6587\uff1a\u501f\u8d37\u6210\u672c\u4e0a\u6da8\u81f4\u4fc4\u7f57\u65af\u94dd\u4e1a\u51c0\u5229\u4e0b\u6ed121%       2\n\u7ec4\u56fe\uff1a\u65b0\u300a\u4e09\u56fd\u300b\u518d\u66dd\u6d77\u91cf\u5267\u7167 \u706b\u6218\u573a\u9762\u6781\u9707\u64bc     9\n\u9ebb\u8fa3\u70b9\u8bc4\uff1a\u5982\u4f55\u8d70\u51fa\u201c\u88ab\u7559\u5b66\u201d\u7684\u5c34\u5c2c        3\n\u7f8e\u80a1\u8bc4\u8bba\uff1aSUN\u7684\u82e6\u6da9\u66d9\u5149 2\n\u62fe\u8352\u7537\u5b50\u6361\u5230\u4efb\u547d\u4e66\u5047\u5192\u8001\u603b \u8fde\u9a97\u4e8c\u5341\u591a\u4f4d\u5973\u5b50     5\n\u82f1\u56fd\u592b\u5987\u518d\u80b2\u201c\u9ed1\u767d\u201d\u53cc\u80de\u80ce        4\n\u4ece\u8ddf\u73ed\u5230\u6218\u53cb \u7075\u517d\u4f34\u4f60\u7545\u6e38\u4f20\u5947\u4e16\u754c       8\n\u4f60\u6709\u968f\u8eab\u542c \u6211\u6709\u968f\u8eab\u770b\uff1a\u638c\u4e0a\u6545\u4e8b\u4f1a       8\n\u4e00\u5c011968\u5e74\u7684\u5e73\u4fe145.92\u4e07\u5143\u6210\u4ea4   0\n\u5973\u4e3b\u4eba\u6210\u529f\u8bf4\u670d\u6740\u4eba\u8eb2\u907f\u8005\u81ea\u9996    5\n</code></pre> <p>dev.txt\u4e2d\u5305\u542b10000\u884c\u6837\u672c, \u6bcf\u884c\u5305\u62ec\u4e24\u5217, \u7b2c\u4e00\u5217\u4e3a\u5f85\u5206\u7c7b\u7684\u4e2d\u6587\u6587\u672c, \u7b2c\u4e8c\u5217\u662f\u6570\u5b57\u5316\u6807\u7b7e, \u4e2d  \u95f4\u7528\\t\u4f5c\u4e3a\u5206\u9694\u7b26.</p> <ul> <li>\u7c7b\u522b\u96c6\u5408\u6570\u636e: </li> </ul> <pre><code>02-data/data/class.txt\n</code></pre> <p>\u517110\u6761.</p> <pre><code>finance\nrealty\nstocks\neducation\nscience\nsociety\npolitics\nsports\ngame\nentertainment\n</code></pre> <p>class.txt\u4e2d\u5305\u542b10\u4e2a\u7c7b\u522b\u6807\u7b7e, \u6bcf\u884c\u4e00\u4e2a\u6807\u7b7e, \u4e3a\u82f1\u6587\u5355\u8bcd\u7684\u5c55\u793a\u683c\u5f0f.</p>"},{"location":"02-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.html#2","title":"2.\u5c0f\u8282\u603b\u7ed3","text":"<p>\u5bf9\u9879\u76ee\u6570\u636e\u8fdb\u884c\u4e86\u4ecb\u7ecd, \u672c\u9879\u76ee\u62ff\u5230\u624b\u7684\u5df2\u7ecf\u662f\u6570\u636e\u5e73\u53f0\u90e8\u95e8\u5904\u7406\u597d\u7684\"\u4f18\u8d28\u6570\u636e\", \u6211\u4eec\u53ea\u9700\u8981\u5c06\u5168\u90e8\u7cbe\u529b\u653e\u5728\u529f\u80fd\u5b9e\u73b0, \u6a21\u578b\u4f18\u5316\u4e0a\u5373\u53ef.</p>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html","title":"\u6570\u636e\u96c6\u5206\u6790","text":"<p>\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u638c\u63e1\u5bf9\u6570\u636e\u8fdb\u884c\u5feb\u901f\u5206\u6790\u7684\u4ee3\u7801\u5b9e\u73b0.</li> <li>\u638c\u63e1\u5229\u7528\u968f\u673a\u68ee\u6797\u5feb\u901f\u5b9e\u73b0\u5e76\u8bc4\u4f30\u57fa\u7ebf\u6a21\u578b.</li> </ul>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html#1","title":"1.\u6570\u636e\u5206\u6790","text":"<p>\u6570\u636e\u5206\u6790\u4ee3\u7801\u4f4d\u7f6e:</p> <pre><code> analysis.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff1a</p> <pre><code>import pandas as pd\nfrom collections import Counter\nimport numpy as np\nimport jieba\n</code></pre> <p>\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li>\u7b2c\u4e00\u6b65: \u8bfb\u6570\u636e\u5e76\u7edf\u8ba1\u5206\u7c7b\u6570\u91cf</li> <li>\u7b2c\u4e8c\u6b65: \u5206\u6790\u6837\u672c\u5206\u5e03</li> <li>\u7b2c\u4e09\u6b65: \u8fdb\u884c\u5206\u8bcd\u9884\u5904\u7406</li> <li>\u7b2c\u56db\u6b65: \u5904\u7406\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u6570\u636e</li> </ul>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html#11","title":"1.1 \u8bfb\u6570\u636e\u5e76\u7edf\u8ba1\u5206\u7c7b\u6570\u91cf","text":"<p>\u8bfb\u53d6\u6587\u672c\u6587\u4ef6\u4e2d\u7684\u6570\u636e\uff0c\u5206\u6790\u4e86\u6570\u636e\u7684\u57fa\u672c\u4fe1\u606f\uff0c\u5305\u62ec\u663e\u793a\u524d10\u884c\u6570\u636e\u3001\u8f93\u51fa\u603b\u6837\u672c\u6570\u91cf\u4ee5\u53ca\u6bcf\u4e2a\u7c7b\u522b\u7684\u6837\u672c\u6570\u91cf\u3002\u4f7f\u7528\u4e86 pandas \u5e93\u6765\u5904\u7406\u6570\u636e\uff0c\u5e76\u4f7f\u7528 Counter \u8fdb\u884c\u6837\u672c\u7c7b\u522b\u7684\u8ba1\u6570</p> <pre><code># \u8bfb\u53d6\u6570\u636e\ncontent = pd.read_csv('./data/data/train.txt', sep='\\t')\n# \u6253\u5370\u524d10\u884c\nprint(content.head(10))\n# \u83b7\u53d6\u6837\u672c\u6570\u91cf\nprint(len(content))\n# \u7edf\u8ba1\u6bcf\u4e2a\u7c7b\u522b\u7684\u6570\u91cf\ncount = Counter(content.label.values)\n# \u6253\u5370\u4fe1\u606f\nprint(count)\nprint(len(count))\nprint('***************************************')\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>                    sentence  label\n0         \u4e2d\u534e\u5973\u5b50\u5b66\u9662\uff1a\u672c\u79d1\u5c42\u6b21\u4ec51\u4e13\u4e1a\u62db\u7537\u751f      3\n1     \u4e24\u5929\u4ef7\u7f51\u7ad9\u80cc\u540e\u91cd\u91cd\u8ff7\u96fe\uff1a\u505a\u4e2a\u7f51\u7ad9\u7a76\u7adf\u8981\u591a\u5c11\u94b1      4\n2  \u4e1c5\u73af\u6d77\u68e0\u516c\u793e230-290\u5e732\u5c45\u51c6\u73b0\u623f98\u6298\u4f18\u60e0      1\n3  \u5361\u4f69\u7f57\uff1a\u544a\u8bc9\u4f60\u5fb7\u56fd\u811a\u751f\u731b\u7684\u539f\u56e0 \u4e0d\u5e0c\u671b\u82f1\u5fb7\u6218\u8e22\u70b9\u7403      7\n4    82\u5c81\u8001\u592a\u4e3a\u5b66\u751f\u505a\u996d\u626b\u573044\u5e74\u83b7\u6388\u6e2f\u5927\u8363\u8a89\u9662\u58eb      5\n5       \u8bb0\u8005\u56de\u8bbf\u5730\u9707\u4e2d\u53ef\u4e50\u7537\u5b69\uff1a\u5c06\u53d7\u9080\u8d74\u7f8e\u56fd\u53c2\u89c2      5\n6          \u51af\u5fb7\u4f26\u5f90\u82e5\ufffd\u9694\u7a7a\u4f20\u60c5 \u9ed8\u8ba4\u5176\u662f\u5973\u53cb      9\n7     \u4f20\u90ed\u6676\u6676\u6b32\u843d\u6237\u9999\u6e2f\u6218\u4f26\u6566\u5965\u8fd0 \u88c5\u4fee\u522b\u5885\u5f53\u5a5a\u623f      1\n8           \u300a\u8d64\u58c1OL\u300b\u653b\u57ce\u6218\u8bf8\u4faf\u6218\u785d\u70df\u53c8\u8d77      8\n9                \u201c\u624b\u673a\u94b1\u5305\u201d\u4eae\u76f8\u79d1\u535a\u4f1a      4\n180000\nCounter({3: 18000, 4: 18000, 1: 18000, 7: 18000, 5: 18000, 9: 18000, 8: 18000, 2: 18000, 6: 18000, 0: 18000})\n10\n***************************************\n</code></pre>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html#12","title":"1.2 \u5206\u6790\u6837\u672c\u5206\u5e03","text":"<p>\u7edf\u8ba1\u4e86\u6837\u672c\u7684\u603b\u91cf\u3001\u6bcf\u4e2a\u7c7b\u522b\u6837\u672c\u6570\u91cf\u7684\u6bd4\u4f8b\uff0c\u5e76\u8ba1\u7b97\u4e86\u6bcf\u884c\u6837\u672c\u7684\u957f\u5ea6\u4ee5\u53ca\u6587\u672c\u957f\u5ea6\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u8ba1\u7b97\u6837\u672c\u603b\u91cf\uff1a \u901a\u8fc7\u904d\u5386\u6bcf\u4e2a\u7c7b\u522b\u7684\u6837\u672c\u6570\u91cf\uff0c\u7d2f\u52a0\u5f97\u5230\u6837\u672c\u603b\u91cf\u3002</li> <li>\u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u6837\u672c\u6570\u91cf\u7684\u6bd4\u4f8b\uff1a \u904d\u5386\u6bcf\u4e2a\u7c7b\u522b\uff0c\u8ba1\u7b97\u5176\u6837\u672c\u6570\u91cf\u5728\u603b\u91cf\u4e2d\u7684\u6bd4\u4f8b\uff0c\u5e76\u8f93\u51fa\u3002</li> <li>\u7edf\u8ba1\u6bcf\u884c\u6837\u672c\u7684\u957f\u5ea6\uff1a \u4f7f\u7528 pandas \u5e93\u7684 <code>apply</code> \u51fd\u6570\uff0c\u8ba1\u7b97\u6bcf\u884c\u6837\u672c\u7684\u957f\u5ea6\uff0c\u5e76\u5c06\u7ed3\u679c\u6dfb\u52a0\u5230\u6570\u636e\u6846\u4e2d\u3002</li> <li>\u7edf\u8ba1\u6587\u672c\u957f\u5ea6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff1a \u4f7f\u7528 numpy \u5e93\u8ba1\u7b97\u6587\u672c\u957f\u5ea6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5e76\u8f93\u51fa\u7ed3\u679c</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code># \u7edf\u8ba1\u6837\u672c\u603b\u91cf\ntotal = 0\n# \u904d\u5386\u6bcf\u4e2a\u7c7b\u522b\u7684\u6837\u672c\u6570\u91cf\nfor i, v in count.items():\n    total += v\nprint(total)\n# \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u6837\u672c\u6570\u91cf\u7684\u6bd4\u4f8b\nfor i, v in count.items():\n    print(i, v / total * 100, '%')\n\nprint('***************************************')\n# \u7edf\u8ba1\u6bcf\u884c\u6837\u672c\u7684\u957f\u5ea6\ncontent['sentence_len'] = content['sentence'].apply(len)\n# \u6253\u5370\u524d\u5341\u884c\u7ed3\u679c\nprint(content.head(10))\n# \u7edf\u8ba1\u6587\u672c\u957f\u5ea6\u7684\u5747\u503c\u548c\u65b9\u5dee\nlength_mean = np.mean(content['sentence_len'])\nlength_std = np.std(content['sentence_len'])\nprint('length_mean = ', length_mean)\nprint('length_std = ', length_std)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>180000\n3 10.0 %\n4 10.0 %\n1 10.0 %\n7 10.0 %\n5 10.0 %\n9 10.0 %\n8 10.0 %\n2 10.0 %\n6 10.0 %\n0 10.0 %\n***************************************\n                    sentence  label  sentence_len\n0         \u4e2d\u534e\u5973\u5b50\u5b66\u9662\uff1a\u672c\u79d1\u5c42\u6b21\u4ec51\u4e13\u4e1a\u62db\u7537\u751f      3            18\n1     \u4e24\u5929\u4ef7\u7f51\u7ad9\u80cc\u540e\u91cd\u91cd\u8ff7\u96fe\uff1a\u505a\u4e2a\u7f51\u7ad9\u7a76\u7adf\u8981\u591a\u5c11\u94b1      4            22\n2  \u4e1c5\u73af\u6d77\u68e0\u516c\u793e230-290\u5e732\u5c45\u51c6\u73b0\u623f98\u6298\u4f18\u60e0      1            25\n3  \u5361\u4f69\u7f57\uff1a\u544a\u8bc9\u4f60\u5fb7\u56fd\u811a\u751f\u731b\u7684\u539f\u56e0 \u4e0d\u5e0c\u671b\u82f1\u5fb7\u6218\u8e22\u70b9\u7403      7            25\n4    82\u5c81\u8001\u592a\u4e3a\u5b66\u751f\u505a\u996d\u626b\u573044\u5e74\u83b7\u6388\u6e2f\u5927\u8363\u8a89\u9662\u58eb      5            23\n5       \u8bb0\u8005\u56de\u8bbf\u5730\u9707\u4e2d\u53ef\u4e50\u7537\u5b69\uff1a\u5c06\u53d7\u9080\u8d74\u7f8e\u56fd\u53c2\u89c2      5            20\n6          \u51af\u5fb7\u4f26\u5f90\u82e5\ufffd\u9694\u7a7a\u4f20\u60c5 \u9ed8\u8ba4\u5176\u662f\u5973\u53cb      9            17\n7     \u4f20\u90ed\u6676\u6676\u6b32\u843d\u6237\u9999\u6e2f\u6218\u4f26\u6566\u5965\u8fd0 \u88c5\u4fee\u522b\u5885\u5f53\u5a5a\u623f      1            22\n8           \u300a\u8d64\u58c1OL\u300b\u653b\u57ce\u6218\u8bf8\u4faf\u6218\u785d\u70df\u53c8\u8d77      8            16\n9                \u201c\u624b\u673a\u94b1\u5305\u201d\u4eae\u76f8\u79d1\u535a\u4f1a      4            11\n\nlength_mean =  19.21257222222222\nlength_std =  3.863787253359747\n</code></pre>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html#13","title":"1.3 \u8fdb\u884c\u5206\u8bcd\u9884\u5904\u7406","text":"<p>\u4f7f\u7528\u4e86\u7ed3\u5df4\u5206\u8bcd\u5e93\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u8bcd\uff0c\u5e76\u5bf9\u5206\u8bcd\u7ed3\u679c\u8fdb\u884c\u5904\u7406\u548c\u4fdd\u5b58\u3002\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u7ed3\u5df4\u5206\u8bcd\uff1a \u5b9a\u4e49\u4e86\u4e00\u4e2a\u51fd\u6570 <code>cut_sentence</code> \u7528\u4e8e\u8fdb\u884c\u7ed3\u5df4\u5206\u8bcd\u3002</li> <li>\u6dfb\u52a0\u5206\u8bcd\u7ed3\u679c\u5217\uff1a \u4f7f\u7528 <code>apply</code> \u51fd\u6570\u5c06\u5206\u8bcd\u7ed3\u679c\u6dfb\u52a0\u5230\u6570\u636e\u6846\u7684\u65b0\u5217\u4e2d\uff0c\u5217\u540d\u4e3a 'words'\u3002</li> <li>\u5206\u8bcd\uff1a \u4f7f\u7528 <code>apply</code> \u51fd\u6570\uff0c\u5c06\u6bcf\u884c\u6587\u672c\u8fdb\u884c\u7ed3\u5df4\u5206\u8bcd\uff0c\u5e76\u5c06\u7ed3\u679c\u8fde\u63a5\u4e3a\u5b57\u7b26\u4e32\u3002 \u5bf9\u5206\u8bcd\u7ed3\u679c\u8fdb\u884c\u5904\u7406\uff0c\u53ea\u4fdd\u7559\u6bcf\u884c\u7684\u524d30\u4e2a\u5143\u7d20\u3002</li> <li>\u7ed3\u679c\u5b58\u653e\u5230 CSV \u6587\u4ef6\uff1a \u5c06\u5904\u7406\u540e\u7684\u7ed3\u679c\u4fdd\u5b58\u5230\u540d\u4e3a 'train_new.csv' \u7684 CSV \u6587\u4ef6\u4e2d\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code># \u7ed3\u5df4\u5206\u8bcd\ndef cut_sentence(s):\n    return list(jieba.cut(s))\n# \u6dfb\u52a0\u4e00\u5217\u6570\u636e\u5b58\u50a8\u5206\u8bcd\u540e\u7684\u7ed3\u679c\ncontent['words'] = content['sentence'].apply(cut_sentence)\n# \u6253\u5370\u524d\u5341\u884c\nprint(content.head(10))\n# \u5206\u8bcd\ncontent['words'] = content['sentence'].apply(lambda s: ' '.join(cut_sentence(s)))\n\n# \u5c06\u5206\u8bcd\u540e\u7684\u7ed3\u679c\u53ea\u4fdd\u755930\u4e2a\u5143\u7d20\ncontent['words'] = content['words'].apply(lambda s: ' '.join(s.split())[:30])\n# \u7ed3\u679c\u5b58\u653e\u5230csv\u6587\u4ef6\u4e2d\ncontent.to_csv('./data/data/train_new.csv')\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Building prefix dict from the default dictionary ...\nDumping model to file cache /tmp/jieba.cache\nLoading model cost 0.908 seconds.\nPrefix dict has been built successfully.\n                    sentence  label  sentence_len                                              words\n0         \u4e2d\u534e\u5973\u5b50\u5b66\u9662\uff1a\u672c\u79d1\u5c42\u6b21\u4ec51\u4e13\u4e1a\u62db\u7537\u751f      3            18           [\u4e2d\u534e, \u5973\u5b50, \u5b66\u9662, \uff1a, \u672c\u79d1, \u5c42\u6b21, \u4ec5, 1, \u4e13\u4e1a, \u62db, \u7537\u751f]\n1     \u4e24\u5929\u4ef7\u7f51\u7ad9\u80cc\u540e\u91cd\u91cd\u8ff7\u96fe\uff1a\u505a\u4e2a\u7f51\u7ad9\u7a76\u7adf\u8981\u591a\u5c11\u94b1      4            22   [\u4e24\u5929, \u4ef7, \u7f51\u7ad9, \u80cc\u540e, \u91cd\u91cd, \u8ff7\u96fe, \uff1a, \u505a\u4e2a, \u7f51\u7ad9, \u7a76\u7adf, \u8981, \u591a\u5c11, \u94b1]\n2  \u4e1c5\u73af\u6d77\u68e0\u516c\u793e230-290\u5e732\u5c45\u51c6\u73b0\u623f98\u6298\u4f18\u60e0      1            25  [\u4e1c, 5, \u73af, \u6d77\u68e0, \u516c\u793e, 230, -, 290, \u5e73, 2, \u5c45, \u51c6\u73b0\u623f, 9...\n3  \u5361\u4f69\u7f57\uff1a\u544a\u8bc9\u4f60\u5fb7\u56fd\u811a\u751f\u731b\u7684\u539f\u56e0 \u4e0d\u5e0c\u671b\u82f1\u5fb7\u6218\u8e22\u70b9\u7403      7            25  [\u5361\u4f69\u7f57, \uff1a, \u544a\u8bc9, \u4f60, \u5fb7\u56fd, \u811a, \u751f\u731b, \u7684, \u539f\u56e0,  , \u4e0d, \u5e0c\u671b, \u82f1\u5fb7...\n4    82\u5c81\u8001\u592a\u4e3a\u5b66\u751f\u505a\u996d\u626b\u573044\u5e74\u83b7\u6388\u6e2f\u5927\u8363\u8a89\u9662\u58eb      5            23  [82, \u5c81, \u8001\u592a, \u4e3a, \u5b66\u751f, \u505a\u996d, \u626b\u5730, 44, \u5e74, \u83b7\u6388, \u6e2f\u5927, \u8363\u8a89, \u9662\u58eb]\n5       \u8bb0\u8005\u56de\u8bbf\u5730\u9707\u4e2d\u53ef\u4e50\u7537\u5b69\uff1a\u5c06\u53d7\u9080\u8d74\u7f8e\u56fd\u53c2\u89c2      5            20         [\u8bb0\u8005, \u56de\u8bbf, \u5730\u9707, \u4e2d, \u53ef\u4e50, \u7537\u5b69, \uff1a, \u5c06, \u53d7\u9080, \u8d74\u7f8e\u56fd, \u53c2\u89c2]\n6          \u51af\u5fb7\u4f26\u5f90\u82e5\ufffd\u9694\u7a7a\u4f20\u60c5 \u9ed8\u8ba4\u5176\u662f\u5973\u53cb      9            17                [\u51af\u5fb7\u4f26, \u5f90\u82e5, \ufffd, \u9694\u7a7a, \u4f20\u60c5,  , \u9ed8\u8ba4, \u5176\u662f, \u5973\u53cb]\n7     \u4f20\u90ed\u6676\u6676\u6b32\u843d\u6237\u9999\u6e2f\u6218\u4f26\u6566\u5965\u8fd0 \u88c5\u4fee\u522b\u5885\u5f53\u5a5a\u623f      1            22   [\u4f20, \u90ed\u6676\u6676, \u6b32, \u843d\u6237, \u9999\u6e2f, \u6218, \u4f26\u6566, \u5965\u8fd0,  , \u88c5\u4fee, \u522b\u5885, \u5f53\u5a5a, \u623f]\n8           \u300a\u8d64\u58c1OL\u300b\u653b\u57ce\u6218\u8bf8\u4faf\u6218\u785d\u70df\u53c8\u8d77      8            16               [\u300a, \u8d64\u58c1, OL, \u300b, \u653b\u57ce\u6218, \u8bf8\u4faf, \u6218, \u785d\u70df, \u53c8, \u8d77]\n9                \u201c\u624b\u673a\u94b1\u5305\u201d\u4eae\u76f8\u79d1\u535a\u4f1a      4            11                            [\u201c, \u624b\u673a, \u94b1\u5305, \u201d, \u4eae\u76f8, \u79d1\u535a\u4f1a]\n</code></pre>"},{"location":"03-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90.html#14","title":"1.4 \u5904\u7406\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6","text":"<p>\u4f9d\u6b21\u540c\u6837\u7684\u4ee3\u7801\u5904\u7406\u9a8c\u8bc1\u96c6dev.txt, \u6d4b\u8bd5\u96c6test.txt, \u540c\u4e00\u4e2a\u6587\u4ef6\u5939\u4e0b\u751f\u6210dev_new.csv, test_new.csv\u6587\u4ef6.</p>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html","title":"\u968f\u673a\u68ee\u6797\u6a21\u578b","text":"<p>\u5b66\u4e60\u76ee\u6807\uff1a</p> <ul> <li>\u638c\u63e1\u5229\u7528\u968f\u673a\u68ee\u6797\u5feb\u901f\u5b9e\u73b0\u5e76\u8bc4\u4f30\u57fa\u7ebf\u6a21\u578b.</li> </ul>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html#1","title":"1.\u968f\u673a\u68ee\u6797\u6a21\u578b","text":"<p>\u7f16\u5199\u4ee3\u7801\u5b9e\u73b0\u968f\u673a\u68ee\u6797\u7684\u6a21\u578b\u8bad\u7ec3. \u4ee3\u7801\u4f4d\u7f6e:</p> <pre><code>02-random_forest/random_forest.py\n</code></pre> <p>\u5bfc\u5165\u5de5\u5177\u5305</p> <pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nfrom icecream import ic\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n</code></pre>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html#11","title":"1.1 \u8bfb\u53d6\u6570\u636e\u96c6","text":"<pre><code># \u6307\u5b9a\u6570\u636e\u96c6\u7684\u4f4d\u7f6e\nTRAIN_CORPUS = './data/data/train_new.csv'\nSTOP_WORDS = './data/data/stopwords.txt'\nWORDS_COLUMN = 'words'\n# \u8bfb\u53d6\u6570\u636e\u96c6\ncontent = pd.read_csv(TRAIN_CORPUS)\n# \u6784\u5efa\u8bed\u6599\u5e93\ncorpus = content[WORDS_COLUMN].values\n</code></pre>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html#12","title":"1.2 \u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u6570\u503c\u7279\u5f81","text":"<p>\u200b   TF-IDF\uff08term frequency\u2013inverse document frequency\uff0c\u8bcd\u9891-\u9006\u5411\u6587\u4ef6\u9891\u7387\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u4fe1\u606f\u68c0\u7d22\uff08information retrieval\uff09\u4e0e\u6587\u672c\u6316\u6398\uff08text mining\uff09\u7684\u5e38\u7528\u52a0\u6743\u6280\u672f\u3002\u5b83\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0cTF \u548c IDF\u3002</p> <p>\u200b       \u7b2c\u4e00\u6b65\uff0c\u8ba1\u7b97\u8bcd\u9891\u3002</p> <p></p> <p>\u8003\u8651\u5230\u6587\u7ae0\u6709\u957f\u77ed\u4e4b\u5206\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u4e0d\u540c\u6587\u7ae0\u7684\u6bd4\u8f83\uff0c\u8fdb\u884c \u201c\u8bcd\u9891\u201d \u6807\u51c6\u5316\uff08\u5f52\u4e00\u5316\uff09\u3002</p> <p></p> <p>\u7b2c\u4e8c\u6b65\uff0c\u8ba1\u7b97\u9006\u6587\u6863\u9891\u7387\u3002\u8fd9\u65f6\uff0c\u9700\u8981\u4e00\u4e2a\u8bed\u6599\u5e93\uff08corpus\uff09\uff0c\u7528\u6765\u6a21\u62df\u8bed\u8a00\u7684\u4f7f\u7528\u73af\u5883\u3002</p> <p></p> <p>\u5982\u679c\u4e00\u4e2a\u8bcd\u8d8a\u5e38\u89c1\uff0c\u90a3\u4e48\u5206\u6bcd\u5c31\u8d8a\u5927\uff0c\u9006\u6587\u6863\u9891\u7387\u5c31\u8d8a\u5c0f\u8d8a\u63a5\u8fd10\u3002\u5206\u6bcd\u4e4b\u6240\u4ee5\u8981\u52a01\uff0c\u662f\u4e3a\u4e86\u907f\u514d\u5206\u6bcd\u4e3a0\uff08\u5373\u6240\u6709\u6587\u6863\u90fd\u4e0d\u5305\u542b\u8be5\u8bcd\uff09\u3002log\u8868\u793a\u5bf9\u5f97\u5230\u7684\u503c\u53d6\u5bf9\u6570\u3002</p> <p>\u7b2c\u4e09\u6b65\uff0c\u8ba1\u7b97TF-IDF\u3002</p> <p></p> <p>TF-IDF \u662f\u4e00\u79cd\u7edf\u8ba1\u65b9\u6cd5\uff0c\u7528\u4ee5\u8bc4\u4f30\u4e00\u5b57\u8bcd\u5bf9\u4e8e\u4e00\u4e2a\u6587\u4ef6\u96c6\u6216\u4e00\u4e2a\u8bed\u6599\u5e93\u4e2d\u7684\u5176\u4e2d\u4e00\u4efd\u6587\u4ef6\u7684\u91cd\u8981\u7a0b\u5ea6\u3002\u5b57\u8bcd\u7684\u91cd\u8981\u6027\u968f\u7740\u5b83\u5728\u6587\u4ef6\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\u7684\u589e\u52a0\u6210\u6b63\u6bd4\u589e\u52a0\uff0c\u4f46\u540c\u65f6\u4f1a\u968f\u7740\u5b83\u5728\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u7684\u9891\u7387\u6210\u53cd\u6bd4\u4e0b\u964d\u3002</p> <p>TF-IDF \u7684\u4e3b\u8981\u601d\u60f3\u662f\uff1a\u5982\u679c\u67d0\u4e2a\u5355\u8bcd\u5728\u4e00\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0\u7684\u9891\u7387 TF \u9ad8\uff0c\u5e76\u4e14\u5728\u5176\u4ed6\u6587\u7ae0\u4e2d\u5f88\u5c11\u51fa\u73b0\uff0c\u5219\u8ba4\u4e3a\u6b64\u8bcd\u6216\u8005\u77ed\u8bed\u5177\u6709\u5f88\u597d\u7684\u7c7b\u522b\u533a\u5206\u80fd\u529b\uff0c\u9002\u5408\u7528\u6765\u5206\u7c7b\u3002</p> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u8bfb\u53d6\u505c\u7528\u8bcd\nstop_words = open(STOP_WORDS).read().split()\n# \u8ba1\u7b97tfidf\u7279\u5f81\ntfidf = TfidfVectorizer(stop_words=stop_words)\ntext_vectors = tfidf.fit_transform(corpus)\n</code></pre>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html#13","title":"1.3 \u5212\u5206\u6570\u636e\u96c6\uff0c\u6a21\u578b\u8bad\u7ec3\u548c\u6a21\u578b\u9884\u6d4b","text":"<pre><code># \u76ee\u6807\u503c\ntargets = content['label']\n# \u5212\u5206\u6570\u636e\u96c6\nx_train, x_test, y_train, y_test = train_test_split(text_vectors, targets, test_size=0.2, random_state=0)\n# \u5b9e\u4f8b\u5316\u6a21\u578b\nmodel = RandomForestClassifier()\n# \u6a21\u578b\u8bad\u7ec3\nmodel.fit(x_train, y_train)\n# \u6a21\u578b\u8bc4\u4f30\naccuracy = accuracy_score(model.predict(x_test), y_test)\nic(accuracy)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>ic| accuracy: 0.8148333333333333\n</code></pre>"},{"location":"04-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A1%88%E4%BE%8B.html#2","title":"2.\u7ed3\u8bba","text":"<p>\u968f\u673a\u68ee\u6797\u6784\u5efa\u6a21\u578b\u7b80\u5355, \u8bad\u7ec3\u5feb, \u6700\u7ec881.48%\u7684\u51c6\u786e\u7387(\u53ef\u4ee5\u89c6\u4f5c80%)\u5bf9\u4e8e10\u5206\u7c7b\u4efb\u52a1\u6765\u8bf4\u4e5f\u662f\u4e0d\u9519\u7684\u6a21\u578b. \u91cd\u8981\u7684\u662f\u6211\u4eec\u5feb\u901f\u62e5\u6709\u4e86\u4e00\u4e2a\u51c6\u786e\u7387\u8fbe\u523080%\u7684\u57fa\u7ebf\u6a21\u578b1.0</p>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html","title":"FastText\u6a21\u578b","text":"<p>\u5b66\u4e60\u76ee\u6807\uff1a</p> <p>1.\u77e5\u9053\u5982\u4f55\u6784\u5efa\u6a21\u578b</p> <p>2.\u80fd\u591f\u8fdb\u884c\u6a21\u578b\u4f18\u5316</p> <p>3.\u80fd\u591f\u5b8c\u6210\u6a21\u578b\u7684\u90e8\u7f72</p> <p>Fasttext\u7684\u6848\u4f8b\u4ee3\u7801\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <p></p>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#1","title":"1.\u6570\u636e\u51c6\u5907","text":"<p>\u4f7f\u7528 fastText \u5de5\u5177\u89e3\u51b3\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u5b58\u653e\u6570\u636e\u96c6\u7684\u6587\u672c\u6587\u4ef6\u5fc5\u987b\u6ee1\u8db3\u4ee5\u4e0b\u4e24\u4e2a\u6761\u4ef6\uff1a</p> <ul> <li> <p>\u6587\u672c\u6587\u4ef6\u4e2d\u7684\u6bcf\u4e00\u884c\u5bf9\u5e94\u4e00\u4e2a\u6587\u6863\uff1b</p> </li> <li> <p>\u6587\u6863\u7684\u7c7b\u522b\u6807\u7b7e\u4ee5 __label__name \u4e3a\u524d\u7f00\u653e\u5728\u6587\u6863\u7684\u6700\u524d\u9762\uff1b </p> </li> </ul> <p>\u4e0b\u9762\u4e3e\u4e24\u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u5c0f\u4f8b\u5b50\u3002</p> <p>\u5355\u6807\u7b7e\u6570\u636e\u96c6\uff1a</p> <pre><code>__label__1 i love you\n__label__0 i hate you\n</code></pre> <p>\u4e0a\u9762\u7684\u5355\u6807\u7b7e\u6570\u636e\u96c6\u4e2d\u4e00\u5171\u6709 2 \u4e2a\u6587\u6863\uff08\u6bcf\u4e00\u884c\u4e00\u4e2a\u6587\u6863\uff09\uff0c\u7b2c\u4e00\u4e2a\u6587\u6863 \"i love you\"\uff0c\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\u4e3a 1\uff08\u5177\u4f53\u7c7b\u522b\u540d\u4e3a  \u524d\u7f00\u540e\u9762\u7684\u6587\u672c\uff09\uff0c\u7b2c\u4e8c\u4e2a\u6587\u6863 \"i hate you\"\uff0c\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\u4e3a 0\u3002</p> <p>\u591a\u6807\u7b7e\u6570\u636e\u96c6\uff1a</p> <pre><code>__label__baking __label__food-safety __label__substitutions __label__peanuts how to seperate peanut oil from roasted peanuts at home?\n__label__chocolate American equivalent for British chocolate terms\n__label__baking __label__oven __label__convection Fan bake vs bake\n__label__sauce __label__storage-lifetime __label__acidity __label__mayonnaise Regulation and balancing of readymade packed mayonnaise and other sauces\n</code></pre> <p>\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e2d\u7684\u4e0d\u540c\u7684\u7c7b\u522b\u6807\u7b7e\u7528\u7a7a\u683c\u6765\u5206\u5272\u3002\u6bd4\u5982\uff1a\u5bf9\u4e8e \"Regulation and balancing of readymade packed mayonnaise and other sauces\" \u6587\u6863\u7684\u7c7b\u522b\u6807\u7b7e\u6709 sauce\u3001storage-lifetime\u3001acidity \u548c mayonnaise 5 \u4e2a\u3002</p> <p>**\u5355\u6807\u7b7e\u548c\u591a\u6807\u7b7e\u6570\u636e\u96c6\u5728 fastText \u7684\u4f7f\u7528\u4e0a\u5e76\u6ca1\u6709\u533a\u522b **</p> <p>\u6240\u4ee5\u9700\u8981\u5c06\u6570\u636e\u5904\u7406\u6210\u4e0a\u8ff0\u5f62\u5f0f\u3002</p> <p>\u4ee3\u7801\u4f4d\u7f6e:</p> <pre><code>03-fast_text/data/data/preprocess.py </code></pre> <ul> <li>\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f</li> </ul> <pre><code># \u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f\uff1aid:label\nid_to_label = {}\n# id\u4ece0\u5f00\u59cb\nidx = 0\n# \u6253\u5f00\u6570\u636e\u96c6\u7c7b\u522b\u6587\u4ef6\nwith open('class.txt', 'r', encoding='utf-8') as f1:\n    # \u904d\u5386\u6bcf\u4e00\u884c\u6587\u672c\n    for line in f1.readlines():\n        # \u53bb\u6389\u6362\u884c\u7b26\u548c\u7a7a\u767d\u7b26\n        line = line.strip('\\n').strip()\n        # \u8bb0\u5f55\u5728\u5b57\u5178\u4e2d\n        id_to_label[idx] = line\n        # id\u589e\u52a0\n        idx += 1\n\nprint('id_to_label:', id_to_label)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a</p> <pre><code>id_to_label: {0: 'finance', 1: 'realty', 2: 'stocks', 3: 'education', 4: 'science', 5: 'society', 6: 'politics', 7: 'sports', 8: 'game', 9: 'entertainment'}\n</code></pre> <ul> <li>\u8bfb\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u5e76\u8f6c\u6362\u4e3afasttext\u8981\u6c42\u7684\u5f62\u5f0f</li> </ul> <pre><code># \u7528\u6765\u5b58\u50a8\u8bad\u7ec3\u96c6\u6570\u636e\ntrain_data = []\n# \u6253\u5f00\u6570\u636e\u96c6\u6587\u4ef6\uff0c\u8fdb\u884c\u5904\u7406\nwith open('train.txt', 'r', encoding='utf-8') as f2:\n    # \u83b7\u53d6\u6bcf\u4e00\u884c\u6570\u636e\n    for line in f2.readlines():\n        line = line.strip('\\n').strip()\n        # \u83b7\u53d6\u6587\u672c\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\u4fe1\u606f\n        sentence, label = line.split('\\t')\n        # 1: \u9996\u5148\u5904\u7406\u6807\u7b7e\u90e8\u5206\uff1a\u83b7\u53d6\u6807\u7b7eid,\u5e76\u83b7\u53d6\u6807\u7b7e\u540d\u79f0\n        label_id = int(label)\n        label_name = id_to_label[label_id]\n        # \u6784\u5efafasttext\u9700\u8981\u7684\u8bad\u7ec3\u96c6\u6570\u636e\n        new_label = '__label__' + label_name\n        # 2: \u7136\u540e\u5904\u7406\u6587\u672c\u90e8\u5206, \u53ef\u4ee5\u6309\u5b57\u5212\u5206, \u4e5f\u53ef\u4ee5\u6309\u8bcd\u5212\u5206\n        sent_char = ' '.join(list(sentence))\n        # 3: \u5c06\u6587\u672c\u548c\u6807\u7b7e\u7ec4\u5408\u6210fasttext\u89c4\u5b9a\u7684\u683c\u5f0f\n        new_sentence = new_label + ' ' + sent_char\n        # 4: \u5c06\u6570\u636e\u6dfb\u52a0\u5230list\u4e2d\n        train_data.append(new_sentence)\nprint(train_data[:5])\n</code></pre> <p>\u7ed3\u679c\u4e3a\uff1a</p> <pre><code>['__label__education \u4e2d \u534e \u5973 \u5b50 \u5b66 \u9662 \uff1a \u672c \u79d1 \u5c42 \u6b21 \u4ec5 1 \u4e13 \u4e1a \u62db \u7537 \u751f', '__label__science \u4e24 \u5929 \u4ef7 \u7f51 \u7ad9 \u80cc \u540e \u91cd \u91cd \u8ff7 \u96fe \uff1a \u505a \u4e2a \u7f51 \u7ad9 \u7a76 \u7adf \u8981 \u591a \u5c11 \u94b1', '__label__realty \u4e1c 5 \u73af \u6d77 \u68e0 \u516c \u793e 2 3 0 - 2 9 0 \u5e73 2 \u5c45 \u51c6 \u73b0 \u623f 9 8 \u6298 \u4f18 \u60e0', '__label__sports \u5361 \u4f69 \u7f57 \uff1a \u544a \u8bc9 \u4f60 \u5fb7 \u56fd \u811a \u751f \u731b \u7684 \u539f \u56e0   \u4e0d \u5e0c \u671b \u82f1 \u5fb7 \u6218 \u8e22 \u70b9 \u7403', '__label__society 8 2 \u5c81 \u8001 \u592a \u4e3a \u5b66 \u751f \u505a \u996d \u626b \u5730 4 4 \u5e74 \u83b7 \u6388 \u6e2f \u5927 \u8363 \u8a89 \u9662 \u58eb']\n</code></pre> <ul> <li>\u5c06\u6570\u636e\u5199\u5165\u5230\u76f8\u5e94\u7684\u6587\u4ef6\u4e2d</li> </ul> <pre><code># \u5c06\u6570\u636e\u5904\u7406\u540e\u7684\u7ed3\u679c\u5b58\u50a8\u5728txt\u6587\u672c\u4e2d\nwith open('train_fast.txt', 'w', encoding='utf-8') as f3:\n    # \u904d\u5386\u6bcf\u4e00\u884c\u6570\u636e\n    for data in train_data:\n        # \u5199\u5165\u5230\u6587\u4ef6\u4e2d\n        f3.write(data + '\\n')\nprint('FastText\u8bad\u7ec3\u6570\u636e\u9884\u5904\u7406\u5b8c\u6bd5!')\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c: \u67e5\u770btrain_fast.txt\u6587\u4ef6\u5982\u4e0b</p> <pre><code>__label__education \u4e2d \u534e \u5973 \u5b50 \u5b66 \u9662 \uff1a \u672c \u79d1 \u5c42 \u6b21 \u4ec5 1 \u4e13 \u4e1a \u62db \u7537 \u751f\n__label__science \u4e24 \u5929 \u4ef7 \u7f51 \u7ad9 \u80cc \u540e \u91cd \u91cd \u8ff7 \u96fe \uff1a \u505a \u4e2a \u7f51 \u7ad9 \u7a76 \u7adf \u8981 \u591a \u5c11 \u94b1\n__label__realty \u4e1c 5 \u73af \u6d77 \u68e0 \u516c \u793e 2 3 0 - 2 9 0 \u5e73 2 \u5c45 \u51c6 \u73b0 \u623f 9 8 \u6298 \u4f18 \u60e0\n__label__sports \u5361 \u4f69 \u7f57 \uff1a \u544a \u8bc9 \u4f60 \u5fb7 \u56fd \u811a \u751f \u731b \u7684 \u539f \u56e0   \u4e0d \u5e0c \u671b \u82f1 \u5fb7 \u6218 \u8e22 \u70b9 \u7403\n__label__society 8 2 \u5c81 \u8001 \u592a \u4e3a \u5b66 \u751f \u505a \u996d \u626b \u5730 4 4 \u5e74 \u83b7 \u6388 \u6e2f \u5927 \u8363 \u8a89 \u9662 \u58eb\n__label__society \u8bb0 \u8005 \u56de \u8bbf \u5730 \u9707 \u4e2d \u53ef \u4e50 \u7537 \u5b69 \uff1a \u5c06 \u53d7 \u9080 \u8d74 \u7f8e \u56fd \u53c2 \u89c2\n__label__entertainment \u51af \u5fb7 \u4f26 \u5f90 \u82e5 \ufffd \u9694 \u7a7a \u4f20 \u60c5   \u9ed8 \u8ba4 \u5176 \u662f \u5973 \u53cb\n__label__realty \u4f20 \u90ed \u6676 \u6676 \u6b32 \u843d \u6237 \u9999 \u6e2f \u6218 \u4f26 \u6566 \u5965 \u8fd0   \u88c5 \u4fee \u522b \u5885 \u5f53 \u5a5a \u623f\n__label__game \u300a \u8d64 \u58c1 O L \u300b \u653b \u57ce \u6218 \u8bf8 \u4faf \u6218 \u785d \u70df \u53c8 \u8d77\n__label__science \u201c \u624b \u673a \u94b1 \u5305 \u201d \u4eae \u76f8 \u79d1 \u535a \u4f1a\n__label__education \u4e0a \u6d77 2 0 1 0 \u4e0a \u534a \u5e74 \u56db \u516d \u7ea7 \u8003 \u8bd5 \u62a5 \u540d 4 \u6708 8 \u65e5 \u524d \u5b8c \u6210\n__label__sports \u674e \u6c38 \u6ce2 \u79f0 \u674e \u5b97 \u4f1f \u96be \u963b \u6797 \u4e39 \u53d6 \u80dc   \u900f \u9732 \u8c22 \u674f \u82b3 \u6709 \u671b \u51fa \u6218\n__label__society 3 \u5c81 \u5973 \u7ae5 \u4e0b \u4f53 \u7ea2 \u80bf   \u81ea \u79f0 \u88ab \u5e7c \u513f \u56ed \u8001 \u5e08 \u7528 \u5c3a \u5b50 \u6345 \u4f24\n__label__stocks \u91d1 \u8bc1 \u987e \u95ee \uff1a \u8fc7 \u5c71 \u8f66 \u884c \u60c5 \u610f \u5473 \u7740 \u4ec0 \u4e48\n__label__realty \u8c01 \u6599 \u5730 \u738b \u5982 \u6b64 \u865a\n__label__game \u300a \u5149 \u73af 5 \u300b L o g o \u6cc4 \u9732   K i n e c t \u7248 \u51e0 \u65e0 \u60ac \u5ff5\n__label__realty \u6d77 \u6dc0 \u533a \u9886 \u79c0 \u65b0 \u7845 \u8c37 \u5bbd \u666f \u5927 \u5b85 \u9884 \u8ba1 1 0 \u6708 \u5e95 \u5f00 \u76d8\n__label__realty \u67f4 \u5fd7 \u5764 \uff1a \u571f \u5730 \u4f9b \u5e94 \u91cf \u4e0d \u65ad \u4ece \u7d27   \u5730 \u4ef7 \u96be \u73b0 0 7 \u6c34 \u5e73 ( \u56fe )\n__label__game \u4f0a \u8fbe \u4f20 \u8bf4 E D D A   O n l i n e\n__label__science \u4e09 \u8054 \u4e66 \u5e97 \u5efa \u8d77 \u4e66 \u9999 \u5df7\n__label__science \u5b87 \u822a \u5458 \u5c3f \u6db2 \u5835 \u585e \u56fd \u9645 \u7a7a \u95f4 \u7ad9 \u6c34 \u5faa \u73af \u7cfb \u7edf\n__label__politics \u7814 \u7a76 \u53d1 \u73b0 \u5f00 \u8f66 \u6280 \u672f \u5dee \u6216 \u4e0e \u57fa \u56e0 \u76f8 \u5173\n__label__sports \u7687 \u9a6c \u8f93 \u7403 \u66ff \u8865 \u5e2d \u95f9 \u4e11 \u95fb   \u961f \u526f \u5973 \u7403 \u8ff7 \u516c \u7136 \u8c03 \u60c5 ( \u89c6 \u9891 )\n__label__realty \u5317 \u4eac \u5efa \u5de5 \u4e0e \u5e02 \u653f \u5e9c \u518d \u5ea6 \u5408 \u4f5c \u63a8 \u51fa \u90ed \u5e84 \u5b50 \u9650 \u4ef7 \u623f\n__label__entertainment \u7ec4 \u56fe \uff1a \u674e \u6b23 \u6c5d \u7d20 \u989c \u51fa \u955c \u62cd \u4f4e \u78b3 \u73af \u4fdd \u5927 \u7247\n</code></pre> <ul> <li>\u540c\u4e0a\u5904\u7406\u6d4b\u8bd5\u96c6\u6570\u636e, \u5f97\u5230test_fast.txt; \u540c\u4e0a\u5904\u7406\u9a8c\u8bc1\u96c6\u7684\u6570\u636e, \u5f97\u5230dev_fast.txt</li> </ul>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#2","title":"2.\u6a21\u578b\u642d\u5efa","text":"<p>\u4ee3\u7801\u4f4d\u7f6e:</p> <pre><code>03-fast_text/fast_text.py\n</code></pre> <p>\u4f7f\u7528train_supervised\u51fd\u6570\u8bad\u7ec3\u6a21\u578b\uff0c\u5176\u4e2d input \u53c2\u6570\u6307\u5b9a\u5305\u542b\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6587\u672c\u6587\u4ef6\uff0c\u51fd\u6570\u8fd4\u56de\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5bf9\u8c61\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e2a\u6a21\u578b\u5bf9\u8c61\u8bbf\u95ee\u8bad\u7ec3\u6a21\u578b\u7684\u5404\u79cd\u4fe1\u606f\u3002</p> <pre><code>import fasttext\n# \u6307\u5b9a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u6570\u636e\ntrain_data_path = './data/data/train_fast.txt'\ntest_data_path = './data/data/test_fast.txt'\n\n# \u5f00\u542f\u6a21\u578b\u8bad\u7ec3\nmodel = fasttext.train_supervised(input=train_data_path, wordNgrams=2)\nprint('\u8bcd\u7684\u6570\u91cf',len(model.words))\nprint('\u6807\u7b7e\u503c',model.labels)\n\n# \u5f00\u542f\u6a21\u578b\u6d4b\u8bd5\nresult = model.test(test_data_path)\n# \u8f93\u51fa\u6d4b\u8bd5\u7ed3\u679c\nprint(result)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Read 3M words\nNumber of words:  4760\nNumber of labels: 10\nProgress: 100.0% words/sec/thread: 1745187 lr:  0.000000 avg.loss:  0.284760 ETA:   0h 0m 0s\n\u8bcd\u7684\u6570\u91cf: 4760\n\u6807\u7b7e\u503c: ['__label__science', '__label__finance', '__label__realty', '__label__sports', '__label__society', '__label__politics', '__label__stocks', '__label__entertainment', '__label__game', '__label__education']\n(10000, 0.9165, 0.9165)\n</code></pre> <p>\u7ed3\u8bba: \u572810000\u6761\u6d4b\u8bd5\u96c6\u4e0a, \u6211\u4eec\u7684\u6a21\u578b\u5f97\u5230\u4e860.9165\u7684\u7cbe\u786e\u7387, 0.9165\u7684\u53ec\u56de\u7387. \u76f8\u6bd4\u8f83\u968f\u673a\u68ee\u6797\u5df2\u7ecf\u6709\u4e86\u5927\u5e45\u5ea6\u7684\u63d0\u5347.</p>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#3","title":"3.\u6a21\u578b\u4f18\u5316","text":"<ul> <li>\u5bf9\u4e8e\u4efb\u610f\u8868\u73b0\u826f\u597d\u7684\u6a21\u578b, \u4f18\u5316\u7684\u811a\u6b65\u90fd\u4e0d\u80fd\u505c\u6b62!</li> </ul>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#31-fasttext1","title":"3.1 fasttext\u4f18\u53161","text":"<p>\u5728\u771f\u5b9e\u7684\u751f\u4ea7\u73af\u5883\u4e0b, \u5bf9\u4e8efasttext\u6a21\u578b\u4e00\u822c\u4e0d\u4f1a\u91c7\u7528\u8d39\u65f6\u8d39\u529b\u7684\u4eba\u5de5\u8c03\u53c2, \u800c\u90fd\u662f\u7528\u81ea\u52a8\u5316\u6700\u4f18\u53c2\u6570\u641c\u7d22\u7684\u6a21\u5f0f.\u8be5\u4ee3\u7801\u4f4d\u7f6e\u5728\uff1a <pre><code>03-fast_text/fast_text_2.py\n</code></pre></p> <p>\u63a5\u4e0b\u6765\u4f7f\u7528 FastText \u6846\u67b6\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u3001\u6d4b\u8bd5\u548c\u4fdd\u5b58\uff0c\u5177\u4f53\u8fc7\u7a0b\u4e3a\uff1a</p> <ol> <li>\u6307\u5b9a\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u7684\u6587\u4ef6\u8def\u5f84\u3002</li> <li>\u4f7f\u7528 <code>fasttext.train_supervised</code> \u51fd\u6570\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u6765\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002</li> <li>\u4f7f\u7528 <code>model.test</code> \u51fd\u6570\u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u8f93\u51fa\u8bc4\u4f30\u7ed3\u679c\u3002</li> <li>\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4fdd\u5b58\u5230\u6587\u4ef6\u4e2d\uff0c\u6587\u4ef6\u540d\u5305\u542b\u5f53\u524d\u65f6\u95f4\u6233\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>import fasttext\nimport time\n\n# \u83b7\u53d6\u8bad\u7ec3\u96c6,\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u8def\u5f84\ntrain_data_path = 'data/data/train_fast.txt'\ndev_data_path = 'data/data/dev_fast.txt'\ntest_data_path = 'data/data/test_fast.txt'\n\n# \u5f00\u542f\u6a21\u578b\u8bad\u7ec3\n# autotuneValidationFile\u53c2\u6570\u9700\u8981\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6\u6240\u5728\u7684\u8def\u5f84\n# \u5b83\u5c06\u5728\u9a8c\u8bc1\u96c6\u662f\u4f7f\u7528\u968f\u673a\u641c\u7d22\u7684\u65b9\u6cd5\u5bfb\u627e\u6700\u4f18\u7684\u8d85\u53c2\u6570\n# \u4f7f\u7528autotuneDuration\u53c2\u6570\u53ef\u4ee5\u63a7\u5236\u968f\u673a\u641c\u7d22\u7684\u65f6\u95f4, \u9ed8\u8ba4\u662f300\u79d2.\n# \u6839\u636e\u4e0d\u540c\u7684\u9700\u6c42, \u53ef\u4ee5\u5ef6\u957f\u6216\u8005\u7f29\u77ed\u65f6\u95f4.\n# \u8c03\u8282\u7684\u8d85\u53c2\u6570\u5305\u542b\u8fd9\u4e9b\u5185\u5bb9:\n# lr                         \u5b66\u4e60\u7387 default 0.1\n# dim                        \u8bcd\u5411\u91cf\u7ef4\u5ea6 default 100\n# ws                         \u4e0a\u4e0b\u6587\u7a97\u53e3\u5927\u5c0f default 5\uff0c cbow\n# epoch                      epochs \u6570\u91cf default 5\n# minCount                   \u6700\u4f4e\u8bcd\u9891 default 5\n# wordNgrams                 n-gram\u8bbe\u7f6e default 1\n# loss                       \u635f\u5931\u51fd\u6570 {hs,softmax} default softmax\n# minn                       \u6700\u5c0f\u5b57\u7b26\u957f\u5ea6 default 0\n# maxn                       \u6700\u5927\u5b57\u7b26\u957f\u5ea6 default 0\n# \u6211\u4eec\u8bbe\u7f6everbose\u6765\u89c2\u5bdf\u8d85\u53c2\u6570\u7684\u503c\n# verbose: \u8be5\u53c2\u6570\u51b3\u5b9a\u65e5\u5fd7\u6253\u5370\u7ea7\u522b, \u5f53\u8bbe\u7f6e\u4e3a3, \u53ef\u4ee5\u5c06\u5f53\u524d\u6b63\u5728\u5c1d\u8bd5\u7684\u8d85\u53c2\u6570\u6253\u5370\u51fa\u6765\nmodel = fasttext.train_supervised(input=train_data_path, # \u8bad\u7ec3\u96c6\u8def\u5f84\n                                  autotuneValidationFile=dev_data_path, # \u9a8c\u8bc1\u96c6\u8def\u5f84\n                                  autotuneDuration=6, # \u65f6\u95f4\u5355\u4f4d\u4e3as\n                                  wordNgrams=2, # N_gram\n                                  verbose=3)\n\n\n# \u5f00\u542f\u6a21\u578b\u6d4b\u8bd5\nresult = model.test(test_data_path)\nprint(result)\n\n# \u83b7\u53d6\u5f53\u524d\u65f6\u95f4,\u4f5c\u4e3a\u6a21\u578b\u6587\u4ef6\u7684\u540d\u79f0\ntime1 = int(time.time())\nmodel_save_path = \"./toutiao_fasttext_{}.bin\".format(time1)\n# \u6a21\u578b\u4fdd\u5b58\nmodel.save_model(model_save_path)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>/Users/mac/opt/anaconda3/envs/dltorch/bin/python /Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/03-fast_text/fast_text_2.py\nTrial = 1\nepoch = 5\nlr = 0.1\ndim = 100\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2000000\ndsub = 2\nloss = softmax\nWarning : wordNgrams is manually set to a specific value. It will not be automatically optimized.\nProgress:  33.5% Trials:    1 Best score:   unknown ETA:   0h 0m 3scurrentScore = 0.912\ntrain took = 2.26149\nTrial = 2\nepoch = 1\nlr = 0.705001\ndim = 320\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2211530\ndsub = 2\nloss = softmax\nProgress: 100.0% Trials:    2 Best score:  0.912000 ETA:   0h 0m 0s\nTraining again with best arguments\ncurrentScore = 0.9051\ntrain took = 4.87654\nBest selected args = 0\nepoch = 5\nlr = 0.1\ndim = 100\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2000000\ndsub = 2\nloss = softmax\nRead 3M words\nNumber of words:  4760\nNumber of labels: 10\nProgress: 100.0% words/sec/thread: 1844699 lr:  0.000000 avg.loss:  0.283439 ETA:   0h 0m 0s\n(10000, 0.9172, 0.9172)\n</code></pre> <p>\u6a21\u578b\u7684\u4fdd\u5b58\u7ed3\u679c\u4e3a\uff1a</p> <p></p> <p>\u7ed3\u8bba: \u7ecf\u8fc7\u53c2\u6570\u7684\u81ea\u52a8\u641c\u7d22, \u5f97\u5230\u4e86\u6700\u597d\u7684\u4e00\u7248\u6a21\u578b, \u4e3b\u8981\u53c2\u6570\u5305\u62ec\u8bcd\u5d4c\u5165\u7ef4\u5ea6dim=355, wordNgrams=2\u7b49. \u6a21\u578b\u7684\u6700\u7ec8\u8868\u73b0\u7cbe\u51c6\u7387\u7b49\u4e8e91.73%, \u53ec\u56de\u7387\u4e5f\u662f91.73%, \u76f8\u6bd4\u8f83\u6700\u521d\u768491.62%\u6709\u7a0d\u8bb8\u63d0\u5347\u4f46\u5e76\u4e0d\u663e\u8457.</p>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#32-fasttext2","title":"3.2 fasttext\u4f18\u53162","text":"<p>\u6a21\u578b\u7684\u4f18\u5316\u4e0d\u4ec5\u4ec5\u5728\u67b6\u6784\u4e0a, \u66f4\u8981\u6ce8\u610f\u56de\u6eaf\u5230\u6e90\u5934, \u4e5f\u5c31\u662f\u6570\u636e\u7aef\u7684\u4f18\u5316. * \u7b2c\u4e00\u6b65: \u539f\u59cb\u6570\u636e\u91c7\u7528\u8bcd\u5411\u91cf\u7ea7\u522b. * \u7b2c\u4e8c\u6b65: \u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u5e76\u8bc4\u4f30.</p> <p>\u7b2c\u4e00\u6b65: \u539f\u59cb\u6570\u636e\u91c7\u7528\u8bcd\u5411\u91cf\u7ea7\u522b.</p> <p>\u4ee3\u7801\u4f4d\u7f6e: </p> <pre><code>03-fast_text/data/data/preprocess1.py\n</code></pre> <p>\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f</p> <pre><code>import jieba\n# \u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f\uff1aid:label\nid_to_label = {}\n# id\u4ece0\u5f00\u59cb\nidx = 0\n# \u6253\u5f00\u6570\u636e\u96c6\u7c7b\u522b\u6587\u4ef6\nwith open('class.txt', 'r', encoding='utf-8') as f1:\n    # \u904d\u5386\u6bcf\u4e00\u884c\u6587\u672c\n    for line in f1.readlines():\n        # \u53bb\u6389\u6362\u884c\u7b26\u548c\u7a7a\u767d\u7b26\n        line = line.strip('\\n').strip()\n        # \u8bb0\u5f55\u5728\u5b57\u5178\u4e2d\n        id_to_label[idx] = line\n        # id\u589e\u52a0\n        idx += 1\n\nprint('id_to_label:', id_to_label)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a</li> </ul> <pre><code>id_to_label: {0: 'finance', 1: 'realty', 2: 'stocks', 3: 'education', 4: 'science', 5: 'society', 6: 'politics', 7: 'sports', 8: 'game', 9: 'entertainment'}\n</code></pre> <p>\u8bfb\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u5e76\u8f6c\u6362\u4e3afasttext\u8981\u6c42\u7684\u5f62\u5f0f</p> <pre><code># \u7528\u6765\u5b58\u50a8\u8bad\u7ec3\u96c6\u6570\u636e\ntrain_data = []\n# \u6253\u5f00\u6570\u636e\u96c6\u6587\u4ef6\uff0c\u8fdb\u884c\u5904\u7406\nwith open('train.txt', 'r', encoding='utf-8') as f2:\n    # \u83b7\u53d6\u6bcf\u4e00\u884c\u6570\u636e\n    for line in f2.readlines():\n        line = line.strip('\\n').strip()\n        # \u83b7\u53d6\u6587\u672c\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\u4fe1\u606f\n        sentence, label = line.split('\\t')\n        # 1: \u9996\u5148\u5904\u7406\u6807\u7b7e\u90e8\u5206\uff1a\u83b7\u53d6\u6807\u7b7eid,\u5e76\u83b7\u53d6\u6807\u7b7e\u540d\u79f0\n        label_id = int(label)\n        label_name = id_to_label[label_id]\n        # \u6784\u5efafasttext\u9700\u8981\u7684\u8bad\u7ec3\u96c6\u6570\u636e\n        new_label = '__label__' + label_name\n        # 2: \u7136\u540e\u5904\u7406\u6587\u672c\u90e8\u5206, \u53ef\u4ee5\u6309\u5b57\u5212\u5206, \u4e5f\u53ef\u4ee5\u6309\u8bcd\u5212\u5206\n        sent_char = ' '.join(list(jieba.cut(sentence)))\n        # 3: \u5c06\u6587\u672c\u548c\u6807\u7b7e\u7ec4\u5408\u6210fasttext\u89c4\u5b9a\u7684\u683c\u5f0f\n        new_sentence = new_label + ' ' + sent_char\n        # 4: \u5c06\u6570\u636e\u6dfb\u52a0\u5230list\u4e2d\n        train_data.append(new_sentence)\nprint(train_data[:5])\n</code></pre> <ul> <li>\u7ed3\u679c\u4e3a\uff1a</li> </ul> <pre><code>['__label__education \u4e2d\u534e \u5973\u5b50 \u5b66\u9662 \uff1a \u672c\u79d1 \u5c42\u6b21 \u4ec5 1 \u4e13\u4e1a \u62db \u7537\u751f', '__label__science \u4e24\u5929 \u4ef7 \u7f51\u7ad9 \u80cc\u540e \u91cd\u91cd \u8ff7\u96fe \uff1a \u505a\u4e2a \u7f51\u7ad9 \u7a76\u7adf \u8981 \u591a\u5c11 \u94b1', '__label__realty \u4e1c 5 \u73af \u6d77\u68e0 \u516c\u793e 230 - 290 \u5e73 2 \u5c45 \u51c6\u73b0\u623f 98 \u6298 \u4f18\u60e0', '__label__sports \u5361\u4f69\u7f57 \uff1a \u544a\u8bc9 \u4f60 \u5fb7\u56fd \u811a \u751f\u731b \u7684 \u539f\u56e0   \u4e0d \u5e0c\u671b \u82f1\u5fb7 \u6218 \u8e22 \u70b9\u7403', '__label__society 82 \u5c81 \u8001\u592a \u4e3a \u5b66\u751f \u505a\u996d \u626b\u5730 44 \u5e74 \u83b7\u6388 \u6e2f\u5927 \u8363\u8a89 \u9662\u58eb']\n</code></pre> <p>\u5c06\u6570\u636e\u5199\u5165\u5230\u76f8\u5e94\u7684\u6587\u4ef6\u4e2d</p> <pre><code># \u5c06\u6570\u636e\u5904\u7406\u540e\u7684\u7ed3\u679c\u5b58\u50a8\u5728txt\u6587\u672c\u4e2d\nwith open('train_fast.txt', 'w', encoding='utf-8') as f3:\n    # \u904d\u5386\u6bcf\u4e00\u884c\u6570\u636e\n    for data in train_data:\n        # \u5199\u5165\u5230\u6587\u4ef6\u4e2d\n        f3.write(data + '\\n')\nprint('FastText\u8bad\u7ec3\u6570\u636e\u9884\u5904\u7406\u5b8c\u6bd5!')\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c(\u67e5\u770btrain_fast1.txt\u6587\u4ef6):</li> </ul> <pre><code>__label__education      \u4e2d\u534e \u5973\u5b50 \u5b66\u9662 \uff1a \u672c\u79d1 \u5c42\u6b21 \u4ec5 1 \u4e13\u4e1a \u62db \u7537\u751f\n__label__science        \u4e24\u5929 \u4ef7 \u7f51\u7ad9 \u80cc\u540e \u91cd\u91cd \u8ff7\u96fe \uff1a \u505a\u4e2a \u7f51\u7ad9 \u7a76\u7adf \u8981 \u591a\u5c11 \u94b1\n__label__realty \u4e1c 5 \u73af \u6d77\u68e0 \u516c\u793e 230 - 290 \u5e73 2 \u5c45 \u51c6\u73b0\u623f 98 \u6298 \u4f18\u60e0\n__label__sports \u5361\u4f69\u7f57 \uff1a \u544a\u8bc9 \u4f60 \u5fb7\u56fd \u811a \u751f\u731b \u7684 \u539f\u56e0   \u4e0d \u5e0c\u671b \u82f1\u5fb7 \u6218 \u8e22 \u70b9\u7403\n__label__society        82 \u5c81 \u8001\u592a \u4e3a \u5b66\u751f \u505a\u996d \u626b\u5730 44 \u5e74 \u83b7\u6388 \u6e2f\u5927 \u8363\u8a89 \u9662\u58eb\n__label__society        \u8bb0\u8005 \u56de\u8bbf \u5730\u9707 \u4e2d \u53ef\u4e50 \u7537\u5b69 \uff1a \u5c06 \u53d7\u9080 \u8d74\u7f8e\u56fd \u53c2\u89c2\n__label__entertainment  \u51af\u5fb7\u4f26 \u5f90\u82e5 \ufffd \u9694\u7a7a \u4f20\u60c5   \u9ed8\u8ba4 \u5176\u662f \u5973\u53cb\n__label__realty \u4f20 \u90ed\u6676\u6676 \u6b32 \u843d\u6237 \u9999\u6e2f \u6218 \u4f26\u6566 \u5965\u8fd0   \u88c5\u4fee \u522b\u5885 \u5f53\u5a5a \u623f\n__label__game   \u300a \u8d64\u58c1 OL \u300b \u653b\u57ce\u6218 \u8bf8\u4faf \u6218 \u785d\u70df \u53c8 \u8d77\n__label__science        \u201c \u624b\u673a \u94b1\u5305 \u201d \u4eae\u76f8 \u79d1\u535a\u4f1a\n__label__education      \u4e0a\u6d77 2010 \u4e0a\u534a\u5e74 \u56db\u516d\u7ea7 \u8003\u8bd5 \u62a5\u540d 4 \u6708 8 \u65e5\u524d \u5b8c\u6210\n__label__sports \u674e\u6c38\u6ce2 \u79f0 \u674e\u5b97\u4f1f \u96be \u963b\u6797\u4e39 \u53d6\u80dc   \u900f\u9732 \u8c22\u674f\u82b3 \u6709\u671b \u51fa\u6218\n__label__society        3 \u5c81 \u5973\u7ae5 \u4e0b\u4f53 \u7ea2\u80bf   \u81ea\u79f0 \u88ab \u5e7c\u513f\u56ed \u8001\u5e08 \u7528 \u5c3a\u5b50 \u6345 \u4f24\n__label__stocks \u91d1\u8bc1 \u987e\u95ee \uff1a \u8fc7\u5c71\u8f66 \u884c\u60c5 \u610f\u5473\u7740 \u4ec0\u4e48\n__label__realty \u8c01\u6599 \u5730 \u738b \u5982\u6b64 \u865a\n__label__game   \u300a \u5149\u73af 5 \u300b Logo \u6cc4\u9732   Kinect \u7248\u51e0\u65e0 \u60ac\u5ff5\n__label__realty \u6d77\u6dc0\u533a \u9886\u79c0\u65b0 \u7845\u8c37 \u5bbd\u666f \u5927\u5b85 \u9884\u8ba1 10 \u6708\u5e95 \u5f00\u76d8\n__label__realty \u67f4\u5fd7\u5764 \uff1a \u571f\u5730 \u4f9b\u5e94\u91cf \u4e0d\u65ad \u4ece \u7d27   \u5730\u4ef7 \u96be\u73b0 07 \u6c34\u5e73 ( \u56fe )\n__label__game   \u4f0a\u8fbe \u4f20\u8bf4 EDDA   Online\n__label__science        \u4e09\u8054\u4e66\u5e97 \u5efa\u8d77 \u4e66\u9999 \u5df7\n__label__science        \u5b87\u822a\u5458 \u5c3f\u6db2 \u5835\u585e \u56fd\u9645 \u7a7a\u95f4\u7ad9 \u6c34 \u5faa\u73af\u7cfb\u7edf\n__label__politics       \u7814\u7a76 \u53d1\u73b0 \u5f00\u8f66 \u6280\u672f \u5dee \u6216 \u4e0e \u57fa\u56e0 \u76f8\u5173\n__label__sports \u7687\u9a6c \u8f93\u7403 \u66ff\u8865\u5e2d \u95f9 \u4e11\u95fb   \u961f \u526f \u5973\u7403\u8ff7 \u516c\u7136 \u8c03\u60c5 ( \u89c6\u9891 )\n__label__realty \u5317\u4eac \u5efa\u5de5 \u4e0e \u5e02\u653f\u5e9c \u518d\u5ea6 \u5408\u4f5c \u63a8\u51fa \u90ed \u5e84\u5b50 \u9650\u4ef7 \u623f\n__label__entertainment  \u7ec4\u56fe \uff1a \u674e\u6b23\u6c5d\u7d20 \u989c \u51fa\u955c \u62cd\u4f4e \u78b3 \u73af\u4fdd \u5927\u7247\n</code></pre> <p>\u6d4b\u8bd5\u96c6\u540c\u6837\u7684\u65b9\u6cd5\u8fdb\u884c\u5904\u7406, \u5f97\u5230\u7ed3\u679c\u6587\u4ef6test_fast1.txt; \u9a8c\u8bc1\u96c6\u540c\u6837\u7684\u65b9\u6cd5\u8fdb\u884c\u5904\u7406, \u5f97\u5230\u7ed3\u679c\u6587\u4ef6dev_fast1.txt</p> <p>\u6a21\u578b\u8bad\u7ec3, \u4ee3\u7801\u4f4d\u7f6e: </p> <pre><code>03-fast_text/fast_text_3.py\n</code></pre> <p>\u8be5\u4ee3\u7801\u4e0efast_text_2.py\u662f\u5b8c\u5168\u4e00\u6837\u7684\uff0c\u4e0d\u540c\u7684\u662f\u6570\u636e\u96c6\u7684\u4f4d\u7f6e\u4e0d\u4e00\u6837</p> <pre><code>import fasttext\nimport time\n\n# \u83b7\u53d6\u8bad\u7ec3\u96c6,\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u8def\u5f84\ntrain_data_path = 'data/data/train_fast1.txt'\ndev_data_path = 'data/data/dev_fast1.txt'\ntest_data_path = 'data/data/test_fast1.txt'\n\n# \u5f00\u542f\u6a21\u578b\u8bad\u7ec3\n# autotuneValidationFile\u53c2\u6570\u9700\u8981\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6\u6240\u5728\u7684\u8def\u5f84\n# \u5b83\u5c06\u5728\u9a8c\u8bc1\u96c6\u662f\u4f7f\u7528\u968f\u673a\u641c\u7d22\u7684\u65b9\u6cd5\u5bfb\u627e\u6700\u4f18\u7684\u8d85\u53c2\u6570\n# \u4f7f\u7528autotuneDuration\u53c2\u6570\u53ef\u4ee5\u63a7\u5236\u968f\u673a\u641c\u7d22\u7684\u65f6\u95f4, \u9ed8\u8ba4\u662f300\u79d2.\n# \u6839\u636e\u4e0d\u540c\u7684\u9700\u6c42, \u53ef\u4ee5\u5ef6\u957f\u6216\u8005\u7f29\u77ed\u65f6\u95f4.\n# \u8c03\u8282\u7684\u8d85\u53c2\u6570\u5305\u542b\u8fd9\u4e9b\u5185\u5bb9:\n# lr                         \u5b66\u4e60\u7387 default 0.1\n# dim                        \u8bcd\u5411\u91cf\u7ef4\u5ea6 default 100\n# ws                         \u4e0a\u4e0b\u6587\u7a97\u53e3\u5927\u5c0f default 5\uff0c cbow\n# epoch                      epochs \u6570\u91cf default 5\n# minCount                   \u6700\u4f4e\u8bcd\u9891 default 5\n# wordNgrams                 n-gram\u8bbe\u7f6e default 1\n# loss                       \u635f\u5931\u51fd\u6570 {hs,softmax} default softmax\n# minn                       \u6700\u5c0f\u5b57\u7b26\u957f\u5ea6 default 0\n# maxn                       \u6700\u5927\u5b57\u7b26\u957f\u5ea6 default 0\n# \u6211\u4eec\u8bbe\u7f6everbose\u6765\u89c2\u5bdf\u8d85\u53c2\u6570\u7684\u503c\n# verbose: \u8be5\u53c2\u6570\u51b3\u5b9a\u65e5\u5fd7\u6253\u5370\u7ea7\u522b, \u5f53\u8bbe\u7f6e\u4e3a3, \u53ef\u4ee5\u5c06\u5f53\u524d\u6b63\u5728\u5c1d\u8bd5\u7684\u8d85\u53c2\u6570\u6253\u5370\u51fa\u6765\nmodel = fasttext.train_supervised(input=train_data_path, # \u8bad\u7ec3\u96c6\u8def\u5f84\n                                  autotuneValidationFile=dev_data_path, # \u9a8c\u8bc1\u96c6\u8def\u5f84\n                                  autotuneDuration=6, # \u65f6\u95f4\u5355\u4f4d\u4e3as\n                                  wordNgrams=2, # N_gram\n                                  verbose=3)\n\n\n# \u5f00\u542f\u6a21\u578b\u6d4b\u8bd5\nresult = model.test(test_data_path)\nprint(result)\n\n# \u83b7\u53d6\u5f53\u524d\u65f6\u95f4,\u4f5c\u4e3a\u6a21\u578b\u6587\u4ef6\u7684\u540d\u79f0\ntime1 = int(time.time())\nmodel_save_path = \"./toutiao_fasttext_{}.bin\".format(time1)\n# \u6a21\u578b\u4fdd\u5b58\nmodel.save_model(model_save_path)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Warning : wordNgrams is manually set to a specific value. It will not be automatically optimized.\nTrial = 1\nepoch = 5\nlr = 0.1\ndim = 100\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2000000\ndsub = 2\nloss = softmax\nProgress:  41.9% Trials:    1 Best score:   unknown ETA:   0h 0m 3scurrentScore = 0.902\ntrain took = 2.6367\nTrial = 2\nepoch = 1\nlr = 0.595139\ndim = 268\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2201775\ndsub = 2\nloss = softmax\nProgress: 100.0% Trials:    2 Best score:  0.902000 ETA:   0h 0m 0s\ncurrentScore = 0.8978\ntrain took = 4.49292\nBest selected args = 0\nepoch = 5\nlr = 0.1\ndim = 100\nminCount = 1\nwordNgrams = 2\nminn = 0\nmaxn = 0\nbucket = 2000000\ndsub = 2\nloss = softmax\nTraining again with best arguments\nRead 2M words\nNumber of words:  118456\nNumber of labels: 10\nProgress: 100.0% words/sec/thread: 1049980 lr:  0.000000 avg.loss:  0.235721 ETA:   0h 0m 0s\n(10000, 0.9093, 0.9093)\n</code></pre> <p>\u6a21\u578b\u4fdd\u5b58\u7ed3\u679c\u4e3a\uff1a</p> <p></p> <p>\u7ed3\u8bba: \u91c7\u7528\u8bcd\u4e3a\u5355\u4f4d\u7684\u6a21\u578b\u6548\u679c\u7cbe\u51c6\u7387\u548c\u53ec\u56de\u7387\u90fd\u8fbe\u5230\u4e8690.93%, \u76f8\u6bd4\u4e8e\u524d\u9762\u7684\u5b9e\u9a8c\u5e76\u6ca1\u6709\u5f97\u5230\u63d0\u5347\u3002</p>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#4","title":"4. \u6a21\u578b\u90e8\u7f72","text":"<ul> <li>\u5de5\u4e1a\u754c\u4e2d\u7684AI\u662f\u6307\"\u80fd\u843d\u5730\u7684AI\", \u5373\u6307\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u53ef\u4ee5\u90e8\u7f72\u5e76\u63d0\u4f9b\u5728\u7ebf, \u6216\u79bb\u7ebf\u4f5c\u4e1a\u7684\u6a21\u578b.<ul> <li>\u7b2c\u4e00\u6b65: \u7f16\u5199\u4e3b\u670d\u52a1\u903b\u8f91\u4ee3\u7801.</li> <li>\u7b2c\u4e8c\u6b65: \u542f\u52a8Flask\u670d\u52a1.</li> <li>\u7b2c\u4e09\u6b65: \u7f16\u5199\u6d4b\u8bd5\u4ee3\u7801.</li> <li>\u7b2c\u56db\u6b65: \u6267\u884c\u6d4b\u8bd5\u5e76\u68c0\u9a8c\u7ed3\u679c.</li> </ul> </li> </ul>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#41","title":"4.1  \u670d\u52a1\u7aef\u4ee3\u7801.","text":"<p>\u4ee3\u7801\u4f4d\u7f6e:</p> <pre><code> 03-fast_text/app.py\n</code></pre> <p>\u670d\u52a1\u7aef\u4ee3\u7801\u5b9e\u73b0\u4e86\u4e00\u4e2a\u4f7f\u7528 FastText \u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u7684 Flask \u670d\u52a1\u3002\u670d\u52a1\u63a5\u6536\u5305\u542b\u7528\u6237ID (<code>uid</code>) \u548c\u6587\u672c (<code>text</code>) \u7684 POST \u8bf7\u6c42\uff0c\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u8bcd\u540e\uff0c\u4f7f\u7528\u4e8b\u5148\u8bad\u7ec3\u597d\u7684 FastText \u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u5e76\u8fd4\u56de\u5206\u7c7b\u7ed3\u679c\u3002</p> <pre><code>import time\nimport jieba\nimport fasttext\n\n# \u670d\u52a1\u6846\u67b6\u4f7f\u7528Flask, \u5bfc\u5165\u5de5\u5177\u5305\nfrom flask import Flask\nfrom flask import request\napp = Flask(__name__)\n\n# \u5bfc\u5165\u53d1\u9001http\u8bf7\u6c42\u7684requests\u5305\nimport requests\n\n# \u52a0\u8f7d\u81ea\u5b9a\u4e49\u7684\u505c\u7528\u8bcd\u8868\njieba.load_userdict('./data/data/stopwords.txt')\n\n# \u63d0\u4f9b\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8def\u5f84\nmodel_save_path = 'toutiao_fasttext_1699862718.bin'\n\n# \u5b9e\u4f8b\u5316fasttext\u5bf9\u8c61, \u5e76\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\u7528\u4e8e\u63a8\u65ad, \u63d0\u4f9b\u670d\u52a1\u8bf7\u6c42\nmodel = fasttext.load_model(model_save_path)\nprint('FastText\u6a21\u578b\u5b9e\u4f8b\u5316\u5b8c\u6bd5...')\n\n# \u8bbe\u5b9a\u6295\u6ee1\u5206\u9879\u76ee\u7684\u670d\u52a1\u7684\u8def\u7531\u548c\u8bf7\u6c42\u65b9\u6cd5\n@app.route('/v1/main_server/', methods=[\"POST\"])\ndef main_server():\n    # \u63a5\u6536\u6765\u81ea\u8bf7\u6c42\u65b9\u53d1\u9001\u7684\u670d\u52a1\u5b57\u6bb5\n    uid = request.form['uid']\n    text = request.form['text']\n\n    # \u5bf9\u8bf7\u6c42\u6587\u672c\u8fdb\u884c\u5904\u7406, \u56e0\u4e3a\u524d\u9762\u52a0\u8f7d\u7684\u662f\u57fa\u4e8e\u5206\u8bcd\u7684\u6a21\u578b, \u6240\u4ee5\u8fd9\u91cc\u4e5f\u8981\u5bf9text\u8fdb\u884c\u5206\u8bcd\u64cd\u4f5c\n    input_text = ' '.join(jieba.lcut(text))\n\n    # \u6267\u884c\u6a21\u578b\u7684\u9884\u6d4b\n    res = model.predict(input_text)\n    predict_name = res[0][0]\n\n    return predict_name\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0',port=5000)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Building prefix dict from the default dictionary ...\nLoading model from cache /var/folders/tp/phgg55c9549cnr0qyp8qf4j40000gn/T/jieba.cache\nLoading model cost 0.647 seconds.\nPrefix dict has been built successfully.\nWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\nFastText\u6a21\u578b\u5b9e\u4f8b\u5316\u5b8c\u6bd5...\n * Serving Flask app 'app'\n * Debug mode: off\nWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n * Running on all addresses (0.0.0.0)\n * Running on http://127.0.0.1:5000\n * Running on http://172.16.43.153:5000\n</code></pre>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#42","title":"4.2 \u5ba2\u6237\u7aef\u4ee3\u7801.","text":"<p>\u4ee3\u7801\u4f4d\u7f6e: </p> <pre><code>03-fast_text/test.py\n</code></pre> <p>\u5ba2\u6237\u7aef\u4ee3\u7801\u5b9e\u73b0\u4e86\u5411\u524d\u9762\u6240\u8ff0 FastText \u6a21\u578b\u63d0\u4f9b\u7684 Flask \u670d\u52a1\u53d1\u9001 HTTP POST \u8bf7\u6c42\uff0c\u5e76\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c\u548c\u9884\u6d4b\u8017\u65f6\u3002</p> <pre><code>import requests\nimport time\n\n# \u5b9a\u4e49\u8bf7\u6c42\u7684url\u5730\u5740\u548c\u4f20\u5165\u7684\u6570\u636e\nurl = \"http://0.0.0.0:5000/v1/main_server/\"\ndata = {\"uid\": \"AI-6-202204\", \"text\": \"\u516c\u5171\u82f1\u8bed(PETS)\u5199\u4f5c\u4e2d\u5e38\u89c1\u7684\u903b\u8f91\u8bcd\u6c47\u6c47\u603b\"}\n# \u8ba1\u65f6\nstart_time = time.time()\n# \u5411\u670d\u52a1\u53d1\u9001\u8bf7\u6c42\nres = requests.post(url, data=data)\n# \u83b7\u53d6\u5904\u7406\u65f6\u95f4\ncost_time = time.time() - start_time\n\n# \u6253\u5370\u8fd4\u56de\u7ed3\u679c\nprint('\u8f93\u5165\u6587\u672c:', data['text'])\nprint('\u5206\u7c7b\u7ed3\u679c:', res.text)\nprint('\u5355\u6761\u6837\u672c\u9884\u6d4b\u7684\u8017\u65f6:', cost_time * 1000, 'ms')\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>\u8f93\u5165\u6587\u672c: \u516c\u5171\u82f1\u8bed(PETS)\u5199\u4f5c\u4e2d\u5e38\u89c1\u7684\u903b\u8f91\u8bcd\u6c47\u6c47\u603b\n\u5206\u7c7b\u7ed3\u679c: __label__education\n\u5355\u6761\u6837\u672c\u9884\u6d4b\u8017\u65f6:  4.739046096801758 ms\n</code></pre>"},{"location":"05-fasttext%E5%AE%9E%E7%8E%B0.html#5","title":"5. \u7ed3\u8bba","text":"<p>\u9884\u6d4b\u7ed3\u679c\u8fd8\u4e0d\u9519, \u540c\u65f6\u66f4\u91cd\u8981\u7684\u662f\u5728GPU\u73af\u5883\u4e0b\u9884\u6d4b\u65f6\u95f4\u4ec5\u4ec5\u4e0d\u52305ms!!! \u8fd9\u662f\u5de5\u4e1a\u754c\u573a\u666f\u4e0bfasttext\u5de5\u5177\u6700\u5927\u7684\u610f\u4e49!!!</p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html","title":"BERT\u6a21\u578b\u7684\u5b9e\u73b0","text":"<p>\u5b66\u4e60\u76ee\u6807\uff1a</p> <p>1.\u80fd\u591f\u6784\u5efaBert\u6848\u4f8b\u7684\u4ee3\u7801\u7ed3\u6784</p> <p>2.\u80fd\u591f\u5b8c\u6210\u6570\u636e\u96c6\u7684\u8bfb\u53d6</p> <p>3.\u80fd\u591f\u5b8c\u6210Bert\u5206\u7c7b\u6a21\u578b\u7684\u6784\u5efa</p> <p>4.\u80fd\u591f\u5b8c\u6210Bert\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u6d4b\u8bd5</p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#1","title":"1.\u4ee3\u7801\u67b6\u6784","text":"<p>\u4ee3\u7801\u67b6\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <p></p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#2","title":"2.\u6570\u636e\u5904\u7406","text":""},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#21","title":"2.1 \u9879\u76ee\u6570\u636e\u96c6","text":"<p>\u6570\u636e\u96c6\u7684\u8def\u5f84: toutiao/data/data/</p> <p>\u9879\u76ee\u7684\u6570\u636e\u96c6\u5305\u62ec4\u4e2a\u6587\u4ef6, \u5305\u542b\u8bad\u7ec3\u96c6\uff0c\u6d4b\u8bd5\u96c6\u3001\u9a8c\u8bc1\u96c6\u6570\u636e\u4ee5\u53ca\u76f8\u5e94\u7684\u7c7b\u522b\u4fe1\u606f\uff0c\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684\u4e00\u6837\u3002</p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#22","title":"2.2 \u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5173\u6570\u636e","text":"<p>\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5173\u6570\u636e\u7684\u6587\u4ef6\u5939\u8def\u5f84\u4e3adata/bert_pretrain/\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5173\u6570\u636e\u5171\u5305\u542b3\u4e2a\u6587\u4ef6:</p> <p></p> <p>1\u3001BERT\u6a21\u578b\u7684\u8d85\u53c2\u6570\u914d\u7f6e\u6587\u4ef6</p> <p>04-bert/data/bert_pretrain/bert_config.json</p> <pre><code>{\n\"attention_probs_dropout_prob\": 0.1,  // \u6ce8\u610f\u529b\u673a\u5236\u7684\u4e22\u5f03\u6982\u7387\n\"directionality\": \"bidi\",  // \u6a21\u578b\u7684\u65b9\u5411\u6027\uff0c\u8fd9\u91cc\u662f\u53cc\u5411\n\"hidden_act\": \"gelu\",  // \u9690\u85cf\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd9\u91cc\u662fGELU\n\"hidden_dropout_prob\": 0.1,  // \u9690\u85cf\u5c42\u4e2d\u7684\u4e22\u5f03\u6982\u7387\n\"hidden_size\": 768,  // \u9690\u85cf\u5c42\u7684\u795e\u7ecf\u5143\u4e2a\u6570\uff0c\u5bf9\u5e94H\n\"initializer_range\": 0.02,  // \u6743\u91cd\u521d\u59cb\u5316\u65f6\u622a\u65ad\u6b63\u6001\u5206\u5e03\u7684\u6807\u51c6\u5dee\u7684\u5927\u5c0f\n\"intermediate_size\": 3072,  // encoder\u4e2d\u95f4\u9690\u5c42\u795e\u7ecf\u5143\u4e2a\u6570\uff0c\u5bf9\u5e944H\n\"max_position_embeddings\": 512,  // \u6700\u5927\u7684\u4f4d\u7f6e\u7f16\u7801\n\"num_attention_heads\": 12,  // \u591a\u5934\u6ce8\u610f\u529b\u5934\u7684\u6570\u91cf\uff0c\u5bf9\u5e94A\n\"num_hidden_layers\": 12,  // ecoder\u7684\u91cd\u590d\u4e2a\u6570\uff0c\u5bf9\u5e94L\n\"pooler_fc_size\": 768,  // \u6c60\u5316\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u7684\u7ef4\u5ea6\n\"pooler_num_attention_heads\": 12,  // \u6c60\u5316\u5c42\u7684\u6ce8\u610f\u529b\u5934\u7684\u6570\u91cf\n\"pooler_num_fc_layers\": 3,  // \u6c60\u5316\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6570\u91cf\n\"pooler_size_per_head\": 128,  // \u6c60\u5316\u5c42\u4e2d\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u7ef4\u5ea6\n\"pooler_type\": \"first_token_transform\",  // \u6c60\u5316\u5c42\u7684\u7c7b\u578b\uff0c\u4f7f\u7528\u7b2c\u4e00\u4e2a\u6807\u8bb0\u8fdb\u884c\u53d8\u6362\n\"type_vocab_size\": 2,  // \u7c7b\u578b\u8bcd\u6c47\u8868\u7684\u5927\u5c0f\n\"vocab_size\": 21128  // \u8bcd\u6c47\u8868\u7684\u5927\u5c0f\n}\n</code></pre> <p>2\u3001BERT\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u6587\u4ef6</p> <p>04-bert/data/bert_pretrain/pytorch_model.bin</p> <p>3\u3001BERT\u9884\u8bad\u7ec3\u6a21\u578b\u8bcd\u5178\u6587\u4ef6</p> <p>04-bert/data/bert_pretrain/vocab.txt</p> <pre><code>[PAD]\n[unused1]\n[unused2]\n[unused3]\n[unused4]\n[unused5]\n[unused6]\n[unused7]\n[unused8]\n[unused9]\n[unused10]\n\n......\n......\n......\n\n[unused98]\n[unused99]\n[UNK]\n[CLS]\n[SEP]\n[MASK]\n&lt;S&gt;\n&lt;T&gt;\n!\n......\n......\n......\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#3","title":"3.\u5de5\u5177\u7c7b\u51fd\u6570","text":"<ul> <li>\u5de5\u5177\u7c7b\u51fd\u6570\u7684\u8def\u5f84\u4e3a</li> </ul> <pre><code>04-bert/src/utils.py\n</code></pre> <ul> <li>\u6240\u9700\u7684\u5de5\u5177\u5305\u5982\u4e0b\u6240\u793a\uff1a</li> </ul> <pre><code>import torch\nfrom tqdm import tqdm\nimport time\nfrom datetime import timedelta\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#31-build_dataset","title":"3.1 \u5de5\u5177\u7c7b\u51fd\u6570build_dataset()","text":"<p>\u5de5\u5177\u7c7b\u51fd\u6570build_dataset(), \u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570.\u8be5\u51fd\u6570\u7684\u76ee\u7684\u662f\u6839\u636e\u914d\u7f6e\u4fe1\u606f\u6784\u5efa\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u7684\u6570\u636e\u96c6\u3002\u5b83\u901a\u8fc7\u52a0\u8f7d\u6587\u672c\u6587\u4ef6\u3001\u5206\u8bcd\u3001\u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0\uff0c\u751f\u6210\u5305\u542b\u8bcd\u6c47\u7d22\u5f15\u3001\u6807\u7b7e\u3001\u5e8f\u5217\u957f\u5ea6\u548c\u586b\u5145\u63a9\u7801\u7684\u6570\u636e\u96c6\u3002\u6700\u7ec8\uff0c\u51fd\u6570\u8fd4\u56de\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u4ee5\u4f9b\u6a21\u578b\u4f7f\u7528</p> <pre><code>def build_dataset(config):\n\"\"\"\n    \u6839\u636e\u914d\u7f6e\u4fe1\u606f\u6784\u5efa\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u6570\u636e\u96c6\u3002\n\n    \u53c2\u6570\uff1a\n    - config (object): \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\uff0c\u5305\u542b\u6709\u5173\u6570\u636e\u96c6\u548c\u6a21\u578b\u7684\u76f8\u5173\u53c2\u6570\u3002\n\n    \u8fd4\u56de\uff1a\n    - train, dev, test (tuple): \u5305\u542b\u4e09\u4e2a\u5143\u7ec4\uff0c\u5206\u522b\u662f\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\n    \"\"\"\n    def load_dataset(path, pad_size=32):\n\"\"\"\n        \u52a0\u8f7d\u5e76\u5904\u7406\u5355\u4e2a\u6570\u636e\u96c6\u6587\u4ef6\u3002\n\n        \u53c2\u6570\uff1a\n        - path (str): \u6570\u636e\u96c6\u6587\u4ef6\u8def\u5f84\u3002\n        - pad_size (int): \u586b\u5145\u5230\u7684\u5e8f\u5217\u957f\u5ea6\uff0c\u9ed8\u8ba4\u4e3a32\u3002\n\n        \u8fd4\u56de\uff1a\n        - contents (list): \u5305\u542b\u5904\u7406\u540e\u7684\u6570\u636e\u7684\u5217\u8868\u3002\n        \"\"\"\n        contents = []  # \u7528\u4e8e\u5b58\u50a8\u5904\u7406\u540e\u7684\u6570\u636e\u7684\u5217\u8868\n        with open(path, \"r\", encoding=\"UTF-8\") as f:\n            for line in tqdm(f):  # \u9010\u884c\u904d\u5386\u6587\u4ef6\u5185\u5bb9\n                lin = line.strip()\n                if not lin:\n                    continue\n                content, label = lin.split(\"\\t\")  # \u5206\u5272\u6bcf\u884c\u7684\u5185\u5bb9\u548c\u6807\u7b7e\n                token = config.tokenizer.tokenize(content)  # \u4f7f\u7528\u5206\u8bcd\u5668\u5bf9\u5185\u5bb9\u8fdb\u884c\u5206\u8bcd\n                token = [CLS] + token  # \u5728\u5206\u8bcd\u7ed3\u679c\u524d\u52a0\u5165[CLS]\u6807\u8bb0\n                seq_len = len(token)  # \u8ba1\u7b97\u5e8f\u5217\u957f\u5ea6\n                mask = []  # \u7528\u4e8e\u5b58\u50a8\u586b\u5145\u63a9\u7801\n\n                token_ids = config.tokenizer.convert_tokens_to_ids(token)  # \u5c06\u5206\u8bcd\u7ed3\u679c\u8f6c\u6362\u4e3a\u8bcd\u6c47\u7d22\u5f15\n\n                if pad_size:\n                    if len(token) &lt; pad_size:  # \u5982\u679c\u5e8f\u5217\u957f\u5ea6\u5c0f\u4e8e\u8bbe\u5b9a\u7684\u586b\u5145\u957f\u5ea6\n                        mask = [1] * len(token_ids) + [0] * (pad_size - len(token))  # \u521b\u5efa\u586b\u5145\u63a9\u7801\n                        token_ids += [0] * (pad_size - len(token))  # \u5bf9\u8bcd\u6c47\u7d22\u5f15\u5217\u8868\u8fdb\u884c\u586b\u5145\n                    else:\n                        mask = [1] * pad_size  # \u5982\u679c\u5e8f\u5217\u957f\u5ea6\u5927\u4e8e\u7b49\u4e8e\u586b\u5145\u957f\u5ea6\uff0c\u586b\u5145\u63a9\u7801\u4e3a\u51681\n                        token_ids = token_ids[:pad_size]  # \u5bf9\u8bcd\u6c47\u7d22\u5f15\u5217\u8868\u8fdb\u884c\u622a\u65ad\n                        seq_len = pad_size  # \u66f4\u65b0\u5e8f\u5217\u957f\u5ea6\u4e3a\u586b\u5145\u957f\u5ea6\n                # \u5c06\u5904\u7406\u540e\u7684\u6570\u636e\u6dfb\u52a0\u5230contents\u5217\u8868\n                contents.append((token_ids, int(label), seq_len, mask))\n        return contents\n\n    # \u4f7f\u7528load_dataset\u51fd\u6570\u52a0\u8f7d\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\n    train = load_dataset(config.train_path, config.pad_size)\n    dev = load_dataset(config.dev_path, config.pad_size)\n    test = load_dataset(config.test_path, config.pad_size)\n\n    # \u8fd4\u56de\u4e09\u4e2a\u5143\u7ec4\uff0c\u5206\u522b\u662f\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\n    return train, dev, test\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#32-build_iterator","title":"3.2 \u5de5\u5177\u51fd\u6570build_iterator()","text":"<p>\u5305\u62ec\u6570\u636e\u8fed\u4ee3\u5668\u7684\u7c7bclass DatasetIterater()\u548c\u5de5\u5177\u51fd\u6570build_iterator()\uff0c\u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570\u548c\u7c7b. </p> <ul> <li><code>DatasetIterater</code> \u7c7b\uff1a</li> <li><code>__init__</code>\uff1a\u63a5\u6536\u6279\u6b21\u6570\u636e\u3001\u6279\u6b21\u5927\u5c0f\u3001\u8bbe\u5907\u7c7b\u578b\u548c\u6a21\u578b\u540d\u79f0\uff0c\u8bbe\u7f6e\u76f8\u5173\u5c5e\u6027\u3002</li> <li><code>_to_tensor</code> \u51fd\u6570\uff1a\u5c06\u6279\u6b21\u6570\u636e\u8f6c\u6362\u4e3a PyTorch \u7684 Tensor \u683c\u5f0f\u3002</li> <li><code>__next__</code> \u51fd\u6570\uff1a\u83b7\u53d6\u4e0b\u4e00\u4e2a\u6279\u6b21\u7684\u6837\u672c\uff0c\u5904\u7406\u4e0d\u89c4\u5219\u6279\u6b21\u548c\u7d22\u5f15\u6ea2\u51fa\u3002</li> <li><code>__iter__</code> \u51fd\u6570\uff1a\u8fd4\u56de\u8fed\u4ee3\u5668\u5bf9\u8c61\u672c\u8eab\u3002</li> <li><code>__len__</code> \u51fd\u6570\uff1a\u83b7\u53d6\u8fed\u4ee3\u5668\u7684\u957f\u5ea6\u3002</li> <li><code>build_iterator</code> \u51fd\u6570\uff1a</li> <li>\u6839\u636e\u914d\u7f6e\u4fe1\u606f\u548c\u7ed9\u5b9a\u7684\u6570\u636e\u96c6\u6784\u5efa\u6570\u636e\u96c6\u8fed\u4ee3\u5668\u5bf9\u8c61\u3002</li> <li>\u8fd4\u56de\u6570\u636e\u96c6\u8fed\u4ee3\u5668\u3002</li> </ul> <pre><code>class DatasetIterater(object):\n    def __init__(self, batches, batch_size, device, model_name):\n\"\"\"\n        \u6570\u636e\u96c6\u8fed\u4ee3\u5668\u7684\u521d\u59cb\u5316\u51fd\u6570\u3002\n        \u53c2\u6570\uff1a\n        - batches (list): \u5305\u542b\u6837\u672c\u7684\u5217\u8868\u3002\n        - batch_size (int): \u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\u3002\n        - device (str): \u6570\u636e\u52a0\u8f7d\u5230\u7684\u8bbe\u5907\uff08CPU\u6216GPU\uff09\u3002\n        - model_name (str): \u4f7f\u7528\u7684\u6a21\u578b\u540d\u79f0\u3002\n        \"\"\"\n        self.batch_size = batch_size # \u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\n        self.batches = batches # \u5305\u542b\u6837\u672c\u7684\u5217\u8868\n        self.model_name = model_name # \u4f7f\u7528\u7684\u6a21\u578b\u540d\u79f0\n        self.n_batches = len(batches) // batch_size # \u6279\u6b21\u7684\u6570\u91cf\n        self.residue = False  # \u8bb0\u5f55batch\u6570\u91cf\u662f\u5426\u4e3a\u6574\u6570\n        if len(batches) % self.n_batches != 0:\n            self.residue = True\n        self.index = 0 # \u5f53\u524d\u6279\u6b21\u7684\u7d22\u5f15\n        self.device = device # \u6570\u636e\u52a0\u8f7d\u5230\u7684\u8bbe\u5907\uff08CPU\u6216GPU\uff09\n\n    def _to_tensor(self, datas):\n\"\"\"\n        \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3aTensor\u3002\n        \"\"\"\n        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n        # pad\u524d\u7684\u957f\u5ea6(\u8d85\u8fc7pad_size\u7684\u8bbe\u4e3apad_size)\n        seq_len = torch.LongTensor([_[2] for _ in datas]).to(self.device)\n        # \u82e5\u4e3aBERT\u6a21\u578b\uff0c\u8fd4\u56de(x, seq_len, mask), y\uff1b\n        if self.model_name == \"bert\" :\n            mask = torch.LongTensor([_[3] for _ in datas]).to(self.device)\n            return (x, seq_len, mask), y\n        # \u82e5\u4e3aTextCNN\u6a21\u578b\uff0c\u8fd4\u56de(x, seq_len), y\n        if self.model_name == \"textCNN\":\n            return (x, seq_len), y\n\n    def __next__(self):\n\"\"\"\n        \u83b7\u53d6\u4e0b\u4e00\u4e2a\u6279\u6b21\u7684\u6837\u672c\u3002\n        \"\"\"\n        if self.residue and self.index == self.n_batches:\n            batches = self.batches[self.index * self.batch_size: len(self.batches)]\n            self.index += 1\n            batches = self._to_tensor(batches)\n            return batches\n        elif self.index &gt;= self.n_batches:\n            self.index = 0\n            raise StopIteration\n        else:\n            batches = self.batches[self.index * self.batch_size: (self.index + 1) * self.batch_size]\n            self.index += 1\n            batches = self._to_tensor(batches)\n            return batches\n\n    def __iter__(self):\n\"\"\"\n        \u8fd4\u56de\u8fed\u4ee3\u5668\u5bf9\u8c61\u672c\u8eab\u3002\n        \"\"\"\n        return self\n\n    def __len__(self):\n\"\"\"\n        \u83b7\u53d6\u8fed\u4ee3\u5668\u7684\u957f\u5ea6\u3002\n        \"\"\"\n        if self.residue:\n            return self.n_batches + 1\n        else:\n            return self.n_batches\n\ndef build_iterator(dataset, config):\n\"\"\"\n    \u6839\u636e\u914d\u7f6e\u4fe1\u606f\u6784\u5efa\u6570\u636e\u96c6\u8fed\u4ee3\u5668\u3002\n    \u8fd4\u56de\uff1a\n    - \u6570\u636e\u96c6\u8fed\u4ee3\u5668\u5bf9\u8c61\u3002\n    \"\"\"\n    iter = DatasetIterater(dataset, config.batch_size, config.device, config.model_name)\n    return iter\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#33get_time_dif","title":"3.3\u5de5\u5177\u7c7b\u51fd\u6570get_time_dif()","text":"<p>get_time_dif()\u51fd\u6570\u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u63a5\u53d7\u4e00\u4e2a\u5f00\u59cb\u65f6\u95f4\u6233\u4f5c\u4e3a\u53c2\u6570\uff0c\u8ba1\u7b97\u5f53\u524d\u65f6\u95f4\u4e0e\u5f00\u59cb\u65f6\u95f4\u7684\u5dee\u503c\uff0c\u5e76\u5c06\u5dee\u503c\u8f6c\u6362\u4e3a <code>timedelta</code> \u5bf9\u8c61\u8868\u793a\u5df2\u4f7f\u7528\u7684\u65f6\u95f4\u3002\u8fd9\u79cd\u8ba1\u7b97\u65f6\u95f4\u5dee\u7684\u65b9\u6cd5\u901a\u5e38\u7528\u4e8e\u6d4b\u91cf\u7a0b\u5e8f\u8fd0\u884c\u7684\u65f6\u95f4\u3002</p> <pre><code>def get_time_dif(start_time):\n\"\"\"\n    \u8ba1\u7b97\u5df2\u4f7f\u7528\u7684\u65f6\u95f4\u5dee\u3002\n    \"\"\"\n    # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4\n    end_time = time.time()\n    # \u8ba1\u7b97\u65f6\u95f4\u5dee\n    time_dif = end_time - start_time\n    # \u5c06\u65f6\u95f4\u5dee\u8f6c\u6362\u4e3a\u6574\u6570\u79d2\uff0c\u5e76\u8fd4\u56de\u65f6\u95f4\u5dee\u5bf9\u8c61\n    return timedelta(seconds=int(round(time_dif))\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#4bert","title":"4.BERT\u5206\u7c7b\u6a21\u578b\u642d\u5efa","text":"<p>\u63a5\u4e0b\u6765\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8eBERT\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u5305\u542b\u4e86\u76f8\u5173\u7684\u914d\u7f6e\u4fe1\u606f\u3002\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/models/bert.py\n</code></pre> <p>\u4e3b\u8981\u5185\u5bb9\u5305\u542b\uff1a</p> <p>\u914d\u7f6e\u7c7b <code>Config</code>\uff1a\u548c\u6a21\u578b\u7c7b <code>Model</code>\uff1a</p> <p>\u9996\u5148**\u5bfc\u5165\u5de5\u5177\u5305**\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport os\nfrom transformers import BertModel, BertTokenizer, BertConfig\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#41-config","title":"4.1 \u5b9e\u73b0Config\u7c7b\u4ee3\u7801","text":"<p>\u914d\u7f6e\u7c7b <code>Config</code>\u4e2d\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li><code>Config</code> \u7c7b\u5305\u542b\u4e86\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u5904\u7406\u7684\u5404\u79cd\u53c2\u6570\u3002</li> <li>\u5b9a\u4e49\u4e86\u6a21\u578b\u540d\u79f0\u3001\u6570\u636e\u96c6\u8def\u5f84\u3001\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u6587\u4ef6\u8def\u5f84\u3001\u7c7b\u522b\u540d\u5355\u7b49\u4fe1\u606f\u3002</li> <li>\u5305\u542b\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u548c\u91cf\u5316\u6a21\u578b\u5b58\u50a8\u7ed3\u679c\u7684\u8def\u5f84\u3002</li> <li>\u914d\u7f6e\u4e86\u8bad\u7ec3\u8bbe\u5907\uff08GPU\u6216CPU\uff09\u3001\u7c7b\u522b\u6570\u3001epoch\u6570\u3001mini-batch\u5927\u5c0f\u3001\u53e5\u5b50\u957f\u5ea6\u7b49\u3002</li> <li>BERT\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8def\u5f84\u3001\u5206\u8bcd\u5668\u3001BERT\u6a21\u578b\u914d\u7f6e\u3001\u9690\u85cf\u5c42\u5927\u5c0f\u7b49\u3002</li> </ul> <pre><code>class Config(object):\n    def __init__(self):\n\"\"\"\n        \u914d\u7f6e\u7c7b\uff0c\u5305\u542b\u6a21\u578b\u548c\u8bad\u7ec3\u6240\u9700\u7684\u5404\u79cd\u53c2\u6570\u3002\n        \"\"\"\n        self.model_name = \"bert\" # \u6a21\u578b\u540d\u79f0\n        self.data_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/data/data1/\" #\u6570\u636e\u96c6\u7684\u6839\u8def\u5f84\n        self.train_path = self.data_path + \"train.txt\"  # \u8bad\u7ec3\u96c6\n        self.dev_path = self.data_path + \"dev.txt\"  # \u9a8c\u8bc1\u96c6\n        self.test_path = self.data_path + \"test.txt\"  # \u6d4b\u8bd5\u96c6\n        self.class_list = [x.strip() for x in open(self.data_path + \"class.txt\").readlines()]  # \u7c7b\u522b\u540d\u5355\n\n        self.save_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/src/saved_dic\" #\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\n        if not os.path.exists(self.save_path):\n            os.mkdir(self.save_path)\n        self.save_path += \"/\" + self.model_name + \".pt\"  # \u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\n\n        self.save_path2 = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/src/saved_dic1\" # \u91cf\u5316\u6a21\u578b\u5b58\u50a8\u7ed3\u679c\u8def\u5f84\n        if not os.path.exists(self.save_path2):\n            os.mkdir(self.save_path2)\n        self.save_path2 += \"/\" + self.model_name + \"_quantized.pt\"  # \u91cf\u5316\u6a21\u578b\u5b58\u50a8\u7ed3\u679c\n\n        # \u6a21\u578b\u8bad\u7ec3+\u9884\u6d4b\u7684\u65f6\u5019, \u653e\u5f00\u4e0b\u4e00\u884c\u4ee3\u7801, \u5728GPU\u4e0a\u8fd0\u884c.\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # \u8bad\u7ec3\u8bbe\u5907\uff0c\u5982\u679cGPU\u53ef\u7528\uff0c\u5219\u4e3acuda\uff0c\u5426\u5219\u4e3acpu\n        # \u6a21\u578b\u91cf\u5316\u7684\u65f6\u5019, \u653e\u5f00\u4e0b\u4e00\u884c\u4ee3\u7801, \u5728CPU\u4e0a\u8fd0\u884c.\n        # self.device = 'cpu'\n\n        self.num_classes = len(self.class_list)  # \u7c7b\u522b\u6570\n        self.num_epochs = 2  # epoch\u6570\n        self.batch_size = 128  # mini-batch\u5927\u5c0f\n        self.pad_size = 32  # \u6bcf\u53e5\u8bdd\u5904\u7406\u6210\u7684\u957f\u5ea6(\u77ed\u586b\u957f\u5207)\n        self.learning_rate = 5e-5  # \u5b66\u4e60\u7387\n        self.bert_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/data/bert_pretrain\" # \u9884\u8bad\u7ec3BERT\u6a21\u578b\u7684\u8def\u5f84\n        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path) # BERT\u6a21\u578b\u7684\u5206\u8bcd\u5668\n        self.bert_config = BertConfig.from_pretrained(self.bert_path + '/bert_config.json') # BERT\u6a21\u578b\u7684\u914d\u7f6e\n        self.hidden_size = 768 # BERT\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5927\u5c0f\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#42-model","title":"4.2 \u5b9e\u73b0Model\u7c7b\u4ee3\u7801","text":"<p>**\u6a21\u578b\u7c7b <code>Model</code>**\u4e3b\u8981\u5b9e\u73b0\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li><code>Model</code> \u7c7b\u7ee7\u627f\u81ea <code>nn.Module</code>\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eBERT\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\u3002</li> <li>\u5728\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\uff0c\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684BERT\u6a21\u578b\u548c\u914d\u7f6e\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3002</li> <li>\u5728\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\u4e2d\uff0c\u901a\u8fc7BERT\u6a21\u578b\u83b7\u53d6\u53e5\u5b50\u7684\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b</li> </ul> <pre><code>class Model(nn.Module):\n    def __init__(self, config):\n        super(Model, self).__init__()\n        # \u9884\u8bad\u7ec3BERT\u6a21\u578b\n        self.bert = BertModel.from_pretrained(config.bert_path, config=config.bert_config)\n        # \u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u6587\u672c\u5206\u7c7b\n        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n\n    def forward(self, x):\n        # x: \u6a21\u578b\u8f93\u5165\uff0c\u5305\u542b\u53e5\u5b50\u3001\u53e5\u5b50\u957f\u5ea6\u548c\u586b\u5145\u63a9\u7801\u3002\n        context = x[0]  # \u8f93\u5165\u7684\u53e5\u5b50\n        mask = x[2]  # \u5bf9padding\u90e8\u5206\u8fdb\u884cmask\uff0c\u548c\u53e5\u5b50\u4e00\u4e2asize\uff0cpadding\u90e8\u5206\u75280\u8868\u793a\uff0c\u5982\uff1a[1, 1, 1, 1, 0, 0]\n        # _\u662f\u5360\u4f4d\u7b26\uff0c\u63a5\u6536\u6a21\u578b\u7684\u6240\u6709\u8f93\u51fa\uff0c\u800c pooled \u662f\u6c60\u5316\u7684\u7ed3\u679c,\u5c06\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u538b\u7f29\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf\n        _, pooled = self.bert(context, attention_mask=mask, return_dict=False)\n        # \u6a21\u578b\u8f93\u51fa\uff0c\u7528\u4e8e\u6587\u672c\u5206\u7c7b\n        out = self.fc(pooled)\n        return out\n</code></pre> <p>bert.py\u6587\u4ef6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u7075\u6d3b\u7684BERT\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u914d\u7f6e\u7c7b\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u9002\u5e94\u4e0d\u540c\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u8fc7model\u7c7b\u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u7ed3\u6784\u3002</p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#5","title":"5.\u7f16\u5199\u8bad\u7ec3\u51fd\u6570,\u6d4b\u8bd5\u51fd\u6570,\u8bc4\u4f30\u51fd\u6570","text":"<p>\u8fd93\u4e2a\u51fd\u6570\u5171\u540c\u7f16\u5199\u5728\u4e00\u4e2a\u4ee3\u7801\u6587\u4ef6\u4e2d:</p> <pre><code>04-bert/src/train_eval.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u76f8\u5173\u5de5\u5177\u5305\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn import metrics\nimport time\nfrom utils import get_time_dif\nfrom transformers.optimization import AdamW\nfrom tqdm import tqdm\nimport math\nimport logging\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#51","title":"5.1  \u7f16\u5199\u8bad\u7ec3\u51fd\u6570.","text":"<p>\u8bad\u7ec3\u51fd\u6570\u5b9e\u73b0\u4e86\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4e86\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u548cAdamW\u4f18\u5316\u5668\u3002\u5177\u4f53\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ol> <li>\u4f18\u5316\u5668\u8bbe\u7f6e\uff1a \u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u5e76\u8bbe\u7f6e\u4e86\u53c2\u6570\u7684\u6743\u91cd\u8870\u51cf\u3002</li> <li>\u8bad\u7ec3\u5faa\u73af\uff1a \u904d\u5386\u6bcf\u4e2aepoch\u548c\u6bcf\u4e2abatch\uff0c\u8fdb\u884c\u524d\u5411\u4f20\u64ad\u3001\u8ba1\u7b97\u635f\u5931\u3001\u53cd\u5411\u4f20\u64ad\u3001\u53c2\u6570\u66f4\u65b0\u3002</li> <li>\u8bc4\u4f30\uff1a \u6bcf100\u4e2abatch\u8f93\u51fa\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\uff0c\u5305\u62ec\u8bad\u7ec3\u635f\u5931\u3001\u8bad\u7ec3\u51c6\u786e\u7387\u3001\u9a8c\u8bc1\u635f\u5931\u3001\u9a8c\u8bc1\u51c6\u786e\u7387\u7b49\u3002</li> <li>\u4fdd\u5b58\u6a21\u578b\uff1a \u82e5\u9a8c\u8bc1\u96c6\u4e0a\u7684\u635f\u5931\u66f4\u4f4e\uff0c\u4fdd\u5b58\u5f53\u524d\u6a21\u578b\u7684\u53c2\u6570\u3002</li> <li>\u65f6\u95f4\u8ba1\u7b97\uff1a \u8ba1\u7b97\u8bad\u7ec3\u7684\u603b\u65f6\u95f4\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def loss_fn(outputs, labels):\n\"\"\"\n    \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002\n    \"\"\"\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef train(config, model, train_iter, dev_iter):\n\"\"\"\n    \u6a21\u578b\u8bad\u7ec3\u51fd\u6570\u3002\n    \u53c2\u6570\uff1a\n    - config: \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\u3002\n    - model: \u5f85\u8bad\u7ec3\u7684\u6a21\u578b\u3002\n    - train_iter: \u8bad\u7ec3\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n    - dev_iter: \u9a8c\u8bc1\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n    \"\"\"\n    # \u8bb0\u5f55\u5f00\u59cb\u8bad\u7ec3\u7684\u65f6\u95f4\n    start_time = time.time()\n\n    # \u53c2\u6570\u4f18\u5316\u5668\u8bbe\u7f6e\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         \"weight_decay\": 0.01\n         },\n        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         \"weight_decay\": 0.0\n         }]\n    # \u8bbe\u7f6e\u4f18\u5316\u5668\n    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate)\n    dev_best_loss = float(\"inf\")\n    # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u578b\u5e08\n    model.train()\n    # \u904d\u5386\u6bcf\u4e2a\u8f6e\u6b21\n    for epoch in range(config.num_epochs):\n        total_batch = 0\n        print(\"Epoch [{}/{}]\".format(epoch + 1, config.num_epochs))\n        # \u904d\u5386\u6bcf\u4e2a\u6279\u6b21\n        for i, (trains, labels) in enumerate(tqdm(train_iter)):\n            # \u6a21\u578b\u524d\u5411\u4f20\u64ad\n            outputs = model(trains)\n            # \u68af\u5ea6\u6e05\u96f6\n            model.zero_grad()\n            # \u8ba1\u7b97\u635f\u5931\n            loss = loss_fn(outputs, labels)\n            # \u53cd\u5411\u4f20\u64ad\n            loss.backward()\n            # \u53c2\u6570\u66f4\u65b0\n            optimizer.step()\n            # \u6bcf100\u4e2abatch\u8f93\u51fa\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\n            if total_batch % 100 == 0 and total_batch != 0:\n                true = labels.data.cpu()\n                predic = torch.max(outputs.data, 1)[1].cpu()\n                train_acc = metrics.accuracy_score(true, predic)\n                # \u8bc4\u4f30\u9a8c\u8bc1\u96c6\u6548\u679c\n                dev_acc, dev_loss = evaluate(config, model, dev_iter)\n                # \u82e5\u9a8c\u8bc1\u96c6\u635f\u5931\u66f4\u4f4e\uff0c\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n                if dev_loss &lt; dev_best_loss:\n                    dev_best_loss = dev_loss\n                    torch.save(model.state_dict(), config.save_path)\n                    improve = \"*\"\n                else:\n                    improve = \"\"\n                # \u8ba1\u7b97\u65f6\u95f4\u5dee\n                time_dif = get_time_dif(start_time)\n                # \u8f93\u51fa\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\n                msg = \"Iter: {0:&gt;6},  Train Loss: {1:&gt;5.2},  Train Acc: {2:&gt;6.2%},  Val Loss: {3:&gt;5.2},  Val Acc: {4:&gt;6.2%},  Time: {5} {6}\"\n                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n                # \u8bc4\u4f30\u5b8c\u6210\u540e\u5c06\u6a21\u578b\u7f6e\u4e8e\u8bad\u7ec3\u6a21\u5f0f, \u66f4\u65b0\u53c2\u6570\n                model.train()\n            # \u6bcf\u4e2abatch\u7ed3\u675f\u540e\u7d2f\u52a0\u8ba1\u6570\n            total_batch += 1\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#52","title":"5.2 \u7f16\u5199\u9a8c\u8bc1\u51fd\u6570.","text":"<p>\u6a21\u578b\u9a8c\u8bc1\u51fd\u6570 <code>evaluate</code>\uff0c\u7528\u4e8e\u5728\u9a8c\u8bc1\u96c6\u6216\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u4e3b\u8981\u529f\u80fd\u5305\u62ec\uff1a</p> <ol> <li>\u635f\u5931\u8ba1\u7b97\uff1a \u901a\u8fc7\u5faa\u73af\u904d\u5386\u6570\u636e\u96c6\uff0c\u8ba1\u7b97\u6a21\u578b\u5728\u6bcf\u4e2a\u6837\u672c\u4e0a\u7684\u635f\u5931\uff0c\u5e76\u7d2f\u52a0\u5f97\u5230\u603b\u635f\u5931\u3002</li> <li>\u9884\u6d4b\u7ed3\u679c\u8bb0\u5f55\uff1a \u8bb0\u5f55\u6a21\u578b\u5bf9\u6bcf\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u6807\u7b7e\u3002</li> <li>\u51c6\u786e\u7387\u8ba1\u7b97\uff1a \u6839\u636e\u8bb0\u5f55\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u6807\u7b7e\u8ba1\u7b97\u6a21\u578b\u7684\u51c6\u786e\u7387\u3002</li> <li>\u6d4b\u8bd5\u96c6\u8bc4\u4f30\uff1a \u5982\u679c\u662f\u6d4b\u8bd5\u96c6\u8bc4\u4f30\uff0c\u989d\u5916\u8ba1\u7b97\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\u3002</li> </ol> <p>\u8be5\u51fd\u6570\u7684\u76ee\u7684\u662f\u63d0\u4f9b\u4e00\u79cd\u7b80\u4fbf\u7684\u65b9\u5f0f\uff0c\u4ee5\u4fbf\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76d1\u63a7\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5728\u9700\u8981\u65f6\u4fdd\u5b58\u6027\u80fd\u8f83\u597d\u7684\u6a21\u578b\u53c2\u6570\u3002</p> <pre><code>def evaluate(config, model, data_iter, test=False):\n\"\"\"\n    \u6a21\u578b\u8bc4\u4f30\u51fd\u6570\u3002\n    \u53c2\u6570\uff1a\n    - config: \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\u3002\n    - model: \u5f85\u8bc4\u4f30\u7684\u6a21\u578b\u3002\n    - data_iter: \u6570\u636e\u8fed\u4ee3\u5668\u3002\n    - test: \u662f\u5426\u4e3a\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u3002\n    \"\"\"\n\n    # \u91c7\u7528\u91cf\u5316\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u65f6\u9700\u8981\u5173\u95ed\n    # model.eval()\n\n    loss_total = 0\n    # \u9884\u6d4b\u7ed3\u679c\n    predict_all = np.array([], dtype=int)\n    # label\u4fe1\u606f\n    labels_all = np.array([], dtype=int)\n    # \u4e0d\u8fdb\u884c\u68af\u5ea6\u8ba1\u7b97\n    with torch.no_grad():\n        # \u904d\u5386\u6570\u636e\u96c6\n        for texts, labels in data_iter:\n            # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\n            outputs = model(texts)\n            # \u635f\u5931\u51fd\u6570\n            loss = F.cross_entropy(outputs, labels)\n            # \u635f\u5931\u548c\n            loss_total += loss\n            # \u83b7\u53d6label\u4fe1\u606f\n            labels = labels.data.cpu().numpy()\n            # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n            predic = torch.max(outputs.data, 1)[1].cpu().numpy()\n            labels_all = np.append(labels_all, labels)\n            predict_all = np.append(predict_all, predic)\n    # \u8ba1\u7b97\u51c6\u786e\u7387\n    acc = metrics.accuracy_score(labels_all, predict_all)\n\n    if test:\n        # \u5982\u679c\u662f\u6d4b\u8bd5\u96c6\u8bc4\u4f30\uff0c\u8ba1\u7b97\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\n        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=4)\n        confusion = metrics.confusion_matrix(labels_all, predict_all)\n        return acc, loss_total / len(data_iter), report, confusion\n    else:\n        # \u5982\u679c\u662f\u9a8c\u8bc1\u96c6\u8bc4\u4f30\uff0c\u4ec5\u8fd4\u56de\u51c6\u786e\u7387\u548c\u5e73\u5747\u635f\u5931\n        return acc, loss_total / len(data_iter)\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#53","title":"5.3 \u7f16\u5199\u6d4b\u8bd5\u51fd\u6570","text":"<p>\u6d4b\u8bd5<code>test</code> \u51fd\u6570\u7528\u4e8e\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6700\u7ec8\u7684\u6a21\u578b\u6d4b\u8bd5\u3002\u5b83\u8c03\u7528\u4e86\u4e4b\u524d\u5b9a\u4e49\u7684 <code>evaluate</code> \u51fd\u6570\uff0c\u7136\u540e\u8f93\u51fa\u6d4b\u8bd5\u96c6\u4e0a\u7684\u635f\u5931\u3001\u51c6\u786e\u7387\u3001\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\u7b49\u4fe1\u606f\u3002</p> <pre><code>def test(config, model, test_iter):\n\"\"\"\n    \u6a21\u578b\u6d4b\u8bd5\u51fd\u6570\uff0c\u7528\u4e8e\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6700\u7ec8\u7684\u6a21\u578b\u6d4b\u8bd5\u3002\n    \u53c2\u6570\uff1a\n    - config: \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\u3002\n    - model: \u5f85\u6d4b\u8bd5\u7684\u6a21\u578b\u3002\n    - test_iter: \u6d4b\u8bd5\u96c6\u7684\u6570\u636e\u8fed\u4ee3\u5668\u3002\n    \"\"\"\n    # \u91c7\u7528\u91cf\u5316\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u65f6\u9700\u8981\u5173\u95ed\n    # model.eval()\n\n    start_time = time.time()\n    # \u8c03\u7528\u9a8c\u8bc1\u51fd\u6570\u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\n    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=True)\n\n    # \u6253\u5370\u6d4b\u8bd5\u7ed3\u679c\u4fe1\u606f:\u8f93\u51fa\u6d4b\u8bd5\u96c6\u4e0a\u7684\u635f\u5931\u3001\u51c6\u786e\u7387\u3001\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\u7b49\u4fe1\u606f\n    msg = \"Test Loss: {0:&gt;5.2},  Test Acc: {1:&gt;6.2%}\"\n    print(msg.format(test_loss, test_acc))\n    print(\"Precision, Recall and F1-Score...\")\n    print(test_report)\n    print(\"Confusion Matrix...\")\n    print(test_confusion)\n    time_dif = get_time_dif(start_time)\n    print(\"Time usage:\", time_dif)\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#6","title":"6 \u7f16\u5199\u8bad\u7ec3\u8bc4\u4f30\u4e3b\u51fd\u6570","text":"<p>\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684\u5165\u53e3\u811a\u672c\uff0c\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u7c7b\u578b\uff0c\u7136\u540e\u52a0\u8f7d\u5bf9\u5e94\u6a21\u578b\u7684\u914d\u7f6e\u548c\u6a21\u578b\u5b9a\u4e49\uff0c\u6784\u5efa\u6570\u636e\u96c6\u548c\u6570\u636e\u8fed\u4ee3\u5668\uff0c\u6700\u540e\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002</p> <p>\u8be5\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/run.py\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#61","title":"6.1 \u5177\u4f53\u5b9e\u73b0","text":"<p>\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>import time\nimport torch\nimport numpy as np\nfrom train_eval import train, test\nfrom importlib import import_module\nimport argparse\nfrom utils import build_dataset, build_iterator, get_time_dif\n\n# \u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790\nparser = argparse.ArgumentParser(description=\"Chinese Text Classification\")\nparser.add_argument(\"--model\", type=str, default='bert', help=\"choose a model: bert\")\nargs = parser.parse_args()\n\nif __name__ == \"__main__\":\n    if args.model == \"bert\":\n        # \u5bfc\u5165\u5bf9\u5e94\u6a21\u578b\u7684\u914d\u7f6e\u548c\u6a21\u578b\u5b9a\u4e49\n        model_name = \"bert\"\n        x = import_module(\"models.\" + model_name)\n        config = x.Config()\n\n        # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\uff0c\u4fdd\u8bc1\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\n        np.random.seed(1)\n        torch.manual_seed(1)\n        torch.cuda.manual_seed_all(1)\n        torch.backends.cudnn.deterministic = True  # \u4fdd\u8bc1\u6bcf\u6b21\u7ed3\u679c\u4e00\u6837\n\n        # \u6784\u5efa\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u6570\u636e\u96c6\u548c\u6570\u636e\u8fed\u4ee3\u5668\n        train_data, dev_data, test_data = build_dataset(config)\n        train_iter = build_iterator(train_data, config)\n        dev_iter = build_iterator(dev_data, config)\n        test_iter = build_iterator(test_data, config)\n        # \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b\u5e76\u79fb\u81f3\u6307\u5b9a\u8bbe\u5907\n        model = x.Model(config).to(config.device)\n        # \u8bad\u7ec3\u6a21\u578b\n        train(config, model, train_iter, dev_iter)\n        # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\n        test(config, model, test_iter)\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#61_1","title":"6.1 \u8f93\u51fa\u7ed3\u679c","text":"<p>\u6267\u884c\u4e0a\u8ff0\u51fd\u6570\uff0c\u8fd0\u884c\u7ed3\u679c\u5982\u4e0b\uff1a</p> <pre><code>Loading data for Bert Model...\n180000it [00:37, 4820.80it/s]\n10000it [00:02, 4954.00it/s]\n10000it [00:02, 4952.50it/s]\nEpoch [1/3]\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                            | 200/1407 [02:06&lt;13:26,  1.50it/s]Iter:    200,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 90.86%,  Time: 0:02:26 *\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [04:44&lt;11:46,  1.43it/s]Iter:    400,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.26,  Val Acc: 92.10%,  Time: 0:05:07 *\n 43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 600/1407 [07:26&lt;09:25,  1.43it/s]Iter:    600,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.25,  Val Acc: 92.10%,  Time: 0:07:49 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [10:08&lt;07:06,  1.42it/s]Iter:    800,  Train Loss:  0.15,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 92.85%,  Time: 0:10:31 *\n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 1000/1407 [12:50&lt;04:43,  1.44it/s]Iter:   1000,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 93.00%,  Time: 0:13:10 \nNo optimization for a long time, auto-stopping...\nTest Loss:   0.2,  Test Acc: 93.64%\nPrecision, Recall and F1-Score...\n               precision    recall  f1-score   support\n\n      finance     0.9246    0.9320    0.9283      1000\n       realty     0.9484    0.9370    0.9427      1000\n       stocks     0.8787    0.8980    0.8882      1000\n    education     0.9511    0.9730    0.9619      1000\n      science     0.9236    0.8950    0.9091      1000\n      society     0.9430    0.9270    0.9349      1000\n     politics     0.9267    0.9100    0.9183      1000\n       sports     0.9780    0.9780    0.9780      1000\n         game     0.9514    0.9600    0.9557      1000\nentertainment     0.9390    0.9540    0.9464      1000\n\n     accuracy                         0.9364     10000\n    macro avg     0.9365    0.9364    0.9364     10000\n weighted avg     0.9365    0.9364    0.9364     10000\n\nConfusion Matrix...\n[[932  10  37   2   5   5   7   1   1   0]\n [ 13 937  11   2   4  10   5   5   5   8]\n [ 49  12 898   1  19   1  15   0   2   3]\n [  1   1   0 973   0   8   7   0   1   9]\n [  4   4  28   7 895  10  12   2  27  11]\n [  2   8   4  16   5 927  18   1   5  14]\n [  3   8  34  12   9  19 910   0   0   5]\n [  2   3   2   1   1   1   4 978   1   7]\n [  0   2   4   0  24   1   3   1 960   5]\n [  2   3   4   9   7   1   1  12   7 954]]\nTime usage: 0:00:19\n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 1000/1407 [13:29&lt;05:29,  1.24it/s]\n</code></pre> <p>\u7ed3\u8bba: BERT\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u662fTest Acc: 93.64% , \u5bf9\u6bd4\u4e8e\u7b2c\u4e00\u7ae0\u7684fasttext\u6a21\u578b\u6700\u597d\u7684\u8868\u73b091.93%, \u6709\u4e861.71%\u7684\u63d0\u5347, \u53ef\u4ee5\u8bf4\u662f\u663e\u8457\u6027\u63d0\u5347\u4e86!</p> <p>\u5e76\u4e14\u4f1a\u4fdd\u5b58\u76f8\u5e94\u8bad\u7ec3\u6743\u91cd\uff1a</p> <p></p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#7","title":"7.\u6a21\u578b\u9884\u6d4b","text":"<p>\u63a5\u4e0b\u6765\u4f7f\u7528\u4e0a\u4e00\u90e8\u5206\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u9884\u6d4b\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u63a8\u7406\u8fc7\u7a0b\uff0c\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/predict.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff1a</p> <pre><code>import torch\nfrom importlib import import_module\nimport numpy as np\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#71","title":"7.1 \u63a8\u7406\u51fd\u6570\u5b9a\u4e49","text":"<p>\u63a8\u7406\u51fd\u6570\u6765\u5b8c\u6210\u5bf9\u65b0\u6837\u672c\u7684\u9884\u6d4b\uff0c\u63a5\u4e0b\u6765\u5b9a\u4e49\uff1a</p> <ol> <li>\u5b9a\u4e49\u7279\u6b8a\u7b26\u53f7\u548c\u7c7b\u522b\u6620\u5c04\uff1a \u5b9a\u4e49\u4e86\u7528\u4e8e\u586b\u5145\u7684\u7279\u6b8a\u7b26\u53f7\uff08[UNK], [PAD], [CLS]\uff09\u4ee5\u53ca\u7c7b\u522bID\u5230\u7c7b\u522b\u540d\u7684\u6620\u5c04\u3002</li> <li>\u7f16\u5199\u63a8\u7406\u51fd\u6570 <code>inference</code>\uff1a \u5b9a\u4e49\u4e86\u4e00\u4e2a\u7528\u4e8e\u6a21\u578b\u63a8\u7406\u7684\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u63a5\u53d7\u4e00\u4e2a\u6a21\u578b\u3001\u6a21\u578b\u914d\u7f6e\u3001\u5f85\u5206\u6790\u7684\u6587\u672c\uff0c\u8fd4\u56de\u6a21\u578b\u5bf9\u6587\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u5b9a\u4e49\u7279\u6b8a\u7684\u7b26\u53f7\u548c\u7c7b\u522b\u6620\u5c04\nCLS =  \"[CLS]\"\nid_to_name = {0: 'finance', 1: 'realty', 2: 'stocks', 3: 'education', 4: 'science',\n              5: 'society', 6: 'politics', 7: 'sports', 8: 'game', 9: 'entertainment'}\n\ndef inference(model, config, input_text, pad_size=32):\n\"\"\"\n    \u6a21\u578b\u63a8\u7406\u51fd\u6570\uff0c\u7528\u4e8e\u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u60c5\u611f\u5206\u6790\u7684\u63a8\u7406\u3002\n    \u53c2\u6570\uff1a\n    - model: \u5df2\u52a0\u8f7d\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u3002\n    - config: \u6a21\u578b\u914d\u7f6e\u4fe1\u606f\u3002\n    - input_text: \u5f85\u5206\u6790\u7684\u6587\u672c\u3002\n    - pad_size: \u6307\u5b9a\u6587\u672c\u586b\u5145\u7684\u957f\u5ea6\u3002\n    \"\"\"\n    # \u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u5206\u8bcd\u548c\u9884\u5904\u7406\n    content = config.tokenizer.tokenize(input_text)\n    content = [CLS] + content\n    seq_len = len(content)\n    token_ids = config.tokenizer.convert_tokens_to_ids(content)\n    # \u586b\u5145\u6216\u622a\u65ad\u6587\u672c\u81f3\u6307\u5b9a\u957f\u5ea6\n    if seq_len &lt; pad_size:\n        mask = [1] * len(token_ids) + [0] * (pad_size - seq_len)\n        token_ids += [0] * (pad_size - seq_len)\n    else:\n        mask = [1] * pad_size\n        token_ids = token_ids[:pad_size]\n        seq_len = pad_size\n    # \u5c06\u5904\u7406\u540e\u7684\u6587\u672c\u8f6c\u6362\u4e3aPyTorch Tensor\n    x = torch.LongTensor(token_ids).to(config.device)\n    seq_len = torch.LongTensor(seq_len).to(config.device)\n    mask = torch.LongTensor(mask).to(config.device)\n    # \u589e\u52a0\u4e00\u7ef4\uff0c\u8868\u793abatch_size\u4e3a1\n    x = x.unsqueeze(0)\n    seq_len = seq_len.unsqueeze(0)\n    mask = mask.unsqueeze(0)\n    data = (x, seq_len, mask)\n    # \u6a21\u578b\u63a8\u7406\n    output = model(data)\n    # \u83b7\u53d6\u6a21\u578b\u9884\u6d4b\u7ed3\u679cid\n    predict_result = torch.max(output.data, 1)[1]\n    return predict_result\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#72","title":"7.2 \u4e3b\u51fd\u6570\u5b9a\u4e49","text":"<p>\u5728\u4e3b\u7a0b\u5e8f\u4e2d\u52a0\u8f7d\u4e86\u9884\u8bad\u7ec3\u7684BERT\u6a21\u578b\u548c\u76f8\u5173\u914d\u7f6e\uff0c\u521b\u5efa\u4e86\u6a21\u578b\u5b9e\u4f8b\uff0c\u5e76\u5bf9\u6307\u5b9a\u6587\u672c\u8fdb\u884c\u5206\u6790\u63a8\u7406\u3002\u6700\u540e\u8f93\u51fa\u4e86\u6a21\u578b\u5bf9\u6587\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u3002\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>if __name__ == '__main__':\n    # \u52a0\u8f7dBERT\u6a21\u578b\u914d\u7f6e\u548c\u6a21\u578b\n    model_name = 'bert'\n    x = import_module('models.' + model_name)\n    config = x.Config()\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\uff0c\u4fdd\u8bc1\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\n    np.random.seed(1)\n    torch.manual_seed(1)\n    torch.cuda.manual_seed_all(1)\n    torch.backends.cudnn.deterministic = True\n    # \u521b\u5efa\u5e76\u52a0\u8f7dBERT\u6a21\u578b\n    model = x.Model(config).to(config.device)\n    model.load_state_dict(torch.load(config.save_path, map_location=config.device))\n    # \u5f85\u5206\u6790\u7684\u6587\u672c\n    input_text = '\u65e5\u672c\u5730\u9707\uff1a\u91d1\u5409\u5217\u5173\u6ce8\u5728\u65e5\u5b66\u5b50\u7cfb\u5217\u62a5\u9053'\n    # \u8fdb\u884c\u6a21\u578b\u63a8\u7406\n    res = inference(model, config, input_text)\n    # \u83b7\u53d6\u7c7b\u522b\u540d\n    result = id_to_name[res.item()]\n    print(result)\n</code></pre> <p>\u6267\u884c\u4e0a\u8ff0\u4ee3\u7801\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a\uff1a</p> <pre><code>education\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#8","title":"8.\u6a21\u578b\u90e8\u7f72","text":"<p>\u5c06\u8bad\u7ec3\u597d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e94\u7528\u5230\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u5c06\u6a21\u578b\u4ee5\u670d\u52a1\u7684\u5f62\u5f0f\u63d0\u4f9b\uff0c\u5141\u8bb8\u5176\u4ed6\u7cfb\u7edf\u901a\u8fc7 API \u8c03\u7528\uff0c\u5b9e\u73b0\u6a21\u578b\u7684\u53ef\u590d\u7528\u6027\u3002</p>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#81","title":"8.1 \u670d\u52a1\u7aef\u4ee3\u7801","text":"<p>\u5229\u7528Flask\u5e94\u7528\u642d\u5efa\u4e00\u4e2aWeb\u670d\u52a1\uff0c\u7528\u6765\u63a5\u6536\u5ba2\u6237\u7aef\u901a\u8fc7POST\u8bf7\u6c42\u53d1\u9001\u7684\u6587\u672c\u6570\u636e\uff0c\u7136\u540e\u4f7f\u7528\u9884\u8bad\u7ec3\u7684BERT\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff0c\u6700\u540e\u8fd4\u56de\u9884\u6d4b\u7ed3\u679c\u3002\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/app.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a</p> <pre><code>import torch\nfrom flask import Flask, request\nfrom importlib import import_module\nimport numpy as np\n</code></pre> <p>\u63a5\u4e0b\u6765\u52a0\u8f7d\u4e86\u9884\u8bad\u7ec3\u7684BERT\u60c5\u611f\u5206\u6790\u6a21\u578b\u548c\u76f8\u5173\u914d\u7f6e\uff0c\u5e76\u5b9a\u4e49\u63a8\u7406\u51fd\u6570\uff0c\u4e0e\u4e4b\u524d\u63d0\u5230\u7684\u63a8\u7406\u51fd\u6570\u76f8\u540c\uff0c\u7528\u4e8e\u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u5206\u7c7b\uff0c\u4e0e\u4e0a\u8ff0\u6a21\u578b\u9884\u6d4b\u65f6\u7c7b\u4f3c\uff1a</p> <pre><code># \u5b9a\u4e49BERT\u7279\u6b8a\u7b26\u53f7\u548c\u7c7b\u522b\u6620\u5c04\nCLS = '[CLS]'\nid_to_name = {0: 'finance', 1: 'realty', 2: 'stocks', 3: 'education', 4: 'science',\n              5: 'society', 6: 'politics', 7: 'sports', 8: 'game', 9: 'entertainment'}\n\n# \u52a0\u8f7dBERT\u60c5\u611f\u5206\u6790\u6a21\u578b\u548c\u76f8\u5173\u914d\u7f6e\nmodel_name = 'bert'\nx = import_module('models.' + model_name)\nconfig = x.Config()\nnp.random.seed(1)\ntorch.manual_seed(1)\ntorch.cuda.manual_seed_all(1)\ntorch.backends.cudnn.deterministic = True\n\nmodel = x.Model(config).to(config.device)\nmodel.load_state_dict(torch.load(config.save_path, map_location='cpu'))\n\n# \u63a8\u7406\u51fd\u6570\uff0c\u7528\u4e8e\u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u5206\u7c7b\u5206\u6790,\u4e0e\u6a21\u578b\u9884\u6d4b\u90e8\u5206\u662f\u4e00\u6837\u7684\ndef inference(model, config, input_text, pad_size=32):\n    # \u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u5206\u8bcd\u548c\u9884\u5904\u7406\n    content = config.tokenizer.tokenize(input_text)\n    content = [CLS] + content\n    seq_len = len(content)\n    token_ids = config.tokenizer.convert_tokens_to_ids(content)\n    # \u586b\u5145\u6216\u622a\u65ad\u6587\u672c\u5230\u6307\u5b9a\u957f\u5ea6\n    if seq_len &lt; pad_size:\n        mask = [1] * len(token_ids) + [0] * (pad_size - seq_len)\n        token_ids += [0] * (pad_size - seq_len)\n    else:\n        mask = [1] * pad_size\n        token_ids = token_ids[:pad_size]\n        seq_len = pad_size\n    # \u5c06\u5904\u7406\u540e\u7684\u6587\u672c\u8f6c\u6362\u4e3aTensor\u5f62\u5f0f\n    x = torch.LongTensor(token_ids).to(config.device)\n    seq_len = torch.LongTensor(seq_len).to(config.device)\n    mask = torch.LongTensor(mask).to(config.device)\n    # \u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\n    x = x.unsqueeze(0)\n    seq_len = seq_len.unsqueeze(0)\n    mask = mask.unsqueeze(0)\n    data = (x, seq_len, mask)\n    output = model(data)\n    # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u5e76\u8fd4\u56de\n    predict_result = torch.max(output.data, 1)[1]\n    predict_result = predict_result.item()\n    predict_result = id_to_name[predict_result]\n\n    return predict_result\n</code></pre> <p>\u6700\u540e\u4f7f\u7528Flask\u521b\u5efa\u4e00\u4e2aWeb\u5e94\u7528\u3002\u5e76\u5b9a\u4e49\u4e00\u4e2a\u8def\u7531\uff0c\u63a5\u6536POST\u8bf7\u6c42\uff0c\u4ece\u8bf7\u6c42\u4e2d\u83b7\u53d6\u7528\u6237ID\u548c\u6587\u672c\u6570\u636e\uff0c\u7136\u540e\u8c03\u7528\u63a8\u7406\u51fd\u6570\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u5c06\u7ed3\u679c\u4f5c\u4e3a\u54cd\u5e94\u8fd4\u56de\u7ed9\u5ba2\u6237\u7aef\u3002\u5982\u679c\u8be5\u811a\u672c\u4f5c\u4e3a\u4e3b\u7a0b\u5e8f\u8fd0\u884c\uff0c\u5219\u542f\u52a8Flask\u5e94\u7528\uff0c\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u521b\u5efaFlask\u5e94\u7528\napp = Flask(__name__)\n\n# \u5b9a\u4e49\u8def\u7531\uff0c\u63a5\u6536POST\u8bf7\u6c42\u5e76\u8fdb\u884c\u63a8\u7406\n@app.route('/v1/main_server/', methods=[\"POST\"])\ndef main_server():\n    # \u4ecePOST\u8bf7\u6c42\u4e2d\u83b7\u53d6\u7528\u6237ID\u548c\u6587\u672c\u6570\u636e\n    uid = request.form['uid']\n    text = request.form['text']\n    # \u8c03\u7528\u63a8\u7406\u51fd\u6570\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n    res = inference(model, config, text)\n    return res\n\n# \u5982\u679c\u811a\u672c\u4f5c\u4e3a\u4e3b\u7a0b\u5e8f\u8fd0\u884c\uff0c\u5219\u542f\u52a8Flask\u5e94\u7528\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>\u901a\u8fc7\u8fd9\u4e2aWeb\u670d\u52a1\uff0c\u5ba2\u6237\u7aef\u53ef\u4ee5\u901a\u8fc7\u5411\u670d\u52a1\u5668\u53d1\u9001\u6587\u672c\u6570\u636e\u7684POST\u8bf7\u6c42\uff0c\u83b7\u53d6BERT\u6a21\u578b\u5bf9\u6587\u672c\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6211\u4eec\u6267\u884c\u8fd9\u4e2a\u6587\u4ef6\uff0c\u8f93\u51fa\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>* Serving Flask app 'app'\n * Debug mode: off\nWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n * Running on http://127.0.0.1:5000\nPress CTRL+C to quit\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#82","title":"8.2 \u5ba2\u6237\u7aef\u4ee3\u7801","text":"<p>\u5ba2\u6237\u7aef\u4ee3\u7801\u5411Flask\u5e94\u7528\u53d1\u9001HTTP POST\u8bf7\u6c42\uff0c\u4f20\u9012\u6587\u672c\u6570\u636e\uff0c\u7136\u540e\u83b7\u53d6Flask\u5e94\u7528\u8fd4\u56de\u7684\u6587\u672c\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u6253\u5370\u51fa\u9884\u6d4b\u7ed3\u679c\u548c\u5355\u6761\u6837\u672c\u7684\u5904\u7406\u8017\u65f6\u3002\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/demo.py\n</code></pre> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>import requests\nimport time\n\n# \u5b9a\u4e49\u8bf7\u6c42url\u548c\u4f20\u5165\u7684data\nurl = \"http://127.0.0.1:5000/v1/main_server/\"\ndata = {\"uid\": \"AI-12-001\", \"text\": \"\u65e5\u672c\u5730\u9707\uff1a\u91d1\u5409\u5217\u5173\u6ce8\u5728\u65e5\u5b66\u5b50\u7cfb\u5217\u62a5\u9053\"}\n\nstart_time = time.time()\n# \u5411\u670d\u52a1\u53d1\u9001post\u8bf7\u6c42\nres = requests.post(url, data=data)\ncost_time = time.time() - start_time\n\n# \u6253\u5370\u8fd4\u56de\u7684\u7ed3\u679c\nprint('\u6587\u672c\u7c7b\u522b: ', res.text)\nprint('\u5355\u6761\u6837\u672c\u8017\u65f6: ', cost_time * 1000, 'ms')\n</code></pre> <p>\u6267\u884c\u4e0a\u8ff0\u4ee3\u7801\uff0c\u9884\u6d4b\u7ed3\u679c\u4e3a\uff1a</p> <pre><code>\u6587\u672c\u7c7b\u522b:  education\n\u5355\u6761\u6837\u672c\u8017\u65f6:  181.6861629486084 ms\n</code></pre>"},{"location":"06-bert%E6%A8%A1%E5%9E%8B.html#9","title":"9.\u603b\u7ed3","text":"<ul> <li> <p>\u5b9e\u73b0\u4e86\u82e5\u5e72\u5de5\u5177\u51fd\u6570, \u5305\u62ec\u6570\u636e\u7684\u83b7\u53d6\u7b49\u5185\u5bb9.</p> </li> <li> <p>\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT\u5b9e\u73b0\u6295\u6ee1\u5206\u5206\u7c7b\u7684\u6a21\u578b, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.</p> </li> <li>\u5b9e\u73b0\u4e86\u6a21\u578b\u9884\u6d4b\u548c\u90e8\u7f72\u7684\u5185\u5bb9</li> </ul>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html","title":"\u6a21\u578b\u91cf\u5316","text":"<p>\u5b66\u4e60\u76ee\u6807\uff1a</p> <p>1.\u77e5\u9053\u4ec0\u4e48\u662f\u91cf\u5316\uff1f</p> <p>2.\u80fd\u591f\u5229\u7528pytorch\u5b8c\u6210\u6a21\u578b\u91cf\u5316</p>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#1","title":"1. \u4ec0\u4e48\u662f\u6a21\u578b\u7684\u91cf\u5316","text":"<ul> <li>\u901a\u4fd7\u7684\u7406\u89e3, \u5c31\u662f\u5c06\u6a21\u578b\u7684\u53c2\u6570\u7cbe\u5ea6\u8fdb\u884c\u964d\u4f4e\u64cd\u4f5c, \u7528\u66f4\u5c11\u7684\u6bd4\u7279\u4f4d(torch.qint8)\u4ee3\u66ff\u8f83\u591a\u7684\u6bd4\u7279\u4f4d(torch.float32), \u4ece\u800c\u7f29\u51cf\u6a21\u578b, \u5e76\u52a0\u901f\u63a8\u65ad\u901f\u5ea6.</li> </ul> <ul> <li>\u5982\u4e0a\u56fe\u6240\u793a, \u5de6\u4fa7\u7684\u662f\u539f\u59cb\u6a21\u578b\u62e5\u6709\u66f4\u9ad8\u7684\u53c2\u6570\u7cbe\u5ea6(float32), \u7b49\u6548\u4e8e\u50cf\u7d20\u9ad8, \u770b\u7684\u6e05\u6670; \u53f3\u4fa7\u7684\u662f\u91cf\u5316\u540e\u7684\u6a21\u578b, \u62e5\u6709\u8f83\u4f4e\u7684\u53c2\u6570\u7cbe\u5ea6(int8), \u7b49\u6548\u4e8e\u50cf\u7d20\u4f4e, \u770b\u7684\u6a21\u7cca, \u4f46\u4f9d\u7136\u53ef\u4ee5\u51c6\u786e\u7684\u8bc6\u522b\u56fe\u50cf\u5185\u5bb9.</li> <li>Pytorch\u7684\u52a8\u6001\u91cf\u5316(Dynamic Quantization).</li> </ul>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#2pytorch","title":"2.Pytorch\u7684\u91cf\u5316","text":"<p>\u76f4\u63a5\u4f7f\u7528torch.quantization.quantize_dynamic()\u6765\u5b9e\u73b0\u91cf\u5316\u64cd\u4f5c\u5373\u53ef,\u91cf\u5316\u9700\u8981\u5728cpu\u4e2d\u5b8c\u6210\uff0c\u6240\u4ee5\u9700\u8981\u628a\u8bbe\u5907\u4fe1\u606f\u8bbe\u7f6e\u4e3acpu.</p>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#21-config","title":"2.1 \u914d\u7f6e\u7c7b\u6587\u4ef6\u4e2d\u7684Config\u7c7b","text":"<p>\u5c06\u8bbe\u5907\u4fe1\u606f\u4fee\u6539\u4e3acpu,\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/models/bert.py\n</code></pre> <p>\u5177\u4f53\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u5728class Config\u4e2d\u7684__init__\u51fd\u6570\u4e2d\u4fee\u6539\u4e0b\u5217\u4ee3\u7801\u90e8\u5206\n\n# \u6a21\u578b\u8bad\u7ec3+\u9884\u6d4b\u7684\u65f6\u5019, \u653e\u5f00\u4e0b\u4e00\u884c\u4ee3\u7801, \u5728GPU\u4e0a\u8fd0\u884c.\n# self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # \u8bbe\u5907\n# \u6a21\u578b\u91cf\u5316\u7684\u65f6\u5019, \u653e\u5f00\u4e0b\u4e00\u884c\u4ee3\u7801, \u5728CPU\u4e0a\u8fd0\u884c.\nself.device = 'cpu'\n</code></pre>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#22","title":"2.2 \u6a21\u578b\u91cf\u5316\u5b9e\u73b0","text":"<p>\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e0a\u4e00\u7ae0\u8282\u8bad\u7ec3\u597d\u7684bert\u6a21\u578b\u8fdb\u884c\u91cf\u5316</p> <p>\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>04-bert/src/run1.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\u548c\u6a21\u5757\uff1a</p> <pre><code># \u5bfc\u5165\u82e5\u5e72\u5de5\u5177\u5305\nimport torch\nimport numpy as np\nfrom train_eval import test\nfrom importlib import import_module\nimport argparse\nfrom utils import build_dataset, build_iterator\n</code></pre> <p>\u63a5\u4e0b\u6765\u6839\u636e\u547d\u4ee4\u884c\u53c2\u6570\u9009\u62e9\u4f7f\u7528\u7684\u6a21\u578b\u7c7b\u578b\uff08\u9ed8\u8ba4\u4e3a \"bert\"\uff09\uff0c\u7136\u540e\u52a0\u8f7d\u5bf9\u5e94\u6a21\u578b\u7684\u914d\u7f6e\u548c\u6a21\u578b\u5b9a\u4e49\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u6784\u5efa\u6570\u636e\u96c6\u548c\u6570\u636e\u8fed\u4ee3\u5668\uff0c\u51c6\u5907\u597d\u7528\u4e8e\u6d4b\u8bd5\u7684\u6570\u636e\u3002\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\uff0c\u5e76\u5c06\u6a21\u578b\u91cf\u5316\u4e3a8\u4f4d\u6574\u6570\u3002\u6700\u540e\uff0c\u6d4b\u8bd5\u91cf\u5316\u540e\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4fdd\u5b58\u91cf\u5316\u540e\u7684\u6a21\u578b\u3002</p> <pre><code># \u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790\nparser = argparse.ArgumentParser(description=\"Chinese Text Classification\")\nparser.add_argument(\"--model\", type=str, default='bert', help=\"choose a model: bert\")\nargs = parser.parse_args()\n\nif __name__ == '__main__':\n    if args.model == 'bert':\n        # \u6307\u5b9a\u6a21\u578b\u7c7b\u578b\u4e3abert\n        model_name = 'bert'\n        x = import_module(\"models.\" + model_name)\n        config = x.Config()\n        # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\uff0c\u4fdd\u8bc1\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\n        np.random.seed(1)\n        torch.manual_seed(1)\n        torch.cuda.manual_seed_all(1)\n        torch.backends.cudnn.deterministic = True\n        # \u6570\u636e\u8fed\u4ee3\u5668\u7684\u9884\u5904\u7406\u548c\u751f\u6210\n        print('Loading data for Bert Model...')\n        train_data, dev_data, test_data = build_dataset(config)\n        train_iter = build_iterator(train_data, config)\n        dev_iter = build_iterator(dev_data, config)\n        test_iter = build_iterator(test_data, config)\n        # \u5b9e\u4f8b\u5316\u6a21\u578b\u5e76\u52a0\u8f7d\u53c2\u6570\uff0c\u6ce8\u610f\u4e0d\u8981\u52a0\u8f7d\u5230GPU\u4e0a\uff0c\u53ea\u80fd\u5728CPU\u4e0a\u5b9e\u73b0\u6a21\u578b\u91cf\u5316\n        model = x.Model(config)\n        print(model)\n        model.load_state_dict(torch.load(config.save_path, map_location='cpu'))\n        # \u91cf\u5316BERT\u6a21\u578b\n        quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n        print(quantized_model)\n        # \u6d4b\u8bd5\u91cf\u5316\u540e\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\n        test(config, quantized_model, test_iter)\n        # \u4fdd\u5b58\u91cf\u5316\u540e\u7684\u6a21\u578b\n        torch.save(quantized_model, config.save_path2)\n</code></pre>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#23","title":"2.3 \u8f93\u51fa\u7ed3\u679c","text":""},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#1lineardynamicquantizedlinear","title":"1.\u6a21\u578b\u4e2d\u7684\u6240\u6709Linear\u5c42\u53d8\u6210\u4e86DynamicQuantizedLinear\u5c42","text":""},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#3","title":"3.\u8bad\u7ec3\u548c\u8bc4\u4f30\u7ed3\u679c","text":"<pre><code>Test Loss:  0.25,  Test Acc: 91.92%\nPrecision, Recall and F1-Score...\n               precision    recall  f1-score   support\n\n      finance     0.9561    0.8490    0.8994      1000\n       realty     0.9499    0.9300    0.9399      1000\n       stocks     0.8478    0.8580    0.8529      1000\n    education     0.9740    0.9360    0.9546      1000\n      science     0.8407    0.9080    0.8731      1000\n      society     0.9173    0.9100    0.9137      1000\n     politics     0.8961    0.9230    0.9094      1000\n       sports     0.9836    0.9620    0.9727      1000\n         game     0.9562    0.9390    0.9475      1000\nentertainment     0.8898    0.9770    0.9314      1000\n\n     accuracy                         0.9192     10000\n    macro avg     0.9212    0.9192    0.9194     10000\n weighted avg     0.9212    0.9192    0.9194     10000\n\nConfusion Matrix...\n[[849   9  99   0   8  14  14   2   2   3]\n [  7 930  15   0   8  13   8   1   3  15]\n [ 26  18 858   0  54   1  35   1   3   4]\n [  1   3   1 936  15  17  11   1   0  15]\n [  1   2  15   2 908  12   8   1  28  23]\n [  0  13   1  14  11 910  27   1   4  19]\n [  3   2  18   5  31  13 923   0   0   5]\n [  1   2   2   0   3   5   0 962   1  24]\n [  0   0   3   1  37   4   0   3 939  13]\n [  0   0   0   3   5   3   4   6   2 977]]\n</code></pre> <p>\u7ed3\u8bba: \u7ecf\u8fc7\u91cf\u5316\u540e\u7684BERT\u6a21\u578b, F1=91.92%, \u76f8\u6bd4\u4e8e\u91cf\u5316\u524d\u7684F1=93.64%\u6709\u6bd4\u8f83\u663e\u8457\u7684\u4e0b\u964d, \u4f46\u8fd8\u53ef\u4ee5\u63a5\u53d7, \u4e5f\u8bf4\u660eBERT\u6a21\u578b\u7684\u9c81\u68d2\u6027\u975e\u5e38\u9ad8!</p>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#3_1","title":"3.\u5bf9\u6bd4\u6a21\u578b\u538b\u7f29\u540e\u7684\u5927\u5c0f","text":"<p>\u6a21\u578b\u53c2\u6570\u6587\u4ef6\u5927\u5c0f\u7f29\u51cf\u4e86256.6MB, \u540c\u65f6\u8003\u8651\u5230F1\u503c\u4ec5\u4ec5\u4e0b\u964d\u4e86\u4e0d\u52302\u4e2a\u767e\u5206\u70b9, \u6548\u679c\u975e\u5e38\u4f18\u5f02!</p>"},{"location":"07-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.html#3_2","title":"3.\u603b\u7ed3","text":"<ul> <li>\u5b9e\u73b0\u4e86\u5bf9\u6a21\u578b\u7684\u52a8\u6001\u91cf\u5316, \u5e76\u5728CPU\u4e0a\u6d4b\u8bd5\u4e86\u91cf\u5316\u540e\u7684\u6a21\u578b\u7684\u8868\u73b0, \u9a8c\u8bc1\u4e86BERT\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027.</li> <li> <p>\u5bf9\u6bd4\u4e86BERT\u6a21\u578b\u91cf\u5316\u524d\u540e\u7684\u5927\u5c0f, \u8bf4\u660eBERT\u6a21\u578b\u7684\u538b\u7f29\u7387\u5f88\u9ad8, \u540c\u65f6\u8fd8\u80fd\u4fdd\u6301\u8868\u73b0\u4e0d\u4f1a\u663e\u8457\u4e0b\u964d. </p> </li> <li> <p>\u6ce8\u610f: \u5982\u679c\u5c06\u6a21\u578b\u52a0\u8f7d\u5230GPU\u4e0a\u76f4\u63a5\u91cf\u5316, \u4f1a\u62a5\u9519\u5982\u4e0b:</p> </li> </ul> <pre><code># \u8fd9\u8bf4\u660e\u52a8\u6001\u91cf\u5316\u76ee\u524d\u5728Pytorch\u5e73\u53f0\u4e0a\u4ec5\u4ec5\u652f\u6301CPU\u4e0a\u7684\u64cd\u4f5c!\n\nuntimeError: Could not run 'quantized::linear_prepack' with arguments from the 'UNKNOWN_TENSOR_TYPE_ID' backend. 'quantized::linear_prepack' is only available for these backends: [QuantizedCPU].\n</code></pre>"},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html","title":"\u77e5\u8bc6\u84b8\u998f\u7684\u6982\u5ff5\u4ecb\u7ecd","text":"<p>\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u7406\u89e3\u4ec0\u4e48\u662f\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f.</li> </ul> <p></p>"},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html#1","title":"1.\u4ec0\u4e48\u662f\u6a21\u578b\u84b8\u998f","text":"<p>\u5728\u5de5\u4e1a\u7ea7\u7684\u5e94\u7528\u4e2d, \u9664\u4e86\u8981\u6c42\u6a21\u578b\u8981\u6709\u597d\u7684\u9884\u6d4b\u6548\u679c\u4e4b\u5916, \u5f80\u5f80\u8fd8\u5e0c\u671b\u5b83\u7684\"\u6d88\u8017\"\u8db3\u591f\u5c0f. \u4e5f\u5c31\u662f\u8bf4\u4e00\u822c\u5e0c\u671b\u90e8\u7f72\u5728\u7ebf\u4e0a\u7684\u5e94\u7528\u6a21\u578b\u6d88\u8017\u8f83\u5c0f\u7684\u8d44\u6e90. \u8fd9\u4e9b\u8d44\u6e90\u5305\u62ec\u5b58\u50a8\u7a7a\u95f4, \u5305\u62ec\u7b97\u529b.</p> <p>\u5728\u6df1\u5ea6\u5b66\u4e60\u80cc\u666f\u4e0b, \u5982\u679c\u5e0c\u671b\u6a21\u578b\u7684\u6548\u679c\u8db3\u591f\u597d, \u901a\u5e38\u4f1a\u6709\u4e24\u79cd\u65b9\u6848: * \u4f7f\u7528\u66f4\u5927\u89c4\u6a21\u7684\u53c2\u6570. * \u4f7f\u7528\u96c6\u6210\u6a21\u578b, \u5c06\u591a\u4e2a\u5f31\u6a21\u578b\u96c6\u6210\u8d77\u6765.</p> <p>\u6ce8\u610f: \u4e0a\u9762\u4e24\u79cd\u65b9\u6848\u5f80\u5f80\u9700\u8981\u8f83\u5927\u7684\u8ba1\u7b97\u8d44\u6e90, \u5bf9\u90e8\u7f72\u975e\u5e38\u4e0d\u5229. \u7531\u6b64\u4ea7\u751f\u4e86\u6a21\u578b\u538b\u7f29\u7684\u52a8\u673a: \u6211\u4eec\u5e0c\u671b\u6709\u4e00\u4e2a\u5c0f\u6a21\u578b, \u4f46\u53c8\u80fd\u8fbe\u5230\u5927\u6a21\u578b\u4e00\u6837\u6216\u76f8\u5f53\u7684\u6548\u679c.</p> <p>\u6a21\u578b\u84b8\u998f\u662f\u4e00\u79cd\u901a\u8fc7\u5c06\u4e00\u4e2a\u590d\u6742\u6a21\u578b\uff08\u6559\u5e08\u6a21\u578b\uff09\u7684\u77e5\u8bc6\u8f6c\u79fb\u7ed9\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff08\u5b66\u751f\u6a21\u578b\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\u3002\u5728\u51cf\u5c0f\u6a21\u578b\u4f53\u79ef\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002 * \u77e5\u8bc6\u84b8\u998f\u7684\u6982\u5ff5\u6700\u65e9\u7531Hinton\u57282015\u5e74\u63d0\u51fa, \u57282019\u5e74\u540e\u706b\u70ed\u8d77\u6765. * \u77e5\u8bc6\u84b8\u998f\u5728\u76ee\u524d\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u65e2\u524d\u6cbf\u53c8\u5e38\u7528\u7684\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u90e8\u7f72\u4f18\u52bf\u7684\u65b9\u6cd5.</p>"},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html#2","title":"2.\u77e5\u8bc6\u84b8\u998f\u7684\u539f\u7406\u548c\u7b97\u6cd5","text":""},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html#21","title":"2.1 \u6559\u5e08\u6a21\u578b","text":"<ul> <li>\u5b9a\u4e49\uff1a \u590d\u6742\u7684\u3001\u9ad8\u6027\u80fd\u7684\u6a21\u578b\uff0c\u901a\u5e38\u662f\u5927\u578b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002</li> <li>\u7279\u70b9\uff1a \u53c2\u6570\u91cf\u5927\uff0c\u80fd\u591f\u5b66\u4e60\u590d\u6742\u7684\u7279\u5f81\u548c\u5173\u7cfb\u3002</li> </ul>"},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html#22","title":"2.2 \u5b66\u751f\u6a21\u578b","text":"<ul> <li>\u5b9a\u4e49\uff1a \u7b80\u5316\u7684\u3001\u5c0f\u578b\u7684\u6a21\u578b\uff0c\u901a\u5e38\u662f\u6559\u5e08\u6a21\u578b\u7684\u5b50\u96c6\u3002</li> <li>\u7279\u70b9\uff1a \u53c2\u6570\u91cf\u8f83\u5c0f\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u573a\u666f\u3002</li> </ul>"},{"location":"08-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html#23","title":"2.3 \u84b8\u998f\u8fc7\u7a0b","text":"<p>\u4e0b\u56fe\u975e\u5e38\u76f4\u89c2, \u53c8\u7ecf\u5178\u7684\u5c55\u793a\u4e86\u77e5\u8bc6\u84b8\u998f\u7684\u67b6\u6784\u56fe, \u76f8\u5f53\u4e8e\u6709\u4e24\u90e8\u5206\u7684\u5206\u652f: * \u4e00\u90e8\u5206\u662f\u5927\u6a21\u578b\u7684softmax\u5206\u5e03\u4f5c\u4e3a\"\u77e5\u8bc6\u6807\u7b7e\", \u8ba9\u5c0f\u6a21\u578b\u53bb\u5b66\u4e60. * \u4e00\u90e8\u5206\u662f\u771f\u5b9elabel(ground truth)\u4f5c\u4e3a\"\u771f\u5b9e\u6807\u7b7e\", \u8ba9\u5c0f\u6a21\u578b\u53bb\u5339\u914d.</p> <p></p> <p>\u6211\u4eec\u5bf9\u77e5\u8bc6\u84b8\u998f\u8fdb\u884c\u516c\u5f0f\u5316\u5904\u7406: \u5148\u8bad\u7ec3\u597d\u4e00\u4e2a\u7cbe\u5ea6\u8f83\u9ad8\u7684Teacher\u7f51\u7edc(\u4e00\u822c\u662f\u590d\u6742\u5ea6\u8f83\u9ad8\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b), \u7136\u540e\u5c06Teacher\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679cq\u4f5c\u4e3aStudent\u7f51\u7edc\u7684\"\u5b66\u4e60\u76ee\u6807\", \u6765\u8bad\u7ec3Student\u7f51\u7edc(\u4e00\u822c\u662f\u901f\u5ea6\u8f83\u5feb\u7684\u5c0f\u89c4\u6a21\u6a21\u578b), \u6700\u7ec8\u4f7f\u5f97Student\u7f51\u7edc\u7684\u7ed3\u679cp\u63a5\u8fd1\u4e8eq. \u635f\u5931\u51fd\u6570\u5982\u4e0b:</p> <p></p> <ul> <li>\u4e0a\u5f0f\u4e2dCE\u662f\u4ea4\u53c9\u71b5(Cross Entropy), y\u662f\u771f\u5b9e\u6807\u7b7e, q\u662fTeacher\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c, p\u662fStudent\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c.</li> </ul> <p>\u539f\u59cb\u8bba\u6587\u4e2d\u63d0\u51fa\u4e86softmax-T\u516c\u5f0f\u6765\u8ba1\u7b97\u4e0a\u56fe\u4e2d\u7684q:</p> <p></p> <ul> <li>\u4e0a\u5f0f\u4e2dpi\u662fStudent\u7f51\u7edc\u5b66\u4e60\u7684\u5bf9\u8c61, \u4e5f\u5c31\u662f\u6240\u8c13\u7684\u8f6f\u76ee\u6807(soft targets), zi\u662f\u795e\u7ecf\u7f51\u7edcsoftmax\u524d\u7684\u8f93\u51falogits. </li> </ul> <p>\u4e0d\u540c\u7684\u6e29\u5ea6\u7cfb\u6570T\u503c, \u5bf9softmax-T\u7b97\u6cd5\u6709\u4e0d\u540c\u7684\u5f71\u54cd, \u603b\u7ed3\u5982\u4e0b: * \u5982\u679c\u5c06T\u503c\u53d61, softmax-T\u516c\u5f0f\u5c31\u6210\u4e3asoftmax\u516c\u5f0f, \u6839\u636elogits\u8f93\u51fa\u5404\u4e2a\u7c7b\u522b\u7684\u6982\u7387. * \u5982\u679cT\u8d8a\u63a5\u8fd1\u4e8e0, \u5219\u6700\u5927\u503c\u4f1a\u8d8a\u63a5\u8fd11, \u5176\u4ed6\u503c\u4f1a\u63a5\u8fd10, \u7c7b\u4f3c\u4e8e\u9000\u5316\u6210one-hot\u7f16\u7801. * \u5982\u679cT\u8d8a\u5927, \u5219\u8f93\u51fa\u7684\u7ed3\u679c\u5206\u5e03\u8d8a\u5e73\u7f13, \u76f8\u5f53\u4e8e\u6807\u7b7e\u5e73\u6ed1\u7684\u539f\u7406, \u8d77\u5230\u4fdd\u7559\u76f8\u4f3c\u4fe1\u606f\u7684\u4f5c\u7528. * \u5982\u679cT\u8d8b\u4e8e\u65e0\u7a77\u5927, \u5219\u6f14\u53d8\u6210\u5747\u5300\u5206\u5e03.</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html","title":"\u77e5\u8bc6\u84b8\u998f\u5b9e\u8df5","text":"<p>\u5b66\u4e60\u76ee\u6807\uff1a</p> <ul> <li>\u638c\u63e1\u77e5\u8bc6\u84b8\u998f\u7684\u4ee3\u7801\u64cd\u4f5c.</li> <li>\u638c\u63e1\u77e5\u8bc6\u84b8\u998f\u540e\u6a21\u578b\u7684\u6027\u80fd\u6d4b\u8bd5.</li> </ul>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#1","title":"1.\u4ee3\u7801\u7ed3\u6784","text":""},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#2","title":"2.\u6570\u636e\u51c6\u5907","text":"<p>\u8be5\u90e8\u5206\u7684\u6570\u636e\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u4e0eBert\u6a21\u578b\u7ae0\u8282\u662f\u4e00\u6837\u7684\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#3","title":"3.\u7f16\u5199\u5de5\u5177\u7c7b\u51fd\u6570","text":"<p>\u5de5\u5177\u7c7b\u51fd\u6570\u7684\u8def\u5f84\u4e3a\uff1a</p> <pre><code>05-bert_distil/src/utils.py\n</code></pre> <p>\u5bfc\u5165\u5de5\u5177\u5305\u5982\u4e0b\uff1a</p> <pre><code>import torch\nfrom tqdm import tqdm\nimport time\nfrom datetime import timedelta\nimport os\nimport pickle as pkl\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#31-build_vocab","title":"3.1 \u5de5\u5177\u7c7b\u51fd\u6570build_vocab()","text":"<p>build_vocab()\u662f\u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u6587\u672c\u6570\u636e\u4e2d\u7684\u5355\u8bcd\u6620\u5c04\u4e3a\u7d22\u5f15\u3002\u51fd\u6570\u7684\u4e3b\u8981\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u521d\u59cb\u5316\uff1a \u51fd\u6570\u5f00\u59cb\u65f6\u5b9a\u4e49\u4e86\u4e09\u4e2a\u7279\u6b8a\u7b26\u53f7\uff08<code>UNK</code>, <code>PAD</code>, <code>CLS</code>\uff09\uff0c\u5b83\u4eec\u5206\u522b\u4ee3\u8868\u672a\u77e5\u7b26\u53f7\u3001\u586b\u5145\u7b26\u53f7\u548c\u7efc\u5408\u4fe1\u606f\u7b26\u53f7\u3002\u8fd9\u4e9b\u7b26\u53f7\u5728\u6784\u5efa\u8bcd\u6c47\u8868\u65f6\u5c06\u88ab\u6dfb\u52a0\u3002</li> <li>\u904d\u5386\u6587\u672c\u6587\u4ef6\uff1a \u51fd\u6570\u901a\u8fc7\u6253\u5f00\u6307\u5b9a\u8def\u5f84\u7684\u6587\u672c\u6587\u4ef6\uff0c\u9010\u884c\u904d\u5386\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9\u3002\u6bcf\u884c\u901a\u5e38\u5305\u542b\u4e00\u6bb5\u6587\u672c\uff0c\u8fd9\u91cc\u9009\u62e9\u6bcf\u884c\u7684\u7b2c\u4e00\u4e2a\u5b57\u6bb5\u4f5c\u4e3a\u5185\u5bb9\u3002</li> <li>\u5206\u8bcd\u548c\u6784\u5efa\u8bcd\u6c47\u8868\uff1a \u5bf9\u6bcf\u4e2a\u5185\u5bb9\u4f7f\u7528\u7ed9\u5b9a\u7684\u5206\u8bcd\u5668\u8fdb\u884c\u5206\u8bcd\uff0c\u7136\u540e\u66f4\u65b0\u8bcd\u6c47\u8868\u5b57\u5178\u3002\u5206\u8bcd\u7684\u7ed3\u679c\u662f\u5c06\u6587\u672c\u5212\u5206\u4e3a\u5355\u8bcd\u6216\u5b50\u8bcd\uff0c\u800c\u8bcd\u6c47\u8868\u5b57\u5178\u5219\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\u3002</li> <li>\u7b5b\u9009\u9ad8\u9891\u8bcd\u6c47\uff1a \u5bf9\u8bcd\u6c47\u8868\u5b57\u5178\u6839\u636e\u8bcd\u9891\u8fdb\u884c\u6392\u5e8f\uff0c\u9009\u62e9\u51fa\u73b0\u9891\u7387\u8f83\u9ad8\u7684\u8bcd\u6c47\u3002\u8fd9\u91cc\u6839\u636e\u53c2\u6570 <code>min_freq</code> \u6307\u5b9a\u7684\u6700\u5c0f\u51fa\u73b0\u9891\u7387\u8fdb\u884c\u7b5b\u9009\u3002</li> <li>\u6784\u5efa\u6700\u7ec8\u8bcd\u6c47\u8868\uff1a \u5c06\u9009\u5b9a\u7684\u9ad8\u9891\u8bcd\u6c47\u6784\u5efa\u4e3a\u5b57\u5178\uff0c\u5c06\u6bcf\u4e2a\u8bcd\u6c47\u6620\u5c04\u5230\u4e00\u4e2a\u552f\u4e00\u7684\u7d22\u5f15\u3002\u6b64\u5916\uff0c\u51fd\u6570\u8fd8\u5c06\u7279\u6b8a\u7b26\u53f7\uff08<code>UNK</code>, <code>PAD</code>, <code>CLS</code>\uff09\u6dfb\u52a0\u5230\u8bcd\u6c47\u8868\u4e2d\uff0c\u5206\u522b\u8d4b\u4e88\u5b83\u4eec\u989d\u5916\u7684\u7d22\u5f15\u3002</li> <li>\u8fd4\u56de\u7ed3\u679c\uff1a \u8fd4\u56de\u6784\u5efa\u597d\u7684\u8bcd\u6c47\u8868\u5b57\u5178\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8bcd\u6c47\u90fd\u4e0e\u4e00\u4e2a\u552f\u4e00\u7684\u7d22\u5f15\u76f8\u5173\u8054\u3002\u8fd9\u4e2a\u8bcd\u6c47\u8868\u540e\u7eed\u53ef\u7528\u4e8e\u5c06\u6587\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u53ef\u63a5\u53d7\u7684\u8f93\u5165\u5f62\u5f0f\uff0c\u5373\u5c06\u6587\u672c\u4e2d\u7684\u6bcf\u4e2a\u5355\u8bcd\u6620\u5c04\u4e3a\u5bf9\u5e94\u7684\u7d22\u5f15\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>UNK, PAD, CLS = \"[UNK]\", \"[PAD]\", \"[CLS]\"  # padding\u7b26\u53f7, bert\u4e2d\u7efc\u5408\u4fe1\u606f\u7b26\u53f7\nMAX_VOCAB_SIZE = 10000  # \u8bcd\u8868\u957f\u5ea6\u9650\u5236\ndef build_vocab(file_path, tokenizer, max_size, min_freq):\n\"\"\"\n    \u6784\u5efa\u8bcd\u6c47\u8868\u7684\u51fd\u6570\u3002\n\n    \u53c2\u6570\uff1a\n    - file_path (str): \u5305\u542b\u6587\u672c\u6570\u636e\u7684\u6587\u4ef6\u8def\u5f84\u3002\n    - tokenizer (function): \u7528\u4e8e\u5206\u8bcd\u7684\u51fd\u6570\uff0c\u63a5\u53d7\u4e00\u4e2a\u5b57\u7b26\u4e32\u5e76\u8fd4\u56de\u5206\u8bcd\u540e\u7684\u7ed3\u679c\u3002\n    - max_size (int): \u8bcd\u6c47\u8868\u7684\u6700\u5927\u5927\u5c0f\uff0c\u5373\u4fdd\u7559\u7684\u8bcd\u6c47\u6570\u91cf\u4e0a\u9650\u3002\n    - min_freq (int): \u8bcd\u6c47\u8868\u4e2d\u8bcd\u8bed\u7684\u6700\u5c0f\u51fa\u73b0\u9891\u7387\uff0c\u4f4e\u4e8e\u6b64\u9891\u7387\u7684\u8bcd\u6c47\u5c06\u88ab\u8fc7\u6ee4\u6389\u3002\n\n    \u8fd4\u56de\uff1a\n    - vocab_dic (dict): \u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u8bcd\u6c47\u6620\u5c04\u5230\u7d22\u5f15\u7684\u8bcd\u6c47\u8868\u3002\n    \"\"\"\n    vocab_dic = {}  # \u7528\u4e8e\u5b58\u50a8\u8bcd\u6c47\u8868\u7684\u5b57\u5178\uff0c\u952e\u4e3a\u5355\u8bcd\uff0c\u503c\u4e3a\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\n    with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n        for line in tqdm(f):\n            line = line.strip()\n            if not line:\n                continue\n            content = line.split(\"\\t\")[0]  # \u4ee5\u5236\u8868\u7b26\u5206\u9694\u7684\u6587\u672c\uff0c\u8fd9\u91cc\u53d6\u7b2c\u4e00\u5217\u7684\u5185\u5bb9\n            # \u4f7f\u7528\u7ed9\u5b9a\u7684\u5206\u8bcd\u5668\uff08tokenizer\uff09\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u8bcd\uff0c\u5e76\u66f4\u65b0\u8bcd\u6c47\u8868\n            for word in tokenizer(content):\n                vocab_dic[word] = vocab_dic.get(word, 0) + 1\n        # \u6839\u636e\u8bcd\u9891\u5bf9\u8bcd\u6c47\u8868\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u9009\u62e9\u51fa\u73b0\u9891\u7387\u8f83\u9ad8\u7684\u8bcd\u6c47\n        vocab_list = sorted([_ for _ in vocab_dic.items() if _[1] &gt;= min_freq],\n                            key=lambda x: x[1], reverse=True)[:max_size]\n        # \u5c06\u9009\u5b9a\u7684\u8bcd\u6c47\u6784\u5efa\u4e3a\u5b57\u5178\uff0c\u952e\u4e3a\u5355\u8bcd\uff0c\u503c\u4e3a\u7d22\u5f15\n        vocab_dic = {word_count[0]: idx for idx, word_count in enumerate(vocab_list)}\n        # \u6dfb\u52a0\u7279\u6b8a\u7b26\u53f7\u5230\u8bcd\u6c47\u8868\uff0c\u4f8b\u5982\u672a\u77e5\u7b26\u53f7\uff08UNK\uff09\u3001\u586b\u5145\u7b26\u53f7\uff08PAD\uff09\n        vocab_dic.update({UNK: len(vocab_dic), PAD: len(vocab_dic) + 1,CLS: len(vocab_dic) + 2})\n    return vocab_dic\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#32-build_dataset_cnn","title":"3.2 \u5de5\u5177\u7c7b\u51fd\u6570build_dataset_CNN()","text":"<p>build_dataset_CNN()\u662f\u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570\uff0c\u7528\u4e8e\u521b\u5efa\u4e13\u4e3atext_cnn\u6a21\u578b\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u3002\u4ee5\u4e0b\u662f\u4ee3\u7801\u7684\u4e3b\u8981\u4f5c\u7528\uff1a</p> <p><code>d_dataset_CNN</code> \u7684\u51fd\u6570\uff0c\u7528\u4e8e\u521b\u5efa\u4e13\u4e3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u3002\u4ee5\u4e0b\u662f\u4ee3\u7801\u7684\u4e3b\u8981\u4f5c\u7528\uff1a</p> <ol> <li> <p>\u5206\u8bcd\uff08Tokenization\uff09\uff1a\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u5b57\u7b26\u7ea7\u5206\u8bcd\u5668\uff0c\u5c06\u6bcf\u4e2a\u8f93\u5165\u6587\u672c\u8f6c\u6362\u4e3a\u5355\u4e2a\u5b57\u7b26\u7684\u5217\u8868\u3002</p> </li> <li> <p>\u6784\u5efa\u8bcd\u6c47\u8868\uff08Vocabulary Building\uff09\uff1a</p> </li> </ol> <p>\u51fd\u6570\u9996\u5148\u68c0\u67e5\u662f\u5426\u5b58\u5728\u6307\u5b9a\u8def\u5f84 <code>config.vocab_path</code> \u4e0b\u7684\u8bcd\u6c47\u8868\u6587\u4ef6\u3002\u5982\u679c\u5b58\u5728\uff0c\u5219\u52a0\u8f7d\u8bcd\u6c47\u8868\uff1b\u5426\u5219\uff0c\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u65b0\u7684\u8bcd\u6c47\u8868\u3002</p> <ol> <li>\u52a0\u8f7d\u6570\u636e\u96c6\uff08Dataset Loading\uff09\uff1a</li> </ol> <p><code>load_dataset</code> \u662f <code>build_dataset_CNN</code> \u5185\u90e8\u7684\u8f85\u52a9\u51fd\u6570\uff0c\u7528\u4e8e\u4ece\u7ed9\u5b9a\u6587\u4ef6\uff08\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\uff09\u52a0\u8f7d\u6570\u636e\u96c6\u3002</p> <ol> <li>\u6570\u636e\u96c6\u62c6\u5206\uff08Dataset Splitting\uff09\uff1a</li> </ol> <p>\u51fd\u6570\u901a\u8fc7\u5728\u76f8\u5e94\u6587\u4ef6\u8def\u5f84\u4e0a\u8c03\u7528 <code>load_dataset</code> \u6765\u52a0\u8f7d\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8fd4\u56de\u3002</p> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def build_dataset_CNN(config):\n    # \u5b9a\u4e49\u5b57\u7b26\u7ea7\u522b\u5206\u8bcd\u5668\n    tokenizer = lambda x: [y for y in x]  \n    # \u68c0\u67e5\u662f\u5426\u5b58\u5728\u8bcd\u6c47\u8868\u6587\u4ef6\uff0c\u5982\u679c\u5b58\u5728\u5219\u52a0\u8f7d\uff0c\u5426\u5219\u6784\u5efa\u65b0\u7684\u8bcd\u6c47\u8868\n    if os.path.exists(config.vocab_path):\n        vocab = pkl.load(open(config.vocab_path, \"rb\"))\n    else:\n        # \u6784\u5efa\u8bcd\u6c47\u8868\n        vocab = build_vocab(config.train_path, tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1)\n        # \u4fdd\u5b58\u8bcd\u6c47\u8868\n        pkl.dump(vocab, open(config.vocab_path, \"wb\"))\n    print(f\"Vocab size: {len(vocab)}\")\n\n    # \u5b9a\u4e49\u52a0\u8f7d\u6570\u636e\u96c6\u7684\u8f85\u52a9\u51fd\u6570\n    def load_dataset(path, pad_size=32):\n        contents = []\n        with open(path, \"r\", encoding=\"UTF-8\") as f:\n            for line in tqdm(f):\n                lin = line.strip()\n                if not lin:\n                    continue\n                content, label = lin.split(\"\\t\")\n                words_line = []\n                token = tokenizer(content)\n                seq_len = len(token)\n\n                # \u586b\u5145\u6216\u622a\u65ad\u5e8f\u5217\u81f3\u6307\u5b9a\u957f\u5ea6\n                if pad_size:\n                    if len(token) &lt; pad_size:\n                        token.extend([PAD] * (pad_size - len(token)))\n                    else:\n                        token = token[:pad_size]\n                        seq_len = pad_size\n\n                # \u5c06\u8bcd\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\n                for word in token:\n                    words_line.append(vocab.get(word, vocab.get(UNK)))\n\n                # \u5c06\u6570\u636e\u6dfb\u52a0\u5230 contents \u5217\u8868\n                contents.append((words_line, int(label), seq_len))\n        return contents  # [([...], 0), ([...], 1), ...]\n\n    # \u52a0\u8f7d\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\n    train = load_dataset(config.train_path, config.pad_size)\n    dev = load_dataset(config.dev_path, config.pad_size)\n    test = load_dataset(config.test_path, config.pad_size)\n\n    return vocab, train, dev, test\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#33","title":"3.3 \u5176\u4ed6\u5de5\u5177\u7c7b\u51fd\u6570","text":"<p>\u5176\u4ed6\u5de5\u5177\u7c7b\u51fd\u6570build_dataset(), build_iterator()\uff0cget_time_dif()\u90fd\u4f4d\u4e8eutils.py\u4e2d\u7684\u72ec\u7acb\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u4e0eBert\u6a21\u578b\u7ae0\u8282\u662f\u4e00\u6837\u7684\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#4","title":"4.\u6a21\u578b\u7c7b","text":""},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#41-teacher","title":"4.1 Teacher\u6a21\u578b","text":"<p>Teacher\u6a21\u578b\u91c7\u7528BERT\uff0c\u63a5\u4e0b\u6765\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8eBERT\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u5305\u542b\u4e86\u76f8\u5173\u7684\u914d\u7f6e\u4fe1\u606f\u3002\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>05-bert_distil/src/models/bert.py\n</code></pre> <p>\u4e3b\u8981\u5185\u5bb9\u5305\u542b\uff1a</p> <p>\u914d\u7f6e\u7c7b <code>Config</code>\uff1a\u548c\u6a21\u578b\u7c7b <code>Model</code>\uff1a</p> <p>\u9996\u5148**\u5bfc\u5165\u5de5\u5177\u5305**\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport os\nfrom transformers import BertModel, BertTokenizer, BertConfig\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#1-config","title":"1 \u5b9e\u73b0Config\u7c7b\u4ee3\u7801","text":"<p>\u914d\u7f6e\u7c7b <code>Config</code>\u4e2d\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li><code>Config</code> \u7c7b\u5305\u542b\u4e86\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u5904\u7406\u7684\u5404\u79cd\u53c2\u6570\u3002</li> <li>\u5b9a\u4e49\u4e86\u6a21\u578b\u540d\u79f0\u3001\u6570\u636e\u96c6\u8def\u5f84\u3001\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u6587\u4ef6\u8def\u5f84\u3001\u7c7b\u522b\u540d\u5355\u7b49\u4fe1\u606f\u3002</li> <li>\u5305\u542b\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u548c\u91cf\u5316\u6a21\u578b\u5b58\u50a8\u7ed3\u679c\u7684\u8def\u5f84\u3002</li> <li>\u914d\u7f6e\u4e86\u8bad\u7ec3\u8bbe\u5907\uff08GPU\u6216CPU\uff09\u3001\u7c7b\u522b\u6570\u3001epoch\u6570\u3001mini-batch\u5927\u5c0f\u3001\u53e5\u5b50\u957f\u5ea6\u7b49\u3002</li> <li>BERT\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8def\u5f84\u3001\u5206\u8bcd\u5668\u3001BERT\u6a21\u578b\u914d\u7f6e\u3001\u9690\u85cf\u5c42\u5927\u5c0f\u7b49\u3002</li> </ul> <pre><code>class Config(object):\n    def __init__(self):\n\"\"\"\n        \u914d\u7f6e\u7c7b\uff0c\u5305\u542b\u6a21\u578b\u548c\u8bad\u7ec3\u6240\u9700\u7684\u5404\u79cd\u53c2\u6570\u3002\n        \"\"\"\n        self.model_name = \"bert\" # \u6a21\u578b\u540d\u79f0\n        self.data_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/data/data1/\" #\u6570\u636e\u96c6\u7684\u6839\u8def\u5f84\n        self.train_path = self.data_path + \"train.txt\"  # \u8bad\u7ec3\u96c6\n        self.dev_path = self.data_path + \"dev.txt\"  # \u9a8c\u8bc1\u96c6\n        self.test_path = self.data_path + \"test.txt\"  # \u6d4b\u8bd5\u96c6\n        self.class_list = [x.strip() for x in open(self.data_path + \"class.txt\").readlines()]  # \u7c7b\u522b\u540d\u5355\n\n        self.save_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/src/saved_dic\" #\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\n        if not os.path.exists(self.save_path):\n            os.mkdir(self.save_path)\n        self.save_path += \"/\" + self.model_name + \".pt\"  # \u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\n\n\n        # \u6a21\u578b\u8bad\u7ec3+\u9884\u6d4b\u7684\u65f6\u5019, \u653e\u5f00\u4e0b\u4e00\u884c\u4ee3\u7801, \u5728GPU\u4e0a\u8fd0\u884c.\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n\n        self.num_classes = len(self.class_list)  # \u7c7b\u522b\u6570\n        self.num_epochs = 2  # epoch\u6570\n        self.batch_size = 128  # mini-batch\u5927\u5c0f\n        self.pad_size = 32  # \u6bcf\u53e5\u8bdd\u5904\u7406\u6210\u7684\u957f\u5ea6(\u77ed\u586b\u957f\u5207)\n        self.learning_rate = 5e-5  # \u5b66\u4e60\u7387\n        self.bert_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/04-bert/data/bert_pretrain\" # \u9884\u8bad\u7ec3BERT\u6a21\u578b\u7684\u8def\u5f84\n        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path) # BERT\u6a21\u578b\u7684\u5206\u8bcd\u5668\n        self.bert_config = BertConfig.from_pretrained(self.bert_path + '/bert_config.json') # BERT\u6a21\u578b\u7684\u914d\u7f6e\n        self.hidden_size = 768 # BERT\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5927\u5c0f\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#2model","title":"2.\u5b9e\u73b0Model\u7c7b\u4ee3\u7801","text":"<p>**\u6a21\u578b\u7c7b <code>Model</code>**\u4e3b\u8981\u5b9e\u73b0\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li><code>Model</code> \u7c7b\u7ee7\u627f\u81ea <code>nn.Module</code>\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eBERT\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\u3002</li> <li>\u5728\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\uff0c\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684BERT\u6a21\u578b\u548c\u914d\u7f6e\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3002</li> <li>\u5728\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\u4e2d\uff0c\u901a\u8fc7BERT\u6a21\u578b\u83b7\u53d6\u53e5\u5b50\u7684\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b</li> </ul> <pre><code>class Model(nn.Module):\n    def __init__(self, config):\n        super(Model, self).__init__()\n        # \u9884\u8bad\u7ec3BERT\u6a21\u578b\n        self.bert = BertModel.from_pretrained(config.bert_path, config=config.bert_config)\n        # \u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u6587\u672c\u5206\u7c7b\n        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n\n    def forward(self, x):\n        # x: \u6a21\u578b\u8f93\u5165\uff0c\u5305\u542b\u53e5\u5b50\u3001\u53e5\u5b50\u957f\u5ea6\u548c\u586b\u5145\u63a9\u7801\u3002\n        context = x[0]  # \u8f93\u5165\u7684\u53e5\u5b50\n        mask = x[2]  # \u5bf9padding\u90e8\u5206\u8fdb\u884cmask\uff0c\u548c\u53e5\u5b50\u4e00\u4e2asize\uff0cpadding\u90e8\u5206\u75280\u8868\u793a\uff0c\u5982\uff1a[1, 1, 1, 1, 0, 0]\n        # _\u662f\u5360\u4f4d\u7b26\uff0c\u63a5\u6536\u6a21\u578b\u7684\u6240\u6709\u8f93\u51fa\uff0c\u800c pooled \u662f\u6c60\u5316\u7684\u7ed3\u679c,\u5c06\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u538b\u7f29\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf\n        _, pooled = self.bert(context, attention_mask=mask, return_dict=False)\n        # \u6a21\u578b\u8f93\u51fa\uff0c\u7528\u4e8e\u6587\u672c\u5206\u7c7b\n        out = self.fc(pooled)\n        return out\n</code></pre> <p>bert.py\u6587\u4ef6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u7075\u6d3b\u7684BERT\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u914d\u7f6e\u7c7b\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u9002\u5e94\u4e0d\u540c\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u8fc7model\u7c7b\u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u7ed3\u6784\u3002</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#42-student","title":"4.2 Student\u6a21\u578b","text":"<p>Student\u6a21\u578b\u91c7\u7528textCNN\uff0c\u63a5\u4e0b\u6765\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8etextCNN\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u5305\u542b\u4e86\u76f8\u5173\u7684\u914d\u7f6e\u4fe1\u606f\u3002\u8be5\u90e8\u5206\u4ee3\u7801\u5728\uff1a</p> <pre><code>05-bert_distil/src/models/textCNN.py\n</code></pre> <p>\u9996\u5148\u770btextCNN\u6a21\u578b\u7684\u67b6\u6784\u56fe:</p> <p></p> <p>\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#1config","title":"1.\u5b9e\u73b0Config\u7c7b\u4ee3\u7801","text":"<p>config\u914d\u7f6e\u7c7b\u7528\u4e8e\u8bbe\u7f6e\u5b58\u50a8\u6a21\u578b\u7684\u5404\u79cd\u53c2\u6570\u548c\u8def\u5f84\u3002\u5305\u62ec\u6570\u636e\u96c6\u7684\u8def\u5f84\u3001\u6a21\u578b\u4fdd\u5b58\u8def\u5f84\u3001\u8bbe\u5907\u9009\u62e9\u3001\u8d85\u53c2\u6570\u7b49\u3002</p> <pre><code>class Config(object):\n    def __init__(self):\n        self.model_name = \"textCNN\"\n        self.data_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/05-bert_distil/data/data/\"\n        self.train_path = self.data_path + \"train.txt\"  # \u8bad\u7ec3\u96c6\n        self.dev_path = self.data_path + \"dev.txt\"  # \u9a8c\u8bc1\u96c6\n        self.test_path = self.data_path + \"test.txt\"  # \u6d4b\u8bd5\u96c6\n        self.class_list = [x.strip() for x in open(self.data_path+\"class.txt\", encoding=\"utf-8\").readlines()]\n        self.vocab_path = self.data_path + \"vocab.pkl\"  # \u8bcd\u8868\n        self.save_path = \"/Users/mac/Desktop/\u6295\u6ee1\u5206\u9879\u76ee/03-code/05-bert_distil/src/saved_dict\"\n        if not os.path.exists(self.save_path):\n            os.mkdir(self.save_path)\n        self.save_path += \"/\" + self.model_name + \".pt\"  # \u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # \u8bbe\u5907\n\n        self.dropout = 0.5  # \u968f\u673a\u5931\u6d3b\n        self.require_improvement = 1000  # \u82e5\u8d85\u8fc71000batch\u6548\u679c\u8fd8\u6ca1\u63d0\u5347\uff0c\u5219\u63d0\u524d\u7ed3\u675f\u8bad\u7ec3\n        self.num_classes = len(self.class_list)  # \u7c7b\u522b\u6570\n        self.n_vocab = 0  # \u8bcd\u8868\u5927\u5c0f\uff0c\u5728\u8fd0\u884c\u65f6\u8d4b\u503c\n        self.num_epochs = 3  # epoch\u6570\n        self.batch_size = 128  # mini-batch\u5927\u5c0f\n        self.pad_size = 32  # \u6bcf\u53e5\u8bdd\u5904\u7406\u6210\u7684\u957f\u5ea6(\u77ed\u586b\u957f\u5207)\n        self.learning_rate = 1e-3  # \u5b66\u4e60\u7387\n        self.embed = 300  # \u5b57\u5411\u91cf\u7ef4\u5ea6\n        self.filter_sizes = (2, 3, 4) # \u5377\u79ef\u6838\u7684\u5927\u5c0f\n        self.num_filters = 256 # \u5377\u79ef\u6838\u7684\u6570\u91cf\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#2model_1","title":"2.\u5b9e\u73b0Model\u7c7b\u4ee3\u7801","text":"<p>TextCNN\uff08\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u6587\u672c\u5206\u7c7b\uff09\u6a21\u578b\u5305\u542b\u8bcd\u5d4c\u5165\u5c42\u3001\u591a\u4e2a\u5377\u79ef\u6838\u5927\u5c0f\u7684\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u3001\u968f\u673a\u5931\u6d3b\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u3002\u5176\u4e2d\uff0c\u5377\u79ef\u5c42\u901a\u8fc7\u4e0d\u540c\u5927\u5c0f\u7684\u5377\u79ef\u6838\u6355\u6349\u4e0d\u540c\u8303\u56f4\u7684\u6587\u672c\u4fe1\u606f\uff0c\u968f\u673a\u5931\u6d3b\u5c42\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u5168\u8fde\u63a5\u5c42\u7528\u4e8e\u8f93\u51fa\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c\u3002\u5305\u542b\u4ee5\u4e0b\u4e09\u4e2a\u65b9\u6cd5\uff1a</p> <ol> <li><code>__init__</code> \u65b9\u6cd5\uff1a \u521d\u59cb\u5316\u6a21\u578b\u3002\u5b83\u5305\u62ec\u8bcd\u5d4c\u5165\u5c42\uff0c\u591a\u4e2a\u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u968f\u673a\u5931\u6d3b\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u3002</li> <li><code>conv_and_pool</code> \u65b9\u6cd5\uff1a \u5b9a\u4e49\u5377\u79ef\u548c\u6c60\u5316\u7684\u64cd\u4f5c\u3002ReLU\u6fc0\u6d3b\u51fd\u6570\u5e94\u7528\u4e8e\u5377\u79ef\u8f93\u51fa\uff0c\u7136\u540e\u901a\u8fc7\u6700\u5927\u6c60\u5316\u5c42\u8fdb\u884c\u6c60\u5316\u3002</li> <li><code>forward</code> \u65b9\u6cd5\uff1a \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u903b\u8f91\u3002\u901a\u8fc7\u8bcd\u5d4c\u5165\u5c42\u5c06\u8f93\u5165\u6587\u672c\u5e8f\u5217\u8f6c\u6362\u4e3a\u5d4c\u5165\u8868\u793a\uff0c\u7136\u540e\u5e94\u7528\u591a\u4e2a\u5377\u79ef\u6838\u5e76\u8fdb\u884c\u6c60\u5316\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u751f\u6210\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>class Model(nn.Module):\n    def __init__(self, config):\n        super(Model, self).__init__()\n        self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1) # \u8bcd\u5d4c\u5165\u5c42\n        self.convs = nn.ModuleList(\n            [nn.Conv2d(1, config.num_filters, (k, config.embed)) for k in config.filter_sizes]\n        )   # \u5377\u79ef\u5c42\u5217\u8868\uff0c\u5305\u542b\u4e0d\u540c\u5377\u79ef\u6838\u5927\u5c0f\u7684\u5377\u79ef\u5c42\n        self.dropout = nn.Dropout(config.dropout)  # \u968f\u673a\u5931\u6d3b\u5c42\n        self.fc = nn.Linear(config.num_filters * len(config.filter_sizes), config.num_classes)   # \u5168\u8fde\u63a5\u5c42\n\n    def conv_and_pool(self, x, conv):\n        # \u5377\u79ef\u548c\u6c60\u5316\u64cd\u4f5c\n        x = F.relu(conv(x)).squeeze(3)\n        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n        return x\n\n    def forward(self, x):\n        # \u524d\u5411\u4f20\u64ad\n        out = self.embedding(x[0])\n        out = out.unsqueeze(1)\n        # \u5bf9\u6bcf\u4e2a\u5377\u79ef\u5c42\u8fdb\u884c\u5377\u79ef\u548c\u6c60\u5316\u64cd\u4f5c\uff0c\u7136\u540e\u62fc\u63a5\u5728\u4e00\u8d77\n        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n        out = self.dropout(out)  # \u968f\u673a\u5931\u6d3b\n        out = self.fc(out)   # \u5168\u8fde\u63a5\u5c42\n        return out\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#5","title":"5.\u7f16\u5199\u8bad\u7ec3\u51fd\u6570,\u6d4b\u8bd5\u51fd\u6570,\u8bc4\u4f30\u51fd\u6570","text":"<p>\u8fd9\u51e0\u4e2a\u51fd\u6570\u5171\u540c\u7f16\u5199\u5728\u4e00\u4e2a\u4ee3\u7801\u6587\u4ef6\u4e2d:</p> <pre><code>05-bert_distil/src/train_eval.py\n</code></pre> <p>\u9996\u5148\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a</p> <pre><code>import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn import metrics\nimport time\nfrom utils import get_time_dif\nfrom transformers.optimization import AdamW\nfrom tqdm import tqdm\nimport math\nimport logging\n</code></pre> <p>\u5728\u5177\u4f53\u5b9e\u73b0\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u8bad\u7ec3\u7684\u67b6\u6784\u56fe\uff1a</p> <p></p> <p>\u4ee5\u4e0b\u662f\u6a21\u578b\u84b8\u998f\u7684\u57fa\u672c\u8bad\u7ec3\u6b65\u9aa4\uff1a</p> <ol> <li>\u51c6\u5907\u6559\u5e08\u6a21\u578b\uff08bert\u5927\u6a21\u578b\uff09\uff1a \u4f7f\u7528\u4e00\u4e2a\u8f83\u5927\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3, \u8fd9\u4e2a\u6a21\u578b\u5728\u4efb\u52a1\u4e0a\u8868\u73b0\u5f88\u597d\u3002</li> <li>\u4f7f\u7528\u6559\u5e08\u6a21\u578b\u751f\u6210\u8f6f\u76ee\u6807\uff1a \u5bf9\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u63a8\u7406\uff0c\u5f97\u5230\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u5206\u5e03\uff08\u8f6f\u76ee\u6807\uff09\u3002\u8fd9\u4e9b\u6982\u7387\u5206\u5e03\u5305\u542b\u4e86\u6a21\u578b\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u4fe1\u606f\u3002</li> <li>\u51c6\u5907\u5b66\u751f\u6a21\u578b\uff08textcnn\u5c0f\u6a21\u578b\uff09\uff1a \u521d\u59cb\u5316\u4e00\u4e2a\u8f83\u5c0f\u7684\u6a21\u578b\uff0c\u8fd9\u662f\u6211\u4eec\u8981\u8bad\u7ec3\u7684\u76ee\u6807\u6a21\u578b\u3002</li> <li>\u4f7f\u7528\u8f6f\u76ee\u6807\u548c\u786c\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3\uff1a \u4f7f\u7528\u539f\u59cb\u7684\u786c\u6807\u7b7e\uff08\u5b9e\u9645\u6807\u7b7e\uff09\u548c\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u8f6f\u76ee\u6807\u6765\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u3002\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a</li> <li>\u786c\u6807\u7b7e\u635f\u5931\uff08\u901a\u5e38\u4e3a\u4ea4\u53c9\u71b5\u635f\u5931\uff09\uff1a \u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\u4e0e\u5b9e\u9645\u6807\u7b7e\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002</li> <li>\u8f6f\u76ee\u6807\u635f\u5931\uff1a \u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\u4e0e\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u8f6f\u76ee\u6807\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8fd9\u901a\u5e38\u4f7f\u7528 KL \u6563\u5ea6\uff08Kullback-Leibler Divergence\uff09\u6765\u5ea6\u91cf\u3002</li> <li>\u8c03\u6574\u6e29\u5ea6\u53c2\u6570\uff1a KL \u6563\u5ea6\u7684\u8ba1\u7b97\u6d89\u53ca\u4e00\u4e2a\u6e29\u5ea6\u53c2\u6570\uff0c\u8be5\u53c2\u6570\u53ef\u4ee5\u8c03\u6574\u8f6f\u76ee\u6807\u7684\u5206\u5e03\u3002\u6e29\u5ea6\u8f83\u9ad8\u4f1a\u4f7f\u5206\u5e03\u66f4\u52a0\u5e73\u6ed1\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u9010\u6e10\u964d\u4f4e\u6e29\u5ea6\u4ee5\u63d0\u9ad8\u84b8\u998f\u6548\u679c\u3002</li> </ol> <p>\u901a\u8fc7\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u5b66\u751f\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u7684\u77e5\u8bc6\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fbe\u5230\u5728\u5c0f\u6a21\u578b\u4e0a\u83b7\u5f97\u7c7b\u4f3c\u5927\u6a21\u578b\u6027\u80fd\u7684\u76ee\u7684\u3002\u6a21\u578b\u84b8\u998f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u7279\u522b\u6709\u7528\uff0c\u4f8b\u5982\u79fb\u52a8\u8bbe\u5907\u6216\u8fb9\u7f18\u8bbe\u5907\u4e0a\u3002</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#51-teacher","title":"5.1 \u83b7\u53d6Teacher\u7f51\u7edc\u8f93\u51fa\u7684\u51fd\u6570","text":"<p>\u4f7f\u7528Bert\u4f5c\u4e3aTeacher\u6a21\u578b, \u9700\u8981\u7528Bert\u5bf9\u5168\u90e8\u8bad\u7ec3\u6570\u636e\u505a\u9884\u6d4b, \u5e76\u5c06\u7ed3\u679c\u9884\u5148\u5b58\u50a8\u8fdb\u4e00\u4e2alist\u4e2d. \u8fd9\u4e9b\u9884\u6d4b\u7ed3\u679c\u5c31\u662fsoft targets, \u672a\u6765\u7ed9Student\u6a21\u578b\u505a\"\u5b66\u4e60\u6807\u7b7e\"\u4f7f\u7528.\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\u6240\u793a\uff1a</p> <ol> <li>\u5c06\u6559\u5e08\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\uff08\u63a8\u65ad\uff09\u6a21\u5f0f\uff0c\u901a\u8fc7 <code>teacher_model.eval()</code> \u5b9e\u73b0\u3002\u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0c\u6a21\u578b\u4e0d\u4f1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u8fd9\u6709\u52a9\u4e8e\u63d0\u9ad8\u63a8\u65ad\u901f\u5ea6\u5e76\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u3002</li> <li>\u521b\u5efa\u4e00\u4e2a\u7a7a\u5217\u8868 <code>teacher_outputs</code>\uff0c\u7528\u4e8e\u5b58\u50a8\u6559\u5e08\u6a21\u578b\u5bf9\u8bad\u7ec3\u96c6\u6bcf\u4e2a\u6279\u6b21\u7684\u8f93\u51fa\u3002</li> <li>\u904d\u5386\u8bad\u7ec3\u96c6\u8fed\u4ee3\u5668 <code>train_iter</code>\uff0c\u5bf9\u6bcf\u4e2a\u6279\u6b21\u7684\u6570\u636e\u8c03\u7528\u6559\u5e08\u6a21\u578b\uff0c\u83b7\u53d6\u6a21\u578b\u7684\u8f93\u51fa\u3002</li> <li>\u5c06\u6bcf\u4e2a\u6279\u6b21\u7684\u8f93\u51fa\u6dfb\u52a0\u5230 <code>teacher_outputs</code> \u5217\u8868\u4e2d\u3002</li> <li>\u6700\u540e\uff0c\u8fd4\u56de\u5305\u542b\u6559\u5e08\u6a21\u578b\u5bf9\u8bad\u7ec3\u96c6\u6240\u6709\u6279\u6b21\u8f93\u51fa\u7684\u7ed3\u679c\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def fetch_teacher_outputs(teacher_model, train_iter):\n    # \u5c06\u6559\u5e08\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\uff08\u63a8\u65ad\uff09\u6a21\u5f0f\uff0c\u907f\u514d\u5728\u83b7\u53d6\u8f93\u51fa\u65f6\u8fdb\u884c\u68af\u5ea6\u8ba1\u7b97\n    teacher_model.eval()\n    # \u7528\u4e8e\u5b58\u50a8\u6559\u5e08\u6a21\u578b\u5bf9\u8bad\u7ec3\u96c6\u7684\u8f93\u51fa\n    teacher_outputs = []\n    # \u7981\u7528\u68af\u5ea6\u8ba1\u7b97\n    with torch.no_grad():\n        # \u904d\u5386\u8bad\u7ec3\u96c6\u6570\u636e\n        for i, (data_batch, labels_batch) in enumerate(train_iter):\n            # \u83b7\u53d6\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\n            outputs = teacher_model(data_batch)\n            # \u5c06\u8f93\u51fa\u6dfb\u52a0\u5230\u5217\u8868\u4e2d\n            teacher_outputs.append(outputs)\n    # \u8fd4\u56de\u6559\u5e08\u6a21\u578b\u5bf9\u8bad\u7ec3\u96c6\u7684\u6240\u6709\u8f93\u51fa\n    return teacher_outputs\n</code></pre> <p>\u9700\u8981\u6ce8\u610f\u7684\u662fTeacher\u6a21\u578b\u548cStudent\u6a21\u578b\u7684DataLoader\u4e0d\u662f\u540c\u4e00\u4e2a, batch_size\u548c\u987a\u5e8f\u90fd\u8981\u4fdd\u6301\u4e00\u81f4, \u624d\u80fd\u4fdd\u8bc1\u540e\u7eed\u7684\u8bad\u7ec3\u6837\u672c\u4e0esoft targets\u5bf9\u9f50!</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#52","title":"5.2 \u635f\u5931\u51fd\u6570","text":"<p>\u901a\u5e38\u91c7\u7528\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570, \u6709\u4e00\u70b9\u9700\u8981\u6ce8\u610f, F.cross_entropy()\u5bf9\u8f93\u5165\u6709\u9650\u5236, \u8981\u6c42label\u5fc5\u987b\u662fone-hot\u683c\u5f0f\u7684. \u4f46Teacher\u7f51\u7edc\u7684\u8f93\u51fasoft targets\u662f\u6982\u7387\u5206\u5e03\u7684\u5f62\u5f0f, \u4e0d\u5339\u914d\uff0c\u56e0\u6b64\u91c7\u7528KL\u6563\u5ea6\u4f5c\u4e3asoft targets\u7684loss, \u6ce8\u610f: Pytorch\u4e2d\u7684KL\u6563\u5ea6\u51fd\u6570\u53ef\u4ee5\u63a5\u6536\u6982\u7387\u5206\u5e03\u5f62\u5f0f\u7684label.\u5305\u542b\u7684\u6b65\u9aa4\u662f\uff1a</p> <ol> <li> <p><code>loss_fn</code> \u662f\u7528\u4e8e\u4e00\u822c\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u9002\u7528\u4e8e\u8bad\u7ec3 BERT \u6a21\u578b\u3002</p> </li> <li> <p><code>criterion</code> \u662f\u5b9a\u4e49 KL \u6563\u5ea6\u635f\u5931\u7684 PyTorch \u635f\u5931\u7c7b\u3002</p> </li> <li> <p><code>loss_fn_kd</code> \u662f\u84b8\u998f\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u84b8\u998f\u8bad\u7ec3\u3002\u5b83\u63a5\u53d7\u4e09\u4e2a\u53c2\u6570\uff1a<code>outputs</code>\uff08\u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\uff09\uff0c<code>labels</code>\uff08\u771f\u5b9e\u6807\u7b7e\uff09\uff0c<code>teacher_outputs</code>\uff08\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\uff09\u3002</p> </li> <li> <p>\u8bbe\u7f6e\u4e24\u4e2a\u8d85\u53c2\u6570\uff1a<code>alpha</code> \u63a7\u5236\u8f6f\u635f\u5931\u548c\u786c\u635f\u5931\u7684\u6743\u91cd\uff0c<code>T</code> \u662f\u6e29\u5ea6\u53c2\u6570\uff0c\u5f71\u54cd\u8f6f\u5316\u7684\u7a0b\u5ea6\u3002</p> </li> <li> <p>\u8ba1\u7b97\u5b66\u751f\u6a21\u578b\uff08Student\uff09\u7684\u8f93\u51fa\u5206\u5e03\u503c\u548c\u6559\u5e08\u6a21\u578b\uff08Teacher\uff09\u7684\u8f93\u51fa\u5206\u5e03\u503c\u3002\u5bf9\u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\u8fdb\u884c log_softmax \u5904\u7406\uff0c\u5bf9\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u8fdb\u884c softmax \u5904\u7406\u3002</p> </li> <li> <p>\u8ba1\u7b97\u8f6f\u635f\u5931\uff0c\u5373\u5b66\u751f\u6a21\u578b\u548c\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u5206\u5e03\u4e4b\u95f4\u7684 KL \u6563\u5ea6\u635f\u5931\u3002</p> </li> <li> <p>\u8ba1\u7b97\u786c\u635f\u5931\uff0c\u5373\u5b66\u751f\u6a21\u578b\u548c\u771f\u5b9e\u6807\u7b7e\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u3002</p> </li> <li> <p>\u8ba1\u7b97\u603b\u635f\u5931\uff0c\u901a\u8fc7\u52a0\u6743\u8f6f\u635f\u5931\u548c\u786c\u635f\u5931\u5f97\u5230\u3002</p> </li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u4ea4\u53c9\u71b5\u635f\u5931: \u8bad\u7ec3bert\u6a21\u578b\ndef loss_fn(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n# KL\u6563\u5ea6\u635f\u5931\uff08\u8981\u6c42student\u8f93\u5165\u4e3alog-probabilities,\u8f6f\u76ee\u6807\u4e3aprobabilities\uff09\ncriterion = nn.KLDivLoss()\n\n# \u5b9a\u4e49\u84b8\u998f\u635f\u5931\u51fd\u6570\ndef loss_fn_kd(outputs, labels, teacher_outputs):\n    # \u8bbe\u7f6e\u4e24\u4e2a\u91cd\u8981\u8d85\u53c2\u6570\n    alpha = 0.8\n    T = 2\n\n    # 1.\u5b66\u751f\u7f51\u7edc\u7684\u5e26\u6709T\u53c2\u6570\u7684log_softmax\u8f93\u51fa\u5206\u5e03\n    output_student = F.log_softmax(outputs / T, dim=1)\n    # 2.\u6559\u5e08\u7f51\u7edc\u7684\u5e26\u6709T\u53c2\u6570\u7684softmax\u8f93\u51fa\u5206\u5e03\n    output_teacher = F.softmax(teacher_outputs / T, dim=1)\n\n    # 3.\u8ba1\u7b97\u8f6f\u76ee\u6807\u635f\u5931,\u4f7f\u7528KLDivLoss(),\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3astudent\u7f51\u7edc\u8f93\u51fa, \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3ateacher\u7f51\u7edc\u8f93\u51fa\n    soft_loss = criterion(output_student, output_teacher)\n\n    # 4.\u786c\u76ee\u6807\u635f\u5931\uff0c\u5b66\u751f\u7f51\u7edc\u7684\u8f93\u51fa\u6982\u7387\u548c\u771f\u5b9e\u6807\u7b7e\u4e4b\u95f4\u7684\u635f\u5931, \u56e0\u4e3a\u771f\u5b9e\u6807\u7b7e\u662fone-hot\u7f16\u7801, \u56e0\u6b64\u76f4\u63a5\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u5373\u53ef\n    hard_loss = F.cross_entropy(outputs, labels)\n\n    # 5.\u8ba1\u7b97\u603b\u635f\u5931\n    # \u539f\u59cb\u8bba\u6587\u4e2d\u5df2\u7ecf\u8bc1\u660e, \u5f15\u5165T\u4f1a\u5bfc\u81f4\u8f6f\u76ee\u6807\u4ea7\u751f\u7684\u68af\u5ea6\u548c\u771f\u5b9e\u76ee\u6807\u4ea7\u751f\u7684\u68af\u5ea6\u76f8\u6bd4\u53ea\u67091/(T*T)\n    # \u56e0\u6b64\u8ba1\u7b97\u5b8c\u8f6f\u76ee\u6807\u7684loss\u503c\u540e\u8981\u4e58\u4ee5T^2.\n    KD_loss = soft_loss * alpha * T * T + hard_loss * (1.0 - alpha)\n    return KD_loss\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#53-teacher","title":"5.3 Teacher\u6a21\u578b\u8bad\u7ec3\u51fd\u6570","text":"<p>\u8be5\u90e8\u5206\u7684\u5185\u5bb9\u4e0eBert\u6a21\u578b\u7ae0\u8282\u7684\u8bad\u7ec3\u51fd\u6570\u662f\u7c7b\u4f3c\u7684\uff0c\u5177\u4f53\u6b65\u9aa4\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ol> <li>\u521d\u59cb\u5316\u8bad\u7ec3\u5f00\u59cb\u65f6\u95f4\uff0c\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\u3002</li> <li>\u5bf9\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u4f18\u5316\uff0c\u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u540c\u65f6\u8bbe\u7f6e\u4e0d\u540c\u53c2\u6570\u7ec4\u7684\u6743\u91cd\u8870\u51cf\u3002</li> <li>\u8fed\u4ee3\u8bad\u7ec3\uff0c\u6bcf\u4e2aepoch\u5185\u904d\u5386\u8bad\u7ec3\u96c6\u3002\u5728\u6bcf\u4e2abatch\u5185\uff0c\u8fdb\u884c\u524d\u5411\u4f20\u64ad\u3001\u635f\u5931\u8ba1\u7b97\u3001\u53cd\u5411\u4f20\u64ad\u548c\u53c2\u6570\u66f4\u65b0\u3002</li> <li>\u6bcf400\u4e2abatch\uff0c\u6253\u5370\u4e00\u6b21\u8bad\u7ec3\u4fe1\u606f\uff0c\u5e76\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u5224\u65ad\u5f53\u524d\u6a21\u578b\u662f\u5426\u662f\u6700\u4f73\u6a21\u578b\uff0c\u5982\u679c\u662f\u5219\u4fdd\u5b58\u3002</li> <li>\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6700\u7ec8\u6d4b\u8bd5\u3002</li> </ol> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def train(config, model, train_iter, dev_iter, test_iter):\n\"\"\"\n    \u53c2\u6570:\n    - config: \u5305\u542b\u8d85\u53c2\u6570\u548c\u8bbe\u7f6e\u7684\u914d\u7f6e\u5bf9\u8c61\u3002\n    - model: \u8981\u8bad\u7ec3\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\n    - train_iter: \u7528\u4e8e\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n    - dev_iter: \u7528\u4e8e\u9a8c\u8bc1\uff08\u5f00\u53d1\uff09\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n    - test_iter: \u7528\u4e8e\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n    \"\"\"\n    # \u8bb0\u5f55\u8bad\u7ec3\u5f00\u59cb\u65f6\u95f4\n    start_time = time.time()\n    # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n    model.train()\n    # \u83b7\u53d6\u6a21\u578b\u53c2\u6570\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    # \u5206\u7ec4\u53c2\u6570\u5e76\u8bbe\u7f6e\u4f18\u5316\u7684\u6743\u91cd\u8870\u51cf\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.01\n        },\n        {\n            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0\n        }]\n    # \u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u8bbe\u7f6e\u5b66\u4e60\u7387\n    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate)\n    # \u8bb0\u5f55\u6700\u4f73\u9a8c\u8bc1\u635f\u5931\n    dev_best_loss = float(\"inf\")\n    # \u904d\u5386\u6bcf\u4e2aepoch\n    for epoch in range(config.num_epochs):\n        total_batch = 0\n        print(\"Epoch [{}/{}]\".format(epoch + 1, config.num_epochs))\n        # \u904d\u5386\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6bcf\u4e2abatch\n        for i, (trains, labels) in enumerate(tqdm(train_iter)):\n            # \u68af\u5ea6\u6e05\u96f6\n            model.zero_grad()\n            # \u524d\u5411\u4f20\u64ad\n            outputs = model(trains)\n            # \u8ba1\u7b97\u635f\u5931\n            loss = loss_fn(outputs, labels)\n            # \u53cd\u5411\u4f20\u64ad\u548c\u4f18\u5316\n            loss.backward()\n            optimizer.step()\n            total_batch += 1\n            # \u6bcf400\u4e2abatch\u6253\u5370\u4e00\u6b21\u8bad\u7ec3\u4fe1\u606f\n            if total_batch % 400 == 0 and total_batch &gt; 0:\n                true = labels.data.cpu()\n                predic = torch.max(outputs.data, 1)[1].cpu()\n                train_acc = metrics.accuracy_score(true, predic)\n                # \u5728\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\n                dev_acc, dev_loss = evaluate(config, model, dev_iter)\n                # \u68c0\u67e5\u5f53\u524d\u6a21\u578b\u662f\u5426\u662f\u6700\u4f73\u6a21\u578b\n                if dev_loss &lt; dev_best_loss:\n                    dev_best_loss = dev_loss\n                    # \u5f53\u6a21\u578b\u6709\u63d0\u5347\u65f6\u4fdd\u5b58\u6a21\u578b\u6743\u91cd\n                    torch.save(model.state_dict(), config.save_path)\n                    improve = \"*\"\n                else:\n                    improve = \"\"\n                time_dif = get_time_dif(start_time)\n                msg = \"Iter: {0:&gt;6},  Train Loss: {1:&gt;5.2},  Train Acc: {2:&gt;6.2%},  Val Loss: {3:&gt;5.2},  Val Acc: {4:&gt;6.2%},  Time: {5} {6}\"\n                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n                # \u5c06\u6a21\u578b\u91cd\u65b0\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n                model.train()\n    # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u6700\u7ec8\u7684\u6a21\u578b\n    test(config, model, test_iter)\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#54","title":"5.4 \u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u51fd\u6570","text":"<p>\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\uff08Knowledge Distillation\uff09\u7684\u65b9\u5f0f\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u51fd\u6570\u5b8c\u6210\u7684\u4efb\u52a1\u5982\u4e0b\u6240\u793a\uff1a</p> <ol> <li>\u521d\u59cb\u5316\u4f18\u5316\u5668\u548c\u5176\u4ed6\u8bad\u7ec3\u53c2\u6570,\u5c06CNN\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\uff0cBERT\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002</li> <li>\u83b7\u53d6BERT\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u3002</li> <li>\u904d\u5386\u6bcf\u4e2aepoch\uff0c\u5bf9CNN\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002\u8ba1\u7b97\u84b8\u998f\u635f\u5931\uff08\u8f6f\u635f\u5931\uff09\u548c\u4ea4\u53c9\u71b5\u635f\u5931\uff08\u786c\u635f\u5931\uff09\u7684\u7ec4\u5408\uff0c\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u548c\u4f18\u5316\u3002</li> <li>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8f93\u51fa\u8bad\u7ec3\u4fe1\u606f\uff0c\u5305\u62ec\u8bad\u7ec3\u635f\u5931\u3001\u51c6\u786e\u7387\u4ee5\u53ca\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u8868\u73b0\u3002\u4fdd\u5b58\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8868\u73b0\u6700\u597d\u7684CNN\u6a21\u578b\u3002</li> <li>\u5728\u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u4f7f\u7528\u6d4b\u8bd5\u96c6\u5bf9\u6700\u7ec8\u7684CNN\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002</li> </ol> <p>\u5177\u4f53\u7684\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def train_kd(cnn_config, bert_model, cnn_model,\n             bert_train_iter, cnn_train_iter, cnn_dev_iter, cnn_test_iter):\n\"\"\"\n    \u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\uff08Knowledge Distillation\uff09\u7684\u65b9\u5f0f\u8bad\u7ec3\u6a21\u578b\u3002\n\n    \u53c2\u6570:\n    - cnn_config: \u5305\u542bCNN\u6a21\u578b\u8d85\u53c2\u6570\u548c\u8bbe\u7f6e\u7684\u914d\u7f6e\u5bf9\u8c61\u3002\n    - bert_model: BERT\u6a21\u578b\u3002\n    - cnn_model: CNN\u6a21\u578b\u3002\n    - bert_train_iter: \u7528\u4e8eBERT\u6a21\u578b\u8bad\u7ec3\u7684\u8fed\u4ee3\u5668\u3002\n    - cnn_train_iter: \u7528\u4e8eCNN\u6a21\u578b\u8bad\u7ec3\u7684\u8fed\u4ee3\u5668\u3002\n    - cnn_dev_iter: \u7528\u4e8eCNN\u6a21\u578b\u9a8c\u8bc1\u7684\u8fed\u4ee3\u5668\u3002\n    - cnn_test_iter: \u7528\u4e8eCNN\u6a21\u578b\u6d4b\u8bd5\u7684\u8fed\u4ee3\u5668\u3002\n    \"\"\"\n    # \u8bb0\u5f55\u8bad\u7ec3\u5f00\u59cb\u65f6\u95f4\n    start_time = time.time()\n    # \u83b7\u53d6CNN\u6a21\u578b\u53c2\u6570\n    param_optimizer = list(cnn_model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.01\n        },\n        {\n            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0\n        }]\n\n    # \u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u8bbe\u7f6e\u5b66\u4e60\u7387\n    optimizer = AdamW(optimizer_grouped_parameters, lr=cnn_config.learning_rate)\n    # \u8bb0\u5f55\u6700\u4f73\u9a8c\u8bc1\u635f\u5931\n    dev_best_loss = float(\"inf\")\n    # \u5c06CNN\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n    cnn_model.train()\n    # \u5c06BERT\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\n    bert_model.eval()\n    # \u83b7\u53d6BERT\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\n    teacher_outputs = fetch_teacher_outputs(bert_model, bert_train_iter)\n    # \u904d\u5386\u6bcf\u4e2aepoch\n    for epoch in range(cnn_config.num_epochs):\n        total_batch = 0\n        print(\"Epoch [{}/{}]\".format(epoch + 1, cnn_config.num_epochs))\n        # \u904d\u5386CNN\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6bcf\u4e2abatch\n        for i, (trains, labels) in enumerate(tqdm(cnn_train_iter)):\n            # \u68af\u5ea6\u6e05\u96f6\n            cnn_model.zero_grad()\n            # \u524d\u5411\u4f20\u64ad\n            outputs = cnn_model(trains)\n            # \u8ba1\u7b97\u84b8\u998f\u635f\u5931\n            loss = loss_fn_kd(outputs, labels, teacher_outputs[i])\n            # \u53cd\u5411\u4f20\u64ad\u548c\u4f18\u5316\n            loss.backward()\n            optimizer.step()\n            total_batch += 1\n            # \u6bcf400\u4e2abatch\u6253\u5370\u4e00\u6b21\u8bad\u7ec3\u4fe1\u606f\n            if total_batch % 400 == 0 and total_batch &gt; 0:\n                true = labels.data.cpu()\n                predic = torch.max(outputs.data, 1)[1].cpu()\n                train_acc = metrics.accuracy_score(true, predic)\n                # \u5728CNN\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\n                dev_acc, dev_loss = evaluate(cnn_config, cnn_model, cnn_dev_iter)\n                # \u68c0\u67e5\u5f53\u524dCNN\u6a21\u578b\u662f\u5426\u662f\u6700\u4f73\u6a21\u578b\n                if dev_loss &lt; dev_best_loss:\n                    dev_best_loss = dev_loss\n                    torch.save(cnn_model.state_dict(), cnn_config.save_path)\n                    improve = \"*\"\n                else:\n                    improve = \"\"\n                time_dif = get_time_dif(start_time)\n                msg = \"Iter: {0:&gt;6},  Train Loss: {1:&gt;5.2},  Train Acc: {2:&gt;6.2%},  Val Loss: {3:&gt;5.2},  Val Acc: {4:&gt;6.2%},  Time: {5} {6}\"\n                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n                # \u5c06CNN\u6a21\u578b\u91cd\u65b0\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n                cnn_model.train()\n    # \u5728CNN\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u6700\u7ec8\u7684CNN\u6a21\u578b\n    test(cnn_config, cnn_model, cnn_test_iter)\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#55","title":"5.5 \u8bc4\u4f30\u51fd\u6570\u548c\u6d4b\u8bd5\u51fd\u6570","text":"<p>\u8bc4\u4f30\u51fd\u6570\u548c\u6d4b\u8bd5\u51fd\u6570\u7684\u5b9e\u73b0\u4e0ebert\u7ae0\u8282\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\u3002</p> <pre><code>def test(config, model, test_iter):\n\"\"\"\n    \u6a21\u578b\u6d4b\u8bd5\u51fd\u6570\uff0c\u7528\u4e8e\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6700\u7ec8\u7684\u6a21\u578b\u6d4b\u8bd5\u3002\n    \u53c2\u6570\uff1a\n    - config: \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\u3002\n    - model: \u5f85\u6d4b\u8bd5\u7684\u6a21\u578b\u3002\n    - test_iter: \u6d4b\u8bd5\u96c6\u7684\u6570\u636e\u8fed\u4ee3\u5668\u3002\n    \"\"\"\n    model.load_state_dict(torch.load(config.save_path,map_location=torch.device(config.device)))\n    model.eval()\n    start_time = time.time()\n    # \u8c03\u7528\u9a8c\u8bc1\u51fd\u6570\u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\n    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=True)\n\n    # \u6253\u5370\u6d4b\u8bd5\u7ed3\u679c\u4fe1\u606f:\u8f93\u51fa\u6d4b\u8bd5\u96c6\u4e0a\u7684\u635f\u5931\u3001\u51c6\u786e\u7387\u3001\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\u7b49\u4fe1\u606f\n    msg = \"Test Loss: {0:&gt;5.2},  Test Acc: {1:&gt;6.2%}\"\n    print(msg.format(test_loss, test_acc))\n    print(\"Precision, Recall and F1-Score...\")\n    print(test_report)\n    print(\"Confusion Matrix...\")\n    print(test_confusion)\n    time_dif = get_time_dif(start_time)\n    print(\"Time usage:\", time_dif)\n\ndef evaluate(config, model, data_iter, test=False):\n\"\"\"\n    \u6a21\u578b\u8bc4\u4f30\u51fd\u6570\u3002\n    \u53c2\u6570\uff1a\n    - config: \u914d\u7f6e\u4fe1\u606f\u5bf9\u8c61\u3002\n    - model: \u5f85\u8bc4\u4f30\u7684\u6a21\u578b\u3002\n    - data_iter: \u6570\u636e\u8fed\u4ee3\u5668\u3002\n    - test: \u662f\u5426\u4e3a\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u3002\n    \"\"\"\n    model.eval()\n    loss_total = 0\n    # \u9884\u6d4b\u7ed3\u679c\n    predict_all = np.array([], dtype=int)\n    # label\u4fe1\u606f\n    labels_all = np.array([], dtype=int)\n    # \u4e0d\u8fdb\u884c\u68af\u5ea6\u8ba1\u7b97\n    with torch.no_grad():\n        # \u904d\u5386\u6570\u636e\u96c6\n        for texts, labels in data_iter:\n            # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\n            outputs = model(texts)\n            # \u635f\u5931\u51fd\u6570\n            loss = F.cross_entropy(outputs, labels)\n            # \u635f\u5931\u548c\n            loss_total += loss\n            # \u83b7\u53d6label\u4fe1\u606f\n            labels = labels.data.cpu().numpy()\n            # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n            predic = torch.max(outputs.data, 1)[1].cpu().numpy()\n            labels_all = np.append(labels_all, labels)\n            predict_all = np.append(predict_all, predic)\n    # \u8ba1\u7b97\u51c6\u786e\u7387\n    acc = metrics.accuracy_score(labels_all, predict_all)\n    if test:\n        # \u5982\u679c\u662f\u6d4b\u8bd5\u96c6\u8bc4\u4f30\uff0c\u8ba1\u7b97\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\n        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=4)\n        confusion = metrics.confusion_matrix(labels_all, predict_all)\n        return acc, loss_total / len(data_iter), report, confusion\n    else:\n        # \u5982\u679c\u662f\u9a8c\u8bc1\u96c6\u8bc4\u4f30\uff0c\u4ec5\u8fd4\u56de\u51c6\u786e\u7387\u548c\u5e73\u5747\u635f\u5931\n        return acc, loss_total / len(data_iter)\n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#6","title":"6.\u7f16\u5199\u8fd0\u884c\u4e3b\u51fd\u6570","text":"<p>\u8be5\u90e8\u5206\u4ee3\u7801\u5728</p> <pre><code>05-bert_distil/src/run.py\n</code></pre> <p>\u4e2d\uff0c\u7528\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08BERT\u6216\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u7684TextCNN\uff09\u3002\u5177\u4f53\u4efb\u52a1\u662f\u901a\u8fc7\u547d\u4ee4\u884c\u53c2\u6570 <code>--task</code> \u6307\u5b9a\u7684\u65b9\u5f0f\u8fdb\u884c\uff0c\u53ef\u4ee5\u9009\u62e9\u8bad\u7ec3BERT\u6a21\u578b\uff08<code>trainbert</code>\uff09\u6216\u8005\u8bad\u7ec3\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u7684TextCNN\u6a21\u578b\uff08<code>train_kd</code>\uff09\u3002</p> <p>\u6267\u884c\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>\u6839\u636e\u547d\u4ee4\u884c\u53c2\u6570\u9009\u62e9\u4efb\u52a1\uff0c\u5982\u679c\u662f<code>trainbert</code>\uff0c\u5219\u52a0\u8f7dBERT\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff1b\u5982\u679c\u662f<code>train_kd</code>\uff0c\u5219\u52a0\u8f7dBERT\u6a21\u578b\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\uff0c\u52a0\u8f7dTextCNN\u6a21\u578b\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\uff0c\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u3002</li> <li>\u521d\u59cb\u5316\u76f8\u5173\u914d\u7f6e\uff0c\u5305\u62ec\u968f\u673a\u79cd\u5b50\u7b49\u3002</li> <li>\u52a0\u8f7d\u6570\u636e\u96c6\uff0c\u5bf9\u4e8e<code>trainbert</code>\u4efb\u52a1\uff0c\u52a0\u8f7dBERT\u6570\u636e\u96c6\uff1b\u5bf9\u4e8e<code>train_kd</code>\u4efb\u52a1\uff0c\u52a0\u8f7dTextCNN\u7684\u6570\u636e\u96c6\u548cBERT\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u3002</li> <li>\u52a0\u8f7d\u6a21\u578b\uff0c\u5bf9\u4e8e<code>trainbert</code>\u4efb\u52a1\uff0c\u52a0\u8f7dBERT\u6a21\u578b\uff1b\u5bf9\u4e8e<code>train_kd</code>\u4efb\u52a1\uff0c\u52a0\u8f7dBERT\u548cTextCNN\u6a21\u578b\u3002</li> <li>\u6267\u884c\u8bad\u7ec3\uff0c\u5bf9\u4e8e<code>trainbert</code>\u4efb\u52a1\uff0c\u8c03\u7528<code>train</code>\u51fd\u6570\uff1b\u5bf9\u4e8e<code>train_kd</code>\u4efb\u52a1\uff0c\u8c03\u7528<code>train_kd</code>\u51fd\u6570\u3002</li> </ol> <p>\u6b64\u811a\u672c\u7684\u8bbe\u8ba1\u4f7f\u5f97\u53ef\u4ee5\u65b9\u4fbf\u5730\u9009\u62e9\u4e0d\u540c\u7684\u4efb\u52a1\uff0c\u5e76\u5728\u4e00\u4e2a\u811a\u672c\u4e2d\u5b8c\u6210\u76f8\u5e94\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002</p> <p>\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>import numpy as np\nimport torch\nfrom train_eval import train_kd, train\nfrom importlib import import_module\nimport argparse\nfrom utils import build_dataset, build_iterator, build_dataset_CNN\n\n# \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\nparser = argparse.ArgumentParser(description=\"Chinese Text Classification\")\nparser.add_argument(\"--task\", type=str, default='train_kd', help=\"choose a task: trainbert, or train_kd\")\nargs = parser.parse_args()\n\nif __name__ == \"__main__\":\n    # \u6839\u636e\u4efb\u52a1\u7c7b\u578b\u9009\u62e9\u4e0d\u540c\u7684\u6a21\u578b\u548c\u914d\u7f6e\n    if args.task == \"trainbert\":\n        model_name = \"bert\"\n        x = import_module(\"models.\" + model_name)  # \u52a8\u6001\u5bfc\u5165\u6a21\u578b\n        config = x.Config()  # \u4f7f\u7528\u6a21\u578b\u7684\u914d\u7f6e\n        # \u521d\u59cb\u5316\n        np.random.seed(1)\n        torch.manual_seed(1)\n        torch.cuda.manual_seed_all(1)\n        torch.backends.cudnn.deterministic = True  # \u4fdd\u8bc1\u6bcf\u6b21\u7ed3\u679c\u4e00\u6837\n        # \u6570\u636e\u96c6\u6784\u5efa\n        print(\"Loading data for Bert Model...\")\n        train_data, dev_data, test_data = build_dataset(config)  # \u6784\u5efa\u6570\u636e\u96c6\n        train_iter = build_iterator(train_data, config)  # \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668\n        dev_iter = build_iterator(dev_data, config)\n        test_iter = build_iterator(test_data, config)\n        # \u6a21\u578b\u5b9e\u4f8b\u5316\u4e0e\u8bad\u7ec3\n        model = x.Model(config).to(config.device)  # \u5b9e\u4f8b\u5316\u6a21\u578b\uff0c\u5e76\u5c06\u6a21\u578b\u79fb\u52a8\u5230\u8bbe\u5907\u4e0a\n        train(config, model, train_iter, dev_iter, test_iter)\n\n    if args.task == \"train_kd\":\n        # \u52a0\u8f7dbert\u6a21\u578b\n        model_name = \"bert\"\n        bert_module = import_module(\"models.\" + model_name)\n        bert_config = bert_module.Config()  # \u4f7f\u7528BERT\u6a21\u578b\u7684\u914d\u7f6e\n        # \u52a0\u8f7dcnn\u6a21\u578b\n        model_name = \"textCNN\"\n        cnn_module = import_module(\"models.\" + model_name)\n        cnn_config = cnn_module.Config()  # \u4f7f\u7528TextCNN\u6a21\u578b\u7684\u914d\u7f6e\n        # \u521d\u59cb\u5316\n        np.random.seed(1)\n        torch.manual_seed(1)\n        torch.cuda.manual_seed_all(1)\n        torch.backends.cudnn.deterministic = True  # \u4fdd\u8bc1\u6bcf\u6b21\u7ed3\u679c\u4e00\u6837\n        # \u6784\u5efabert\u6570\u636e\u96c6\uff0c\u56e0\u4e3a\u53ea\u9700\u8981\u8bad\u7ec3\u7ed3\u679c\u4f5c\u4e3a\u8f6f\u76ee\u6807\uff0c\u8fd9\u91cc\u4e0d\u9700\u8981dev_iter\u548ctest_iter\n        bert_train_data, _, _ = build_dataset(bert_config)\n        bert_train_iter = build_iterator(bert_train_data, bert_config)\n        # \u6784\u5efacnn\u6570\u636e\u96c6\n        vocab, cnn_train_data, cnn_dev_data, cnn_test_data = build_dataset_CNN(cnn_config)\n        cnn_train_iter = build_iterator(cnn_train_data, cnn_config)\n        cnn_dev_iter = build_iterator(cnn_dev_data, cnn_config)\n        cnn_test_iter = build_iterator(cnn_test_data, cnn_config)\n        cnn_config.n_vocab = len(vocab)\n        # \u52a0\u8f7d\u8bad\u7ec3\u597d\u7684teacher\u6a21\u578b\n        bert_model = bert_module.Model(bert_config).to(bert_config.device)\n        # \u52a0\u8f7dstudent\u6a21\u578b\n        cnn_model = cnn_module.Model(cnn_config).to(cnn_config.device)\n        print(\"Teacher and student models loaded, start training\")\n        train_kd(bert_config, cnn_config, bert_model, cnn_model,\n                 bert_train_iter, cnn_train_iter, cnn_dev_iter, cnn_test_iter) \n</code></pre>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#61-teacher","title":"6.1 \u8bad\u7ec3Teacher\u6a21\u578b","text":"<p>\u6267\u884c\u8bad\u7ec3Teacher\u6a21\u578b\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code># \u5c06--task\u4fee\u6539\u4e3atrainbert\uff0c\u76f4\u63a5\u6267\u884crun\u6587\u4ef6\nparser.add_argument(\"--task\", type=str, default='trainbert', help=\"choose a task: trainbert, or train_kd\")\n\n# \u6216\u8005 \u76f4\u63a5\u5728\u547d\u4ee4\u884c\u8fd0\u884c\u8bad\u7ec3Teacher\u6a21\u578b\u7684\u4ee3\u7801\npython run.py --task trainbert\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Loading data for Bert Model...\n180000it [00:37, 4820.80it/s]\n10000it [00:02, 4954.00it/s]\n10000it [00:02, 4952.50it/s]\nEpoch [1/3]\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                            | 200/1407 [02:06&lt;13:26,  1.50it/s]Iter:    200,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 90.86%,  Time: 0:02:26 *\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [04:44&lt;11:46,  1.43it/s]Iter:    400,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.26,  Val Acc: 92.10%,  Time: 0:05:07 *\n 43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 600/1407 [07:26&lt;09:25,  1.43it/s]Iter:    600,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.25,  Val Acc: 92.10%,  Time: 0:07:49 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [10:08&lt;07:06,  1.42it/s]Iter:    800,  Train Loss:  0.15,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 92.85%,  Time: 0:10:31 *\n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 1000/1407 [12:50&lt;04:43,  1.44it/s]Iter:   1000,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 93.00%,  Time: 0:13:10 \nNo optimization for a long time, auto-stopping...\nTest Loss:   0.2,  Test Acc: 93.64%\nPrecision, Recall and F1-Score...\n               precision    recall  f1-score   support\n\n      finance     0.9246    0.9320    0.9283      1000\n       realty     0.9484    0.9370    0.9427      1000\n       stocks     0.8787    0.8980    0.8882      1000\n    education     0.9511    0.9730    0.9619      1000\n      science     0.9236    0.8950    0.9091      1000\n      society     0.9430    0.9270    0.9349      1000\n     politics     0.9267    0.9100    0.9183      1000\n       sports     0.9780    0.9780    0.9780      1000\n         game     0.9514    0.9600    0.9557      1000\nentertainment     0.9390    0.9540    0.9464      1000\n\n     accuracy                         0.9364     10000\n    macro avg     0.9365    0.9364    0.9364     10000\n weighted avg     0.9365    0.9364    0.9364     10000\n\nConfusion Matrix...\n[[932  10  37   2   5   5   7   1   1   0]\n [ 13 937  11   2   4  10   5   5   5   8]\n [ 49  12 898   1  19   1  15   0   2   3]\n [  1   1   0 973   0   8   7   0   1   9]\n [  4   4  28   7 895  10  12   2  27  11]\n [  2   8   4  16   5 927  18   1   5  14]\n [  3   8  34  12   9  19 910   0   0   5]\n [  2   3   2   1   1   1   4 978   1   7]\n [  0   2   4   0  24   1   3   1 960   5]\n [  2   3   4   9   7   1   1  12   7 954]]\nTime usage: 0:00:19\n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 1000/1407 [13:29&lt;05:29,  1.24it/s]\n</code></pre> <ul> <li>\u7ed3\u8bba: Teacher\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u662fTest Acc: 93.64%</li> </ul>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#62-student","title":"6.2 \u8bad\u7ec3Student\u6a21\u578b","text":"<p>\u8bbe\u5b9aConfig\u4e2d\u7684\u91cd\u8981\u53c2\u6570\u5982\u4e0b:</p> <pre><code># \u6a21\u578b\u8fed\u4ee33\u8f6e\nself.num_epochs = 3\n\n# \u5377\u79ef\u6838\u5c3a\u5bf8\u5206\u522b\u90092, 3, 4\nself.filter_sizes = (2, 3, 4)\n\n# \u5377\u79ef\u6838\u7684\u4e2a\u6570512\nself.num_filters = 512\n</code></pre> <p>\u6267\u884crun\u6587\u4ef6</p> <pre><code># \u5c06--task\u4fee\u6539\u4e3atrain_kd\uff0c\u76f4\u63a5\u6267\u884crun\u6587\u4ef6\nparser.add_argument(\"--task\", type=str, default='train_kd', help=\"choose a task: trainbert, or train_kd\")\n# \u6216\u76f4\u63a5\u5728\u547d\u4ee4\u884c\u8fd0\u884c\u8bad\u7ec3Student\u6a21\u578b\u7684\u4ee3\u7801\npython run.py --task train_kd\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>180000it [00:37, 4862.22it/s]\n10000it [00:02, 4988.47it/s]\n10000it [00:02, 4981.50it/s]\nVocab size: 4762\n180000it [00:02, 69598.12it/s]\n10000it [00:00, 82889.25it/s]\n10000it [00:00, 82326.33it/s]\nData loaded, now load teacher model\nTeacher and student models loaded, start training\nEpoch [1/20]\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                            | 199/1407 [00:08&lt;00:50, 23.87it/s]Iter:    200,  Train Loss:  0.29,  Train Acc: 69.53%,  Val Loss:  0.85,  Val Acc: 82.36%,  Time: 0:05:32 *\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:17&lt;00:42, 23.95it/s]Iter:    400,  Train Loss:  0.27,  Train Acc: 73.44%,  Val Loss:  0.81,  Val Acc: 84.00%,  Time: 0:05:40 *\n 43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 598/1407 [00:25&lt;00:33, 23.86it/s]Iter:    600,  Train Loss:  0.24,  Train Acc: 83.59%,  Val Loss:  0.76,  Val Acc: 85.97%,  Time: 0:05:49 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 799/1407 [00:34&lt;00:25, 23.91it/s]Iter:    800,  Train Loss:  0.23,  Train Acc: 83.59%,  Val Loss:  0.76,  Val Acc: 85.49%,  Time: 0:05:58 \n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 1000/1407 [00:43&lt;00:17, 23.89it/s]Iter:   1000,  Train Loss:  0.21,  Train Acc: 84.38%,  Val Loss:  0.74,  Val Acc: 85.94%,  Time: 0:06:07 *\n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1198/1407 [00:52&lt;00:08, 23.80it/s]Iter:   1200,  Train Loss:  0.22,  Train Acc: 85.94%,  Val Loss:  0.72,  Val Acc: 86.92%,  Time: 0:06:16 *\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1399/1407 [01:01&lt;00:00, 23.85it/s]Iter:   1400,  Train Loss:  0.24,  Train Acc: 79.69%,  Val Loss:  0.72,  Val Acc: 86.87%,  Time: 0:06:24 *\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [01:01&lt;00:00, 22.73it/s]\nEpoch [2/20]\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 198/1407 [00:08&lt;00:50, 23.95it/s]Iter:    200,  Train Loss:  0.23,  Train Acc: 85.16%,  Val Loss:   0.7,  Val Acc: 88.34%,  Time: 0:06:33 *\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                  | 399/1407 [00:17&lt;00:42, 23.92it/s]Iter:    400,  Train Loss:  0.23,  Train Acc: 82.81%,  Val Loss:  0.68,  Val Acc: 88.36%,  Time: 0:06:42 *\n 43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 600/1407 [00:25&lt;00:33, 24.06it/s]Iter:    600,  Train Loss:   0.2,  Train Acc: 91.41%,  Val Loss:  0.68,  Val Acc: 88.26%,  Time: 0:06:51 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                              | 798/1407 [00:34&lt;00:25, 23.98it/s]Iter:    800,  Train Loss:  0.21,  Train Acc: 87.50%,  Val Loss:  0.67,  Val Acc: 88.83%,  Time: 0:07:00 *\n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 999/1407 [00:43&lt;00:17, 23.94it/s]Iter:   1000,  Train Loss:  0.19,  Train Acc: 91.41%,  Val Loss:  0.68,  Val Acc: 88.52%,  Time: 0:07:09 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [00:52&lt;00:08, 24.00it/s]Iter:   1200,  Train Loss:   0.2,  Train Acc: 88.28%,  Val Loss:  0.67,  Val Acc: 89.07%,  Time: 0:07:17 *\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1398/1407 [01:00&lt;00:00, 23.81it/s]Iter:   1400,  Train Loss:  0.21,  Train Acc: 86.72%,  Val Loss:  0.67,  Val Acc: 88.87%,  Time: 0:07:26 *\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [01:01&lt;00:00, 22.79it/s]\nEpoch [3/20]\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 198/1407 [00:08&lt;00:50, 23.90it/s]Iter:    200,  Train Loss:  0.22,  Train Acc: 85.16%,  Val Loss:  0.64,  Val Acc: 89.15%,  Time: 0:07:35 *\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                  | 399/1407 [00:17&lt;00:42, 23.98it/s]Iter:    400,  Train Loss:  0.21,  Train Acc: 84.38%,  Val Loss:  0.64,  Val Acc: 89.43%,  Time: 0:07:44 *\n 43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 600/1407 [00:25&lt;00:33, 24.07it/s]Iter:    600,  Train Loss:   0.2,  Train Acc: 91.41%,  Val Loss:  0.65,  Val Acc: 89.54%,  Time: 0:07:53 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                              | 798/1407 [00:34&lt;00:25, 23.95it/s]Iter:    800,  Train Loss:   0.2,  Train Acc: 88.28%,  Val Loss:  0.64,  Val Acc: 89.50%,  Time: 0:08:01 \n 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 999/1407 [00:43&lt;00:17, 23.93it/s]Iter:   1000,  Train Loss:  0.18,  Train Acc: 90.62%,  Val Loss:  0.66,  Val Acc: 89.14%,  Time: 0:08:10 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [00:52&lt;00:08, 24.03it/s]Iter:   1200,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.65,  Val Acc: 89.36%,  Time: 0:08:19 \n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1398/1407 [01:00&lt;00:00, 24.01it/s]Iter:   1400,  Train Loss:   0.2,  Train Acc: 86.72%,  Val Loss:  0.65,  Val Acc: 89.24%,  Time: 0:08:28 \nNo optimization for a long time, auto-stopping...\nTest Loss:  0.62,  Test Acc: 89.89%\nPrecision, Recall and F1-Score...\n               precision    recall  f1-score   support\n\n      finance     0.9297    0.8730    0.9005      1000\n       realty     0.9341    0.9070    0.9203      1000\n       stocks     0.8183    0.8780    0.8471      1000\n    education     0.9564    0.9430    0.9496      1000\n      science     0.8964    0.8220    0.8576      1000\n      society     0.8359    0.9220    0.8768      1000\n     politics     0.8920    0.8590    0.8752      1000\n       sports     0.9436    0.9540    0.9488      1000\n         game     0.9263    0.9050    0.9155      1000\nentertainment     0.8736    0.9260    0.8990      1000\n\n     accuracy                         0.8989     10000\n    macro avg     0.9006    0.8989    0.8991     10000\n weighted avg     0.9006    0.8989    0.8991     10000\n\nConfusion Matrix...\n[[873   9  68   1   6  19  14   3   3   4]\n [ 15 907  13   2   4  18  13   6   2  20]\n [ 38  24 878   1  18  10  23   2   4   2]\n [  1   2   4 943   4  19   6   5   3  13]\n [  2   3  54   5 822  30  26   2  36  20]\n [  1  14   4  19   6 922  14   1   2  17]\n [  8   8  35   9  11  47 859   5   2  16]\n [  1   1   3   1   3  12   3 954   1  21]\n [  0   0   9   2  37   6   5  15 905  21]\n [  0   3   5   3   6  20   0  18  19 926]]\nTime usage: 0:00:00\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1398/1407 [01:01&lt;00:00, 22.65it/s]\n</code></pre> <ul> <li>\u7ed3\u8bba: Student\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u662fTest Acc: 89.89%</li> </ul>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#63-student","title":"6.3 \u8c03\u53c2\u8bad\u7ec3Student\u6a21\u578b","text":"<ul> <li>\u5bf9Config\u7c7b\u4e2d\u7684\u82e5\u5e72\u8d85\u53c2\u6570\u505a\u51fa\u91cd\u8981\u4fee\u6539:</li> </ul> <pre><code># \u6a21\u578b\u8fed\u4ee330\u8f6e\nself.num_epochs = 30\n\n# \u5377\u79ef\u6838\u5c3a\u5bf8\u5206\u522b\u90092, 3, 4, 5\nself.filter_sizes = (2, 3, 4, 5)\n\n# \u5377\u79ef\u6838\u7684\u4e2a\u65701024\nself.num_filters = 1024\n</code></pre> <ul> <li>\u8c03\u53c2\u540e\u518d\u6b21\u8bad\u7ec3Student\u6a21\u578b:</li> </ul> <pre><code># \u5c06--task\u4fee\u6539\u4e3atrain_kd\uff0c\u76f4\u63a5\u6267\u884crun\u6587\u4ef6\nparser.add_argument(\"--task\", type=str, default='train_kd', help=\"choose a task: trainbert, or train_kd\")\n# \u6216\u76f4\u63a5\u5728\u547d\u4ee4\u884c\u8fd0\u884c\u8bad\u7ec3Student\u6a21\u578b\u7684\u4ee3\u7801\npython run.py --task train_kd\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>180000it [00:37, 4830.81it/s]\n10000it [00:02, 4935.57it/s]\n10000it [00:02, 4955.57it/s]\nVocab size: 4762\n180000it [00:02, 69735.78it/s]\n10000it [00:00, 82937.77it/s]\n10000it [00:00, 82402.02it/s]\nData loaded, now load teacher model\nTeacher and student models loaded, start training\nEpoch [1/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                  | 399/1407 [00:39&lt;01:40, 10.06it/s]Iter:    400,  Train Loss:  0.29,  Train Acc: 75.00%,  Val Loss:  0.76,  Val Acc: 84.65%,  Time: 0:06:00 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [01:20&lt;01:00, 10.05it/s]Iter:    800,  Train Loss:  0.24,  Train Acc: 82.81%,  Val Loss:  0.71,  Val Acc: 86.89%,  Time: 0:06:41 *\n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [02:01&lt;00:20, 10.06it/s]Iter:   1200,  Train Loss:  0.23,  Train Acc: 82.81%,  Val Loss:  0.72,  Val Acc: 85.35%,  Time: 0:07:22 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:23&lt;00:00,  9.80it/s]\nEpoch [2/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:39&lt;01:40, 10.06it/s]Iter:    400,  Train Loss:  0.23,  Train Acc: 79.69%,  Val Loss:  0.67,  Val Acc: 88.46%,  Time: 0:08:24 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [01:20&lt;01:00, 10.08it/s]Iter:    800,  Train Loss:  0.21,  Train Acc: 86.72%,  Val Loss:  0.66,  Val Acc: 88.74%,  Time: 0:09:04 *\n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1199/1407 [02:01&lt;00:20, 10.09it/s]Iter:   1200,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.67,  Val Acc: 88.86%,  Time: 0:09:45 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:22&lt;00:00,  9.85it/s]\nEpoch [3/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:39&lt;01:39, 10.13it/s]Iter:    400,  Train Loss:  0.22,  Train Acc: 82.81%,  Val Loss:  0.63,  Val Acc: 89.46%,  Time: 0:10:46 *\n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 799/1407 [01:20&lt;00:59, 10.15it/s]Iter:    800,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.64,  Val Acc: 89.56%,  Time: 0:11:27 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1199/1407 [02:00&lt;00:20, 10.15it/s]Iter:   1200,  Train Loss:  0.19,  Train Acc: 92.19%,  Val Loss:  0.64,  Val Acc: 89.66%,  Time: 0:12:08 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:22&lt;00:00,  9.89it/s]\nEpoch [4/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:39&lt;01:39, 10.17it/s]Iter:    400,  Train Loss:  0.19,  Train Acc: 90.62%,  Val Loss:  0.64,  Val Acc: 89.44%,  Time: 0:13:08 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 799/1407 [01:19&lt;00:59, 10.18it/s]Iter:    800,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:  0.62,  Val Acc: 89.96%,  Time: 0:13:49 *\n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1199/1407 [02:00&lt;00:20, 10.18it/s]Iter:   1200,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.64,  Val Acc: 89.69%,  Time: 0:14:29 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:21&lt;00:00,  9.92it/s]\nEpoch [5/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                  | 399/1407 [00:39&lt;01:38, 10.25it/s]Iter:    400,  Train Loss:   0.2,  Train Acc: 88.28%,  Val Loss:  0.63,  Val Acc: 89.28%,  Time: 0:15:30 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 799/1407 [01:19&lt;00:59, 10.29it/s]Iter:    800,  Train Loss:  0.19,  Train Acc: 90.62%,  Val Loss:  0.64,  Val Acc: 89.60%,  Time: 0:16:10 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1199/1407 [01:59&lt;00:20, 10.29it/s]Iter:   1200,  Train Loss:  0.17,  Train Acc: 96.88%,  Val Loss:  0.64,  Val Acc: 89.51%,  Time: 0:16:50 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:20&lt;00:00, 10.02it/s]\n\n......\n......\n......\n\nEpoch [28/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:38&lt;01:36, 10.40it/s]Iter:    400,  Train Loss:  0.15,  Train Acc: 98.44%,  Val Loss:  0.64,  Val Acc: 90.58%,  Time: 1:08:43 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [01:17&lt;00:58, 10.43it/s]Iter:    800,  Train Loss:  0.16,  Train Acc: 98.44%,  Val Loss:  0.63,  Val Acc: 91.09%,  Time: 1:09:22 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [01:57&lt;00:19, 10.43it/s]Iter:   1200,  Train Loss:  0.15,  Train Acc: 96.88%,  Val Loss:  0.64,  Val Acc: 90.55%,  Time: 1:10:02 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:18&lt;00:00, 10.17it/s]\nEpoch [29/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:38&lt;01:36, 10.41it/s]Iter:    400,  Train Loss:  0.15,  Train Acc: 97.66%,  Val Loss:  0.64,  Val Acc: 90.78%,  Time: 1:11:01 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [01:17&lt;00:58, 10.42it/s]Iter:    800,  Train Loss:  0.16,  Train Acc: 98.44%,  Val Loss:  0.63,  Val Acc: 90.58%,  Time: 1:11:40 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [01:57&lt;00:19, 10.41it/s]Iter:   1200,  Train Loss:  0.15,  Train Acc: 97.66%,  Val Loss:  0.62,  Val Acc: 90.72%,  Time: 1:12:20 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:18&lt;00:00, 10.17it/s]\nEpoch [30/30]\n 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                  | 400/1407 [00:38&lt;01:36, 10.40it/s]Iter:    400,  Train Loss:  0.16,  Train Acc: 98.44%,  Val Loss:  0.65,  Val Acc: 90.66%,  Time: 1:13:19 \n 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 800/1407 [01:17&lt;00:58, 10.43it/s]Iter:    800,  Train Loss:  0.15,  Train Acc: 98.44%,  Val Loss:  0.63,  Val Acc: 90.79%,  Time: 1:13:59 \n 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 1200/1407 [01:57&lt;00:19, 10.40it/s]Iter:   1200,  Train Loss:  0.15,  Train Acc: 99.22%,  Val Loss:  0.64,  Val Acc: 90.65%,  Time: 1:14:38 \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1407/1407 [02:18&lt;00:00, 10.17it/s]\nTest Loss:   0.6,  Test Acc: 91.25%\nPrecision, Recall and F1-Score...\n               precision    recall  f1-score   support\n\n      finance     0.9105    0.9050    0.9077      1000\n       realty     0.9311    0.9320    0.9315      1000\n       stocks     0.8912    0.8440    0.8670      1000\n    education     0.9532    0.9570    0.9551      1000\n      science     0.8836    0.8730    0.8783      1000\n      society     0.8306    0.9270    0.8762      1000\n     politics     0.9041    0.8770    0.8904      1000\n       sports     0.9733    0.9470    0.9600      1000\n         game     0.9467    0.9240    0.9352      1000\nentertainment     0.9108    0.9390    0.9247      1000\n\n     accuracy                         0.9125     10000\n    macro avg     0.9135    0.9125    0.9126     10000\n weighted avg     0.9135    0.9125    0.9126     10000\n\nConfusion Matrix...\n[[905  10  38   4   5  19  11   3   0   5]\n [ 13 932  13   2   3  17   6   3   4   7]\n [ 54  23 844   1  32   6  33   1   4   2]\n [  2   2   1 957   4  15   6   1   3   9]\n [  3   5  24   5 873  32  17   3  25  13]\n [  2  15   3  18   5 927  12   0   1  17]\n [ 12  10  16  10  14  48 877   2   3   8]\n [  2   0   3   1   2  21   4 947   1  19]\n [  0   0   3   3  43   8   2   5 924  12]\n [  1   4   2   3   7  23   2   8  11 939]]\nTime usage: 0:00:01\n</code></pre> <p>\u7ed3\u8bba: \u8c03\u53c2\u540e\u7684Student\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u662fTest Acc: 91.25%</p> <p>\u5b8c\u6210\u77e5\u8bc6\u84b8\u998f\u540e, \u6211\u4eec\u83b7\u5f97\u4e86\u4e24\u4e2a\u6a21\u578b, Teacher\u6a21\u578b\u548cStudent\u6a21\u578b\uff1a</p> <p></p> <p>\u4ece\u4e0a\u8ff0\u7ed3\u679c\u4e2d\u53ef\u4ee5\u770b\u51fa:</p> <p>Teacher\u6a21\u578b\u5927\u5c0f\u4e3a409.2MB, Student\u6a21\u578b\u5927\u5c0f\u4e3a11.3MB\u548c23.1MB.</p> <p>Teacher\u6a21\u578b\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u4e3a93.64%, Student\u6a21\u578b\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u4e3a89.89%\u548c91.25%.</p>"},{"location":"09-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%AE%9E%E8%B7%B5.html#7","title":"7.\u7ed3\u8bba","text":"<p>\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u540e\u6a21\u578b\u5927\u5c0f\u548c\u51c6\u786e\u7387\u7684\u53d8\u5316\uff1a</p> <p>1\u3001\u6a21\u578b\u5927\u5c0f\u660e\u663e\u51cf\u5c11.</p> <ul> <li>BERT\u6a21\u578b409.2MB, \u6700\u4f18\u7684textCNN\u6a21\u578b23.1MB.</li> <li>\u6a21\u578b\u5927\u5c0f\u538b\u7f29\u4e3a\u539f\u6765\u76845.65%, \u7f29\u5c0f\u4e8617.7\u500d.</li> </ul> <p>2\u3001\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u7387\u4ec5\u67092.39%\u7684\u4e0b\u964d.</p> <ul> <li> <p>BERT\u6a21\u578b\u51c6\u786e\u738793.64%</p> </li> <li> <p>textCNN\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u540e30\u4e2aepochs\u51c6\u786e\u738791.25%</p> </li> </ul>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html","title":"\u6a21\u578b\u526a\u679d\u7684\u6982\u5ff5\u548c\u7406\u8bba","text":"<p>\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u7406\u89e3\u4ec0\u4e48\u662f\u6a21\u578b\u526a\u679d.</li> <li>\u638c\u63e1\u6a21\u578b\u526a\u679d\u7684\u57fa\u672c\u64cd\u4f5c.</li> </ul> <p></p>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html#1","title":"1.\u4ec0\u4e48\u662f\u6a21\u578b\u7684\u526a\u679d","text":"<ul> <li>\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u62e5\u6709\u5e9e\u5927\u7684\u53c2\u6570\u91cf, \u624d\u80fd\u8fbe\u5230SOTA\u7684\u6548\u679c. \u4f46\u662f\u6211\u4eec\u53c2\u8003\u751f\u7269\u7684\u795e\u7ecf\u7f51\u7edc, \u53d1\u73b0\u5374\u662f\u4f9d\u9760\u5927\u91cf\u7a00\u758f\u7684\u8fde\u63a5\u6765\u5b8c\u6210\u590d\u6742\u7684\u610f\u8bc6\u6d3b\u52a8. </li> </ul> <ul> <li>\u4eff\u7167\u751f\u7269\u7684\u7a00\u758f\u795e\u7ecf\u7f51\u7edc, \u5c06\u5927\u578b\u7f51\u7edc\u4e2d\u7684\u7a20\u5bc6\u8fde\u63a5\u53d8\u6210\u7a00\u758f\u7684\u8fde\u63a5, \u5e76\u540c\u6837\u8fbe\u5230SOTA\u7684\u6548\u679c, \u5c31\u662f\u6a21\u578b\u526a\u679d\u7684\u539f\u52a8\u529b.</li> </ul> <ul> <li>Pytorch\u4e2d\u5bf9\u6a21\u578b\u526a\u679d\u7684\u652f\u6301\u5728torch.nn.utils.prune\u6a21\u5757\u4e2d, \u5206\u4ee5\u4e0b\u51e0\u79cd\u526a\u679d\u65b9\u5f0f:<ul> <li>\u5bf9\u7279\u5b9a\u7f51\u7edc\u6a21\u5757\u7684\u526a\u679d(Pruning Model).</li> <li>\u591a\u53c2\u6570\u6a21\u5757\u7684\u526a\u679d(Pruning multiple parameters).</li> <li>\u5168\u5c40\u526a\u679d(GLobal pruning).</li> <li>\u7528\u6237\u81ea\u5b9a\u4e49\u526a\u679d(Custom pruning).</li> </ul> </li> </ul> <ul> <li>\u6ce8\u610f: \u4fdd\u8bc1Pytorch\u7684\u7248\u672c\u57281.4.0\u4ee5\u4e0a, \u652f\u6301\u526a\u679d\u64cd\u4f5c.</li> </ul>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html#2pruning-model","title":"2.\u5bf9\u7279\u5b9a\u7f51\u7edc\u6a21\u5757\u7684\u526a\u679d(Pruning Model).","text":"<ul> <li>\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305:</li> </ul> <pre><code>import torch\nfrom torch import nn\nimport torch.nn.utils.prune as prune\nimport torch.nn.functional as F\n</code></pre> <ul> <li>\u521b\u5efa\u4e00\u4e2a\u7f51\u7edc, \u6211\u4eec\u4ee5\u7ecf\u5178\u7684LeNet\u6765\u793a\u4f8b:</li> </ul> <pre><code>device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        # 1: \u56fe\u50cf\u7684\u8f93\u5165\u901a\u9053(1\u662f\u9ed1\u767d\u56fe\u50cf), 6: \u8f93\u51fa\u901a\u9053, 3x3: \u5377\u79ef\u6838\u7684\u5c3a\u5bf8\n        self.conv1 = nn.Conv2d(1, 6, 3)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 \u662f\u7ecf\u5386\u5377\u79ef\u64cd\u4f5c\u540e\u7684\u56fe\u7247\u5c3a\u5bf8\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, int(x.nelement() / x.shape[0]))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nmodel = LeNet().to(device=device)\n</code></pre> <ul> <li>\u8c03\u7528:</li> </ul> <pre><code>module = model.conv1\nprint(list(module.named_parameters()))\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>[('weight', Parameter containing:\ntensor([[[[ 0.0853, -0.0203, -0.0784],\n          [ 0.3327, -0.0904, -0.0374],\n          [-0.0037, -0.2629, -0.2536]]],\n\n\n        [[[ 0.1313,  0.0249,  0.2735],\n          [ 0.0630,  0.0625, -0.0468],\n          [ 0.3328,  0.3249, -0.2640]]],\n\n\n        [[[ 0.1931, -0.2246,  0.0102],\n          [ 0.3319,  0.1740, -0.0799],\n          [-0.0195, -0.1295, -0.0964]]],\n\n\n        [[[ 0.3005,  0.2704,  0.3162],\n          [-0.2560,  0.0295,  0.2605],\n          [-0.1056, -0.0730,  0.0436]]],\n\n\n        [[[-0.3205,  0.1927, -0.0761],\n          [ 0.0142, -0.0562, -0.3087],\n          [ 0.1202,  0.1119, -0.1336]]],\n\n\n        [[[ 0.0568,  0.1142,  0.3079],\n          [ 0.2000, -0.1661, -0.2935],\n          [-0.1652, -0.2606, -0.0559]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\ntensor([ 0.1085, -0.1044,  0.1366,  0.3240, -0.1522,  0.1630], device='cuda:0',\n       requires_grad=True))]\n</code></pre> <ul> <li>\u518d\u6253\u5370\u4e00\u4e2a\u7279\u6b8a\u7684\u5c5e\u6027\u5f20\u91cf</li> </ul> <pre><code>print(list(module.named_buffers()))\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c</li> </ul> <pre><code># \u8fd9\u91cc\u9762\u6253\u5370\u51fa\u4e00\u4e2a\u7a7a\u5217\u8868, \u81f3\u4e8e\u8fd9\u4e2a\u7a7a\u5217\u8868\u4ee3\u8868\u4ec0\u4e48\u542b\u4e49? \u526a\u679d\u64cd\u4f5c\u540e\u540c\u5b66\u4eec\u5c31\u660e\u767d\u4e86!\n[]\n</code></pre> <ul> <li>\u76f4\u63a5\u8c03\u7528prune\u51fd\u6570\u5bf9\u6a21\u578b\u8fdb\u884c\u526a\u679d\u64cd\u4f5c:</li> </ul> <pre><code># \u7b2c\u4e00\u4e2a\u53c2\u6570: module, \u4ee3\u8868\u8981\u8fdb\u884c\u526a\u679d\u7684\u7279\u5b9a\u6a21\u5757, \u4e4b\u524d\u6211\u4eec\u5df2\u7ecf\u5236\u5b9a\u4e86module=model.conv1,\n#             \u8bf4\u660e\u8fd9\u91cc\u8981\u5bf9\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u6267\u884c\u526a\u679d.\n# \u7b2c\u4e8c\u4e2a\u53c2\u6570: name, \u6307\u5b9a\u8981\u5bf9\u9009\u4e2d\u7684\u6a21\u5757\u4e2d\u7684\u54ea\u4e9b\u53c2\u6570\u6267\u884c\u526a\u679d.\n#             \u8fd9\u91cc\u8bbe\u5b9a\u4e3aname=\"weight\", \u610f\u5473\u7740\u5bf9\u8fde\u63a5\u7f51\u7edc\u4e2d\u7684weight\u526a\u679d, \u800c\u4e0d\u5bf9bias\u526a\u679d.\n# \u7b2c\u4e09\u4e2a\u53c2\u6570: amount, \u6307\u5b9a\u8981\u5bf9\u6a21\u578b\u4e2d\u591a\u5927\u6bd4\u4f8b\u7684\u53c2\u6570\u6267\u884c\u526a\u679d.\n#             amount\u662f\u4e00\u4e2a\u4ecb\u4e8e0.0-1.0\u7684float\u6570\u503c, \u6216\u8005\u4e00\u4e2a\u6b63\u6574\u6570\u6307\u5b9a\u526a\u88c1\u6389\u591a\u5c11\u6761\u8fde\u63a5\u8fb9.\n\nprune.random_unstructured(module, name=\"weight\", amount=0.3)\n</code></pre> <ul> <li>\u8c03\u7528:</li> </ul> <pre><code>print(list(module.named_parameters()))\nprint(list(module.named_buffers()))\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>[('bias', Parameter containing:\ntensor([ 0.1861,  0.2483, -0.3235,  0.0667,  0.0790,  0.1807], device='cuda:0',\n       requires_grad=True)), ('weight_orig', Parameter containing:\ntensor([[[[-0.1544, -0.3045,  0.1339],\n          [ 0.2605, -0.1201,  0.3060],\n          [-0.2502, -0.0023, -0.0362]]],\n\n\n        [[[ 0.3147, -0.1034, -0.1772],\n          [-0.2250, -0.1071,  0.2489],\n          [ 0.2741, -0.1926, -0.2046]]],\n\n\n        [[[-0.1022, -0.2210, -0.1349],\n          [-0.2938,  0.0679,  0.2485],\n          [ 0.1108, -0.0564, -0.3328]]],\n\n\n        [[[-0.0464,  0.0138,  0.0283],\n          [-0.3205,  0.0184,  0.0521],\n          [ 0.2219, -0.2403, -0.2881]]],\n\n\n        [[[ 0.3320, -0.0684, -0.1715],\n          [-0.0381,  0.1819,  0.1796],\n          [-0.3321, -0.2684, -0.0477]]],\n\n\n        [[[-0.1638, -0.0969,  0.0077],\n          [ 0.0906,  0.2051,  0.2174],\n          [-0.2174,  0.1875, -0.2978]]]], device='cuda:0', requires_grad=True))]\n[('weight_mask', tensor([[[[1., 0., 1.],\n          [1., 0., 1.],\n          [1., 0., 1.]]],\n\n\n        [[[0., 0., 0.],\n          [0., 1., 1.],\n          [0., 0., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [0., 1., 1.],\n          [1., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 1., 1.],\n          [1., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 0., 1.],\n          [1., 1., 0.]]],\n\n\n        [[[1., 0., 1.],\n          [0., 0., 1.],\n          [1., 1., 0.]]]], device='cuda:0'))]\n</code></pre> <ul> <li>\u7ed3\u8bba: \u6a21\u578b\u7ecf\u5386\u526a\u679d\u64cd\u4f5c\u540e, \u539f\u59cb\u7684\u6743\u91cd\u77e9\u9635weight\u53c2\u6570\u4e0d\u89c1\u4e86, \u53d8\u6210\u4e86weight_orig. \u5e76\u4e14\u521a\u521a\u6253\u5370\u4e3a\u7a7a\u5217\u8868\u7684module.named_buffers(), \u6b64\u65f6\u62e5\u6709\u4e86\u4e00\u4e2aweight_mask\u53c2\u6570.</li> </ul> <ul> <li>\u8fd9\u65f6\u6253\u5370module.weight\u5c5e\u6027\u503c, \u770b\u770b\u6709\u4ec0\u4e48\u542f\u53d1?</li> </ul> <pre><code>print(module.weight)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>tensor([[[[-0.1544, -0.0000,  0.1339],\n          [ 0.2605, -0.0000,  0.3060],\n          [-0.2502, -0.0000, -0.0362]]],\n\n\n        [[[ 0.0000, -0.0000, -0.0000],\n          [-0.0000, -0.1071,  0.2489],\n          [ 0.0000, -0.0000, -0.2046]]],\n\n\n        [[[-0.1022, -0.2210, -0.1349],\n          [-0.0000,  0.0679,  0.2485],\n          [ 0.1108, -0.0564, -0.3328]]],\n\n\n        [[[-0.0464,  0.0138,  0.0283],\n          [-0.3205,  0.0184,  0.0521],\n          [ 0.2219, -0.2403, -0.2881]]],\n\n\n        [[[ 0.3320, -0.0684, -0.1715],\n          [-0.0381,  0.0000,  0.1796],\n          [-0.3321, -0.2684, -0.0000]]],\n\n\n        [[[-0.1638, -0.0000,  0.0077],\n          [ 0.0000,  0.0000,  0.2174],\n          [-0.2174,  0.1875, -0.0000]]]], device='cuda:0',\n       grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <ul> <li>\u7ed3\u8bba: \u7ecf\u8fc7\u526a\u679d\u64cd\u4f5c\u540e\u7684\u6a21\u578b, \u539f\u59cb\u7684\u53c2\u6570\u5b58\u653e\u5728\u4e86weight_orig\u4e2d, \u5bf9\u5e94\u7684\u526a\u679d\u77e9\u9635\u5b58\u653e\u5728weight_mask\u4e2d, \u800c\u5c06weight_mask\u89c6\u4f5c\u63a9\u7801\u5f20\u91cf, \u518d\u548cweight_orig\u76f8\u4e58\u7684\u7ed3\u679c\u5c31\u5b58\u653e\u5728\u4e86weight\u4e2d.</li> </ul> <ul> <li>\u6ce8\u610f: \u526a\u679d\u64cd\u4f5c\u540e\u7684weight\u5df2\u7ecf\u4e0d\u518d\u662fmodule\u7684\u53c2\u6570(parameter), \u800c\u53ea\u662fmodule\u7684\u4e00\u4e2a\u5c5e\u6027(attribute).</li> </ul> <p>\u6211\u4eec\u53ef\u4ee5\u5bf9\u6a21\u578b\u7684\u4efb\u610f\u5b50\u7ed3\u6784\u8fdb\u884c\u526a\u679d\u64cd\u4f5c, \u9664\u4e86\u5728weight\u4e0a\u9762\u526a\u679d, \u8fd8\u53ef\u4ee5\u5bf9bias\u8fdb\u884c\u526a\u679d.</p> <pre><code># \u7b2c\u4e00\u4e2a\u53c2\u6570: module, \u4ee3\u8868\u526a\u679d\u7684\u5bf9\u8c61, \u6b64\u5904\u4ee3\u8868LeNet\u4e2d\u7684conv1\n# \u7b2c\u4e8c\u4e2a\u53c2\u6570: name, \u4ee3\u8868\u526a\u679d\u5bf9\u8c61\u4e2d\u7684\u5177\u4f53\u53c2\u6570, \u6b64\u5904\u4ee3\u8868\u504f\u7f6e\u91cf\n# \u7b2c\u4e09\u4e2a\u53c2\u6570: amount, \u4ee3\u8868\u526a\u679d\u7684\u6570\u91cf, \u53ef\u4ee5\u8bbe\u7f6e\u4e3a0.0-1.0\u4e4b\u95f4\u8868\u793a\u6bd4\u4f8b, \u4e5f\u53ef\u4ee5\u7528\u6b63\u6574\u6570\u8868\u793a\u526a\u679d\u7684\u53c2\u6570\u7edd\u5bf9\u6570\u91cf\nprune.l1_unstructured(module, name=\"bias\", amount=3)\n\n# \u518d\u6b21\u6253\u5370\u6a21\u578b\u53c2\u6570\nprint(list(module.named_parameters()))\nprint('*'*50)\nprint(list(module.named_buffers()))\nprint('*'*50)\nprint(module.bias)\nprint('*'*50)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c</li> </ul> <pre><code>[('weight_orig', Parameter containing:\ntensor([[[[-0.0159, -0.3175, -0.0816],\n          [ 0.3144, -0.1534, -0.0924],\n          [-0.2885, -0.1054, -0.1872]]],\n\n\n        [[[ 0.0835, -0.1258, -0.2760],\n          [-0.3174,  0.0669, -0.1867],\n          [-0.0381,  0.1156,  0.0078]]],\n\n\n        [[[ 0.1416, -0.2907, -0.0249],\n          [ 0.1018,  0.1757, -0.0326],\n          [ 0.2736, -0.1980, -0.1162]]],\n\n\n        [[[-0.1835,  0.1600,  0.3178],\n          [ 0.0579, -0.0647, -0.1039],\n          [-0.0160, -0.0715,  0.2746]]],\n\n\n        [[[-0.2314, -0.1759, -0.1820],\n          [-0.0594,  0.2355, -0.2087],\n          [ 0.0216,  0.0066, -0.0624]]],\n\n\n        [[[-0.2772,  0.1479, -0.0983],\n          [-0.3307, -0.2360, -0.0596],\n          [ 0.2785,  0.0648,  0.2869]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\ntensor([-0.1924, -0.1420, -0.0235,  0.0325,  0.0188,  0.0120], device='cuda:0',\n       requires_grad=True))]\n**************************************************\n[('weight_mask', tensor([[[[0., 0., 0.],\n          [1., 1., 1.],\n          [1., 0., 1.]]],\n\n\n        [[[1., 0., 1.],\n          [1., 0., 1.],\n          [1., 0., 1.]]],\n\n\n        [[[1., 1., 0.],\n          [1., 1., 1.],\n          [1., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 0., 0.],\n          [0., 1., 0.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 1., 1.],\n          [0., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [0., 0., 1.],\n          [1., 1., 0.]]]], device='cuda:0')), ('bias_mask', tensor([1., 1., 0., 1., 0., 0.], device='cuda:0'))]\n**************************************************\ntensor([-0.1924, -0.1420, -0.0000,  0.0325,  0.0000,  0.0000], device='cuda:0',\n       grad_fn=&lt;MulBackward0&gt;)\n**************************************************\n</code></pre> <ul> <li>\u7ed3\u8bba: \u5728module\u7684\u4e0d\u540c\u53c2\u6570\u96c6\u5408\u4e0a\u5e94\u7528\u4e0d\u540c\u7684\u526a\u679d\u7b56\u7565, \u6211\u4eec\u53d1\u73b0\u6a21\u578b\u53c2\u6570\u4e2d\u4e0d\u4ec5\u4ec5\u6709\u4e86weight_orig, \u4e5f\u6709\u4e86bias_orig. \u5728\u8d77\u5230\u63a9\u7801\u5f20\u91cf\u4f5c\u7528\u7684named_buffers\u4e2d, \u4e5f\u540c\u65f6\u51fa\u73b0\u4e86weight_mask\u548cbias_mask. </li> </ul> <ul> <li>\u5e8f\u5217\u5316\u4e00\u4e2a\u526a\u679d\u6a21\u578b(Serializing a pruned model):</li> </ul> <pre><code># \u5bf9\u4e8e\u4e00\u4e2a\u6a21\u578b\u6765\u8bf4, \u4e0d\u7ba1\u662f\u5b83\u539f\u59cb\u7684\u53c2\u6570, \u62e5\u6709\u7684\u5c5e\u6027\u503c, \u8fd8\u662f\u526a\u679d\u7684mask buffers\u53c2\u6570\n# \u5168\u90e8\u90fd\u5b58\u50a8\u5728\u6a21\u578b\u7684\u72b6\u6001\u5b57\u5178\u4e2d, \u5373state_dict()\u4e2d.\n# \u5c06\u6a21\u578b\u521d\u59cb\u7684\u72b6\u6001\u5b57\u5178\u6253\u5370\u51fa\u6765\nprint(model.state_dict().keys())\nprint('*'*50)\n\n# \u5bf9\u6a21\u578b\u8fdb\u884c\u526a\u679d\u64cd\u4f5c, \u5206\u522b\u5728weight\u548cbias\u4e0a\u526a\u679d\nmodule = model.conv1\nprune.random_unstructured(module, name=\"weight\", amount=0.3)\nprune.l1_unstructured(module, name=\"bias\", amount=3)\n\n# \u518d\u5c06\u526a\u679d\u540e\u7684\u6a21\u578b\u7684\u72b6\u6001\u5b57\u5178\u6253\u5370\u51fa\u6765\nprint(model.state_dict().keys())\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n**************************************************\nodict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n</code></pre> <ul> <li>\u5173\u952e\u4e00\u6b65: \u5bf9\u6a21\u578b\u6267\u884c\u526a\u679dremove\u64cd\u4f5c.<ul> <li>\u901a\u8fc7module\u4e2d\u7684\u53c2\u6570weight_orig\u548cweight_mask\u8fdb\u884c\u526a\u679d, \u672c\u8d28\u4e0a\u5c5e\u4e8e\u7f6e\u96f6\u906e\u63a9, \u8ba9\u6743\u91cd\u8fde\u63a5\u5931\u6548.</li> <li>\u8fd9\u4e2aremove\u662f\u65e0\u6cd5undo\u7684, \u4e5f\u5c31\u662f\u8bf4\u4e00\u65e6\u6267\u884c\u5c31\u662f\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u6c38\u4e45\u6539\u53d8.</li> </ul> </li> </ul> <ul> <li>\u6267\u884cremove\u64cd\u4f5c\u7684\u6f14\u793a\u4ee3\u7801:</li> </ul> <pre><code># \u6253\u5370\u526a\u679d\u540e\u7684\u6a21\u578b\u53c2\u6570\nprint(list(module.named_parameters()))\nprint('*'*50)\n\n# \u6253\u5370\u526a\u679d\u540e\u7684\u6a21\u578bmask buffers\u53c2\u6570\nprint(list(module.named_buffers()))\nprint('*'*50)\n\n# \u6253\u5370\u526a\u679d\u540e\u7684\u6a21\u578bweight\u5c5e\u6027\u503c\nprint(module.weight)\nprint('*'*50)\n\n# \u6267\u884c\u526a\u679d\u6c38\u4e45\u5316\u64cd\u4f5cremove\nprune.remove(module, 'weight')\nprint('*'*50)\n\n# remove\u540e\u518d\u6b21\u6253\u5370\u6a21\u578b\u53c2\u6570\nprint(list(module.named_parameters()))\nprint('*'*50)\n\n# remove\u540e\u518d\u6b21\u6253\u5370\u6a21\u578bmask buffers\u53c2\u6570\nprint(list(module.named_buffers()))\nprint('*'*50)\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>[('weight_orig', Parameter containing:\ntensor([[[[ 0.1668,  0.0369, -0.2930],\n          [-0.2630, -0.1777, -0.1096],\n          [ 0.0481, -0.0898,  0.1920]]],\n\n\n        [[[ 0.0729,  0.1445, -0.0471],\n          [ 0.1525,  0.2986,  0.2602],\n          [-0.0929, -0.2725, -0.0069]]],\n\n\n        [[[-0.2006, -0.2577,  0.2754],\n          [ 0.0999,  0.2106, -0.0046],\n          [-0.2813, -0.2794, -0.0580]]],\n\n\n        [[[-0.2944, -0.2214, -0.0795],\n          [-0.0773,  0.2931, -0.2249],\n          [-0.0796, -0.2343, -0.0457]]],\n\n\n        [[[-0.1965,  0.2550,  0.2606],\n          [ 0.0213, -0.2839,  0.2037],\n          [-0.2068, -0.0507, -0.3097]]],\n\n\n        [[[ 0.0030,  0.2340, -0.1122],\n          [-0.0302, -0.0261,  0.1168],\n          [ 0.0927,  0.1553,  0.1167]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\ntensor([ 0.1147,  0.2439, -0.1753, -0.2578, -0.0994,  0.0588], device='cuda:0',\n       requires_grad=True))]\n**************************************************\n[('weight_mask', tensor([[[[0., 0., 0.],\n          [1., 1., 1.],\n          [0., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 0., 1.],\n          [1., 1., 1.]]],\n\n\n        [[[1., 1., 0.],\n          [1., 1., 1.],\n          [1., 0., 1.]]],\n\n\n        [[[0., 1., 1.],\n          [1., 1., 1.],\n          [1., 1., 0.]]],\n\n\n        [[[1., 0., 1.],\n          [0., 1., 0.],\n          [0., 1., 1.]]],\n\n\n        [[[1., 1., 1.],\n          [1., 0., 0.],\n          [0., 1., 1.]]]], device='cuda:0')), ('bias_mask', tensor([0., 1., 1., 1., 0., 0.], device='cuda:0'))]\n**************************************************\ntensor([[[[ 0.0000,  0.0000, -0.0000],\n          [-0.2630, -0.1777, -0.1096],\n          [ 0.0000, -0.0898,  0.1920]]],\n\n\n        [[[ 0.0729,  0.1445, -0.0471],\n          [ 0.1525,  0.0000,  0.2602],\n          [-0.0929, -0.2725, -0.0069]]],\n\n\n        [[[-0.2006, -0.2577,  0.0000],\n          [ 0.0999,  0.2106, -0.0046],\n          [-0.2813, -0.0000, -0.0580]]],\n\n\n        [[[-0.0000, -0.2214, -0.0795],\n          [-0.0773,  0.2931, -0.2249],\n          [-0.0796, -0.2343, -0.0000]]],\n\n\n        [[[-0.1965,  0.0000,  0.2606],\n          [ 0.0000, -0.2839,  0.0000],\n          [-0.0000, -0.0507, -0.3097]]],\n\n\n        [[[ 0.0030,  0.2340, -0.1122],\n          [-0.0302, -0.0000,  0.0000],\n          [ 0.0000,  0.1553,  0.1167]]]], device='cuda:0',\n       grad_fn=&lt;MulBackward0&gt;)\n**************************************************\nOrderedDict([(0, &lt;torch.nn.utils.prune.RandomUnstructured object at 0x7f65b879e7f0&gt;), (1, &lt;torch.nn.utils.prune.L1Unstructured object at 0x7f655c5ebfd0&gt;)])\n[('bias_orig', Parameter containing:\ntensor([ 0.1147,  0.2439, -0.1753, -0.2578, -0.0994,  0.0588], device='cuda:0',\n       requires_grad=True)), ('weight', Parameter containing:\ntensor([[[[ 0.0000,  0.0000, -0.0000],\n          [-0.2630, -0.1777, -0.1096],\n          [ 0.0000, -0.0898,  0.1920]]],\n\n\n        [[[ 0.0729,  0.1445, -0.0471],\n          [ 0.1525,  0.0000,  0.2602],\n          [-0.0929, -0.2725, -0.0069]]],\n\n\n        [[[-0.2006, -0.2577,  0.0000],\n          [ 0.0999,  0.2106, -0.0046],\n          [-0.2813, -0.0000, -0.0580]]],\n\n\n        [[[-0.0000, -0.2214, -0.0795],\n          [-0.0773,  0.2931, -0.2249],\n          [-0.0796, -0.2343, -0.0000]]],\n\n\n        [[[-0.1965,  0.0000,  0.2606],\n          [ 0.0000, -0.2839,  0.0000],\n          [-0.0000, -0.0507, -0.3097]]],\n\n\n        [[[ 0.0030,  0.2340, -0.1122],\n          [-0.0302, -0.0000,  0.0000],\n          [ 0.0000,  0.1553,  0.1167]]]], device='cuda:0', requires_grad=True))]\n**************************************************\n[('bias_mask', tensor([0., 1., 1., 1., 0., 0.], device='cuda:0'))]\n</code></pre> <p>\u7ed3\u8bba: \u5bf9\u6a21\u578b\u7684weight\u6267\u884cremove\u64cd\u4f5c\u540e, \u6a21\u578b\u53c2\u6570\u96c6\u5408\u4e2d\u53ea\u5269\u4e0bbias_orig\u4e86, weight_orig\u6d88\u5931, \u53d8\u6210\u4e86weight, \u8bf4\u660e\u9488\u5bf9weight\u7684\u526a\u679d\u5df2\u7ecf\u6c38\u4e45\u5316\u751f\u6548. \u5bf9\u4e8enamed_buffers\u5f20\u91cf\u6253\u5370\u53ef\u4ee5\u770b\u51fa, \u53ea\u5269\u4e0bbias_mask\u4e86, \u56e0\u4e3a\u9488\u5bf9weight\u505a\u63a9\u7801\u7684weight_mask\u5df2\u7ecf\u751f\u6548\u5b8c\u6bd5, \u4e0d\u518d\u9700\u8981\u4fdd\u7559\u4e86. </p>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html#3-pruning-multiple-parameters","title":"3. \u591a\u53c2\u6570\u6a21\u5757\u7684\u526a\u679d(Pruning multiple parameters).","text":"<pre><code>model = LeNet().to(device=device)\n\n# \u6253\u5370\u521d\u59cb\u6a21\u578b\u7684\u6240\u6709\u72b6\u6001\u5b57\u5178\nprint(model.state_dict().keys())\nprint('*'*50)\n\n# \u6253\u5370\u521d\u59cb\u6a21\u578b\u7684mask buffers\u5f20\u91cf\u5b57\u5178\u540d\u79f0\nprint(dict(model.named_buffers()).keys())\nprint('*'*50)\n\n# \u5bf9\u4e8e\u6a21\u578b\u8fdb\u884c\u5206\u6a21\u5757\u53c2\u6570\u7684\u526a\u679d\nfor name, module in model.named_modules():\n    # \u5bf9\u6a21\u578b\u4e2d\u6240\u6709\u7684\u5377\u79ef\u5c42\u6267\u884cl1_unstructured\u526a\u679d\u64cd\u4f5c, \u9009\u53d620%\u7684\u53c2\u6570\u526a\u679d\n    if isinstance(module, torch.nn.Conv2d):\n        prune.l1_unstructured(module, name=\"weight\", amount=0.2)\n    # \u5bf9\u6a21\u578b\u4e2d\u6240\u6709\u5168\u8fde\u63a5\u5c42\u6267\u884cln_structured\u526a\u679d\u64cd\u4f5c, \u9009\u53d640%\u7684\u53c2\u6570\u526a\u679d\n    elif isinstance(module, torch.nn.Linear):\n        prune.ln_structured(module, name=\"weight\", amount=0.4, n=2)\n\n# \u6253\u5370\u591a\u53c2\u6570\u6a21\u5757\u526a\u679d\u540e\u7684mask buffers\u5f20\u91cf\u5b57\u5178\u540d\u79f0\nprint(dict(model.named_buffers()).keys())\nprint('*'*50)\n\n# \u6253\u5370\u591a\u53c2\u6570\u6a21\u5757\u526a\u679d\u540e\u6a21\u578b\u7684\u6240\u6709\u72b6\u6001\u5b57\u5178\u540d\u79f0\nprint(model.state_dict().keys())\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n**************************************************\ndict_keys([])\n**************************************************\ndict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n**************************************************\nodict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.bias', 'conv2.weight_orig', 'conv2.weight_mask', 'fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.bias', 'fc2.weight_orig', 'fc2.weight_mask', 'fc3.bias', 'fc3.weight_orig', 'fc3.weight_mask'])\n</code></pre> <ul> <li>\u7ed3\u8bba: \u5bf9\u6bd4\u521d\u59cb\u5316\u6a21\u578b\u7684\u72b6\u6001\u5b57\u5178\u548c\u526a\u679d\u540e\u7684\u72b6\u6001\u5b57\u5178, \u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684weight\u53c2\u6570\u90fd\u6ca1\u6709\u4e86, \u53d8\u6210\u4e86weight_orig\u548cweight_mask\u7684\u7ec4\u5408. \u521d\u59cb\u5316\u7684\u6a21\u578bnamed_buffers\u662f\u7a7a\u5217\u8868, \u526a\u679d\u540e\u62e5\u6709\u4e86\u6240\u6709\u53c2\u4e0e\u526a\u679d\u7684\u53c2\u6570\u5c42\u7684weight_mask\u5f20\u91cf.</li> </ul>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html#4-global-pruning","title":"4. \u5168\u5c40\u526a\u679d(GLobal pruning).","text":"<p>\u7b2c\u4e00\u79cd, \u7b2c\u4e8c\u79cd\u526a\u679d\u7b56\u7565\u672c\u8d28\u4e0a\u5c5e\u4e8e\u5c40\u90e8\u526a\u679d(local pruning), \u9700\u8981\u7a0b\u5e8f\u5458\u6309\u7167\u81ea\u5df1\u7684\u5b9a\u4e49one by one\u7684\u8fdb\u884c\u64cd\u4f5c. \u6700\u4e3b\u8981\u7684\u95ee\u9898\u5c31\u662f\u6a21\u578b\u526a\u679d\u6548\u679c\u7684\u597d\u574f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u7a0b\u5e8f\u5458\u7684\u526a\u679d\u7ecf\u9a8c, \u800c\u4e14\u5c31\u7b97\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7a0b\u5e8f\u5458\u4e5f\u5f88\u96be\u80af\u5b9a\u7684\u8bf4\u67d0\u79cd\u526a\u679d\u7b56\u7565\u4e00\u5b9a\u66f4\u4f18.</p> <p>\u66f4\u666e\u904d\u4e5f\u66f4\u901a\u7528\u7684\u526a\u679d\u7b56\u7565\u662f\u91c7\u7528\u5168\u5c40\u526a\u679d(global pruning), \u6bd4\u5982\u5728\u6574\u4f53\u7f51\u7edc\u7684\u89c6\u89d2\u4e0b\u526a\u679d\u638920%\u7684\u6743\u91cd\u53c2\u6570, \u800c\u4e0d\u662f\u5728\u6bcf\u4e00\u5c42\u4e0a\u90fd\u526a\u679d\u638920%\u7684\u6743\u91cd\u53c2\u6570. \u91c7\u7528\u5168\u5c40\u526a\u679d\u540e, \u4e0d\u540c\u7684\u5c42\u88ab\u526a\u6389\u7684\u767e\u5206\u6bd4\u4e0d\u540c.</p> <pre><code>model = LeNet().to(device=device)\n\n# \u9996\u5148\u6253\u5370\u521d\u59cb\u5316\u6a21\u578b\u7684\u72b6\u6001\u5b57\u5178\nprint(model.state_dict().keys())\nprint('*'*50)\n\n# \u6784\u5efa\u53c2\u6570\u96c6\u5408, \u51b3\u5b9a\u54ea\u4e9b\u5c42, \u54ea\u4e9b\u53c2\u6570\u96c6\u5408\u53c2\u4e0e\u526a\u679d\nparameters_to_prune = (\n            (model.conv1, 'weight'),\n            (model.conv2, 'weight'),\n            (model.fc1, 'weight'),\n            (model.fc2, 'weight'),\n            (model.fc3, 'weight'))\n\n# \u8c03\u7528prune\u4e2d\u7684\u5168\u5c40\u526a\u679d\u51fd\u6570global_unstructured\u6267\u884c\u526a\u679d\u64cd\u4f5c, \u6b64\u5904\u9488\u5bf9\u6574\u4f53\u6a21\u578b\u4e2d\u768420%\u53c2\u6570\u91cf\u8fdb\u884c\u526a\u679d\nprune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n\n# \u6700\u540e\u6253\u5370\u526a\u679d\u540e\u7684\u6a21\u578b\u7684\u72b6\u6001\u5b57\u5178\nprint(model.state_dict().keys())\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n**************************************************\nodict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.bias', 'conv2.weight_orig', 'conv2.weight_mask', 'fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.bias', 'fc2.weight_orig', 'fc2.weight_mask', 'fc3.bias', 'fc3.weight_orig', 'fc3.weight_mask'])\n</code></pre> <ul> <li>\u9488\u5bf9\u6a21\u578b\u526a\u679d\u540e, \u4e0d\u540c\u7684\u5c42\u4f1a\u6709\u4e0d\u540c\u6bd4\u4f8b\u7684\u6743\u91cd\u53c2\u6570\u88ab\u526a\u6389, \u5229\u7528\u4ee3\u7801\u6253\u5370\u51fa\u6765\u770b\u770b:</li> </ul> <pre><code>model = LeNet().to(device=device)\n\nparameters_to_prune = (\n            (model.conv1, 'weight'),\n            (model.conv2, 'weight'),\n            (model.fc1, 'weight'),\n            (model.fc2, 'weight'),\n            (model.fc3, 'weight'))\n\nprune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n\nprint(\n    \"Sparsity in conv1.weight: {:.2f}%\".format(\n    100. * float(torch.sum(model.conv1.weight == 0))\n    / float(model.conv1.weight.nelement())\n    ))\n\nprint(\n    \"Sparsity in conv2.weight: {:.2f}%\".format(\n    100. * float(torch.sum(model.conv2.weight == 0))\n    / float(model.conv2.weight.nelement())\n    ))\n\nprint(\n    \"Sparsity in fc1.weight: {:.2f}%\".format(\n    100. * float(torch.sum(model.fc1.weight == 0))\n    / float(model.fc1.weight.nelement())\n    ))\n\nprint(\n    \"Sparsity in fc2.weight: {:.2f}%\".format(\n    100. * float(torch.sum(model.fc2.weight == 0))\n    / float(model.fc2.weight.nelement())\n    ))\n\nprint(\n    \"Sparsity in fc3.weight: {:.2f}%\".format(\n    100. * float(torch.sum(model.fc3.weight == 0))\n    / float(model.fc3.weight.nelement())\n    ))\n\nprint(\n    \"Global sparsity: {:.2f}%\".format(\n    100. * float(torch.sum(model.conv1.weight == 0)\n               + torch.sum(model.conv2.weight == 0)\n               + torch.sum(model.fc1.weight == 0)\n               + torch.sum(model.fc2.weight == 0)\n               + torch.sum(model.fc3.weight == 0))\n         / float(model.conv1.weight.nelement()\n               + model.conv2.weight.nelement()\n               + model.fc1.weight.nelement()\n               + model.fc2.weight.nelement()\n               + model.fc3.weight.nelement())\n    ))\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>Sparsity in conv1.weight: 1.85%\nSparsity in conv2.weight: 7.87%\nSparsity in fc1.weight: 21.99%\nSparsity in fc2.weight: 12.56%\nSparsity in fc3.weight: 9.17%\nGlobal sparsity: 20.00%\n</code></pre> <ul> <li>\u7ed3\u8bba: \u5f53\u91c7\u7528\u5168\u5c40\u526a\u679d\u7b56\u7565\u7684\u65f6\u5019(\u5047\u5b9a20%\u6bd4\u4f8b\u53c2\u6570\u53c2\u4e0e\u526a\u679d), \u4ec5\u4fdd\u8bc1\u6a21\u578b\u603b\u4f53\u53c2\u6570\u91cf\u768420%\u88ab\u526a\u679d\u6389, \u5177\u4f53\u5230\u6bcf\u4e00\u5c42\u7684\u60c5\u51b5\u5219\u7531\u6a21\u578b\u7684\u5177\u4f53\u53c2\u6570\u5206\u5e03\u60c5\u51b5\u6765\u5b9a.</li> </ul>"},{"location":"10-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.html#5custom-pruning","title":"5.\u7528\u6237\u81ea\u5b9a\u4e49\u526a\u679d(Custom pruning).","text":"<ul> <li>\u6240\u8c13\u7528\u6237\u81ea\u5b9a\u4e49\u526a\u679d, \u5c31\u662f\u7a0b\u5e8f\u5458\u81ea\u5df1\u5b9a\u4e49\u901a\u8fc7\u4ec0\u4e48\u6837\u7684\u89c4\u5219\u8fdb\u884c\u526a\u679d, \u800c\u4e0d\u662f\u4f9d\u8d56Pytorch\u5b9a\u4e49\u597d\u7684\u6bd4\u5982l1_unstructured, ln_structured\u7b49\u7b49\u9884\u8bbe\u597d\u7684\u526a\u679d\u89c4\u5219\u6765\u8fdb\u884c\u526a\u679d.</li> </ul> <ul> <li>\u526a\u679d\u6a21\u578b\u901a\u8fc7\u7ee7\u627fclass BasePruningMethod()\u6765\u6267\u884c\u526a\u679d, \u5185\u90e8\u6709\u82e5\u5e72\u65b9\u6cd5: call, apply_mask, apply, prune, remove\u7b49\u7b49. \u4e00\u822c\u6765\u8bf4, \u7528\u6237\u53ea\u9700\u8981\u5b9e\u73b0__init__, \u548ccompute_mask\u4e24\u4e2a\u51fd\u6570\u5373\u53ef\u5b8c\u6210\u81ea\u5b9a\u4e49\u7684\u526a\u679d\u89c4\u5219\u8bbe\u5b9a.</li> </ul> <pre><code># \u81ea\u5b9a\u4e49\u526a\u679d\u65b9\u6cd5\u7684\u7c7b, \u4e00\u5b9a\u8981\u7ee7\u627fprune.BasePruningMethod\nclass myself_pruning_method(prune.BasePruningMethod):\n    PRUNING_TYPE = \"unstructured\"\n\n    # \u5185\u90e8\u5b9e\u73b0compute_mask\u51fd\u6570, \u5b8c\u6210\u7a0b\u5e8f\u5458\u81ea\u5df1\u5b9a\u4e49\u7684\u526a\u679d\u89c4\u5219, \u672c\u8d28\u4e0a\u5c31\u662f\u5982\u4f55\u53bbmask\u6389\u6743\u91cd\u53c2\u6570\n    def compute_mask(self, t, default_mask):\n        mask = default_mask.clone()\n        # \u6b64\u5904\u5b9a\u4e49\u7684\u89c4\u5219\u662f\u6bcf\u9694\u4e00\u4e2a\u53c2\u6570\u5c31\u906e\u63a9\u6389\u4e00\u4e2a, \u6700\u7ec8\u53c2\u4e0e\u526a\u679d\u7684\u53c2\u6570\u91cf\u768450%\u88abmask\u6389\n        mask.view(-1)[::2] = 0\n        return mask\n\n# \u81ea\u5b9a\u4e49\u526a\u679d\u65b9\u6cd5\u7684\u51fd\u6570, \u5185\u90e8\u76f4\u63a5\u8c03\u7528\u526a\u679d\u7c7b\u7684\u65b9\u6cd5apply\ndef myself_unstructured_pruning(module, name):\n    myself_pruning_method.apply(module, name)\n    return module\n</code></pre> <ul> <li>\u8c03\u7528:</li> </ul> <pre><code># \u5b9e\u4f8b\u5316\u6a21\u578b\u7c7b\nmodel = LeNet().to(device=device)\n\nstart = time.time()\n# \u8c03\u7528\u81ea\u5b9a\u4e49\u526a\u679d\u65b9\u6cd5\u7684\u51fd\u6570, \u5bf9model\u4e2d\u7684\u7b2c\u4e09\u4e2a\u5168\u8fde\u63a5\u5c42fc3\u4e2d\u7684\u504f\u7f6ebias\u6267\u884c\u81ea\u5b9a\u4e49\u526a\u679d\nmyself_unstructured_pruning(model.fc3, name=\"bias\")\n\n# \u526a\u679d\u6210\u529f\u7684\u6700\u5927\u6807\u5fd7, \u5c31\u662f\u62e5\u6709\u4e86bias_mask\u53c2\u6570\nprint(model.fc3.bias_mask)\n\n# \u6253\u5370\u4e00\u4e0b\u81ea\u5b9a\u4e49\u526a\u679d\u7684\u8017\u65f6\nduration = time.time() - start\nprint(duration * 1000, 'ms')\n</code></pre> <ul> <li>\u8f93\u51fa\u7ed3\u679c:</li> </ul> <pre><code>tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0')\n1.7154216766357422 ms\n</code></pre> <p>\u7ed3\u8bba: \u6253\u5370\u51fa\u6765\u7684bias_mask\u5f20\u91cf, \u5b8c\u5168\u662f\u6309\u7167\u9884\u5b9a\u4e49\u7684\u65b9\u5f0f\u6bcf\u9694\u4e00\u4f4d\u906e\u63a9\u6389\u4e00\u4f4d, 0\u548c1\u4ea4\u66ff\u51fa\u73b0, \u540e\u7eed\u6267\u884cremove\u64cd\u4f5c\u7684\u65f6\u5019, \u539f\u59cb\u7684bias_orig\u4e2d\u7684\u6743\u91cd\u5c31\u4f1a\u540c\u6837\u7684\u88ab\u6bcf\u9694\u4e00\u4f4d\u526a\u679d\u6389\u4e00\u4f4d. \u5728GPU\u673a\u5668\u4e0a\u6267\u884c\u81ea\u5b9a\u4e49\u526a\u679d\u901f\u5ea6\u7279\u522b\u5feb, \u4ec5\u97001.7ms.</p>"}]}